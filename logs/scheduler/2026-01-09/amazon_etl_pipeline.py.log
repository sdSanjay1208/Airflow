[2026-01-09T16:02:36.227+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:02:36.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:02:36.229+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:02:36.229+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:02:37.284+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:02:37.321+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:02:37.320+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:02:37.515+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:02:37.515+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:02:37.535+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.313 seconds
[2026-01-09T16:03:07.827+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:03:07.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:03:07.830+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:03:07.830+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:03:08.364+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:03:08.410+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:03:08.409+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:03:08.426+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:03:08.425+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:03:08.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.829 seconds
[2026-01-09T16:03:38.942+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:03:38.944+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:03:38.945+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:03:38.945+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:03:39.395+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:03:39.428+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:03:39.427+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:03:39.442+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:03:39.442+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:03:39.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.523 seconds
[2026-01-09T16:04:09.846+0000] {processor.py:161} INFO - Started process (PID=269) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:04:09.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:04:09.848+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:04:09.847+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:04:10.247+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:04:10.277+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:04:10.276+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:04:10.287+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:04:10.287+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:04:10.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.466 seconds
[2026-01-09T16:04:40.671+0000] {processor.py:161} INFO - Started process (PID=291) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:04:40.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:04:40.673+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:04:40.673+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:04:41.119+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:04:41.151+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:04:41.151+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:04:41.162+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:04:41.162+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:04:41.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.513 seconds
[2026-01-09T16:05:11.555+0000] {processor.py:161} INFO - Started process (PID=313) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:05:11.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:05:11.557+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:05:11.557+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:05:11.994+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:05:12.027+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:05:12.027+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:05:12.041+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:05:12.041+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:05:12.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.513 seconds
[2026-01-09T16:05:42.452+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:05:42.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:05:42.454+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:05:42.454+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:05:42.872+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:05:42.903+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:05:42.902+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:05:42.916+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:05:42.915+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:05:42.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.488 seconds
[2026-01-09T16:06:13.311+0000] {processor.py:161} INFO - Started process (PID=357) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:06:13.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:06:13.313+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:06:13.313+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:06:13.718+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:06:13.748+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:06:13.747+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:06:13.762+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:06:13.762+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:06:13.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.476 seconds
[2026-01-09T16:06:44.160+0000] {processor.py:161} INFO - Started process (PID=379) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:06:44.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:06:44.161+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:06:44.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:06:44.593+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:06:44.623+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:06:44.622+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:06:44.639+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:06:44.638+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:06:44.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.505 seconds
[2026-01-09T16:07:15.038+0000] {processor.py:161} INFO - Started process (PID=401) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:07:15.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:07:15.040+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:07:15.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:07:15.448+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:07:15.481+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:07:15.480+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:07:15.492+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:07:15.492+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:07:15.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.478 seconds
[2026-01-09T16:07:45.907+0000] {processor.py:161} INFO - Started process (PID=423) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:07:45.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:07:45.909+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:07:45.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:07:46.327+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:07:46.362+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:07:46.361+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:07:46.375+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:07:46.375+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:07:46.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.494 seconds
[2026-01-09T16:08:16.755+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:08:16.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:08:16.757+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:08:16.757+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:08:17.196+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:08:17.229+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:08:17.228+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:08:17.242+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:08:17.242+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:08:17.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.513 seconds
[2026-01-09T16:08:47.659+0000] {processor.py:161} INFO - Started process (PID=467) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:08:47.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:08:47.661+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:08:47.661+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:08:48.080+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:08:48.111+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:08:48.111+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:08:48.124+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:08:48.124+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:08:48.339+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.684 seconds
[2026-01-09T16:09:18.622+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:09:18.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:09:18.624+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:09:18.623+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:09:19.045+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:09:19.078+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:09:19.078+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:09:19.094+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:09:19.093+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:09:19.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.497 seconds
[2026-01-09T16:09:49.501+0000] {processor.py:161} INFO - Started process (PID=511) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:09:49.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:09:49.503+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:09:49.503+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:09:50.009+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:09:50.049+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:09:50.049+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:09:50.062+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:09:50.062+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:09:50.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.590 seconds
[2026-01-09T16:10:20.489+0000] {processor.py:161} INFO - Started process (PID=533) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:10:20.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:10:20.491+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:10:20.490+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:10:21.215+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:10:21.266+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:10:21.265+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:10:21.286+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:10:21.286+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:10:21.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.839 seconds
[2026-01-09T16:10:51.780+0000] {processor.py:161} INFO - Started process (PID=555) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:10:51.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:10:51.784+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:10:51.783+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:10:52.235+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:10:52.267+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:10:52.267+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:10:52.281+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:10:52.280+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:10:52.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.525 seconds
[2026-01-09T16:11:22.743+0000] {processor.py:161} INFO - Started process (PID=577) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:11:22.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:11:22.745+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:11:22.745+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:11:23.161+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:11:23.193+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:11:23.192+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:11:23.209+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:11:23.209+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:11:23.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.496 seconds
[2026-01-09T16:11:53.625+0000] {processor.py:161} INFO - Started process (PID=599) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:11:53.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:11:53.628+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:11:53.627+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:11:54.049+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:11:54.082+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:11:54.081+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:11:54.097+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:11:54.096+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:11:54.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.669 seconds
[2026-01-09T16:12:24.567+0000] {processor.py:161} INFO - Started process (PID=621) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:12:24.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:12:24.569+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:12:24.569+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:12:25.036+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:12:25.071+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:12:25.070+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:12:25.086+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:12:25.086+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:12:25.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.546 seconds
[2026-01-09T16:12:55.490+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:12:55.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:12:55.492+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:12:55.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:12:55.918+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:12:55.951+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:12:55.950+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:12:55.963+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:12:55.962+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:12:55.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.496 seconds
[2026-01-09T16:13:26.419+0000] {processor.py:161} INFO - Started process (PID=665) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:13:26.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:13:26.421+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:13:26.420+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:13:26.875+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:13:26.914+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:13:26.912+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:13:26.934+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:13:26.934+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:13:26.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.547 seconds
[2026-01-09T16:13:57.360+0000] {processor.py:161} INFO - Started process (PID=687) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:13:57.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:13:57.362+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:13:57.362+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:13:57.778+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:13:57.809+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:13:57.808+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:13:57.820+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:13:57.820+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:13:57.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.483 seconds
[2026-01-09T16:14:28.215+0000] {processor.py:161} INFO - Started process (PID=709) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:14:28.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:14:28.219+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:14:28.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:14:28.658+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:14:28.708+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:14:28.708+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:14:28.732+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:14:28.731+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:14:28.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.714 seconds
[2026-01-09T16:14:59.222+0000] {processor.py:161} INFO - Started process (PID=731) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:14:59.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:14:59.225+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:14:59.224+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:14:59.662+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:14:59.697+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:14:59.697+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:14:59.864+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:14:59.864+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:14:59.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.664 seconds
[2026-01-09T16:15:30.178+0000] {processor.py:161} INFO - Started process (PID=753) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:15:30.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:15:30.181+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:15:30.180+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:15:30.644+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:15:30.679+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:15:30.678+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:15:30.693+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:15:30.692+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:15:30.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.537 seconds
[2026-01-09T16:16:01.129+0000] {processor.py:161} INFO - Started process (PID=775) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:16:01.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:16:01.132+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:16:01.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:16:01.572+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:16:01.605+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:16:01.605+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:16:01.618+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:16:01.617+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:16:01.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.512 seconds
[2026-01-09T16:16:32.031+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:16:32.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:16:32.034+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:16:32.033+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:16:32.458+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:16:32.494+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:16:32.494+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:16:32.511+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:16:32.511+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:16:32.535+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.507 seconds
[2026-01-09T16:17:02.967+0000] {processor.py:161} INFO - Started process (PID=819) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:17:02.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:17:02.969+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:17:02.969+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:17:03.373+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:17:03.405+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:17:03.404+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:17:03.417+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:17:03.417+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:17:03.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.475 seconds
[2026-01-09T16:17:33.853+0000] {processor.py:161} INFO - Started process (PID=841) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:17:33.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:17:33.855+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:17:33.855+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:17:34.289+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:17:34.319+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:17:34.319+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:17:34.331+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:17:34.331+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:17:34.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.647 seconds
[2026-01-09T16:18:04.836+0000] {processor.py:161} INFO - Started process (PID=863) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:18:04.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:18:04.838+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:18:04.838+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:18:05.254+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:18:05.286+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:18:05.286+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:18:05.456+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:18:05.456+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:18:05.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.640 seconds
[2026-01-09T16:18:35.813+0000] {processor.py:161} INFO - Started process (PID=885) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:18:35.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:18:35.816+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:18:35.815+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:18:36.499+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:18:36.550+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:18:36.550+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:18:36.572+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:18:36.571+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:18:36.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.799 seconds
[2026-01-09T16:19:07.093+0000] {processor.py:161} INFO - Started process (PID=907) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:19:07.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:19:07.096+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:19:07.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:19:07.515+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:19:07.546+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:19:07.545+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:19:07.558+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:19:07.558+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:19:07.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.492 seconds
[2026-01-09T16:19:37.973+0000] {processor.py:161} INFO - Started process (PID=929) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:19:37.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:19:37.975+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:19:37.975+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:19:38.400+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:19:38.431+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:19:38.431+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:19:38.443+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:19:38.442+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:19:38.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.495 seconds
[2026-01-09T16:20:08.831+0000] {processor.py:161} INFO - Started process (PID=951) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:20:08.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:20:08.834+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:20:08.834+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:20:09.325+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:20:09.359+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:20:09.358+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:20:09.372+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:20:09.372+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:20:09.393+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.566 seconds
[2026-01-09T16:20:39.779+0000] {processor.py:161} INFO - Started process (PID=973) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:20:39.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:20:39.781+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:20:39.781+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:20:40.185+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:20:40.216+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:20:40.216+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:20:40.231+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:20:40.231+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:20:40.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.646 seconds
[2026-01-09T16:21:10.707+0000] {processor.py:161} INFO - Started process (PID=995) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:21:10.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:21:10.710+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:21:10.710+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:21:11.177+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:21:11.222+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:21:11.221+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:21:11.242+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:21:11.241+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:21:11.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.584 seconds
[2026-01-09T16:21:41.715+0000] {processor.py:161} INFO - Started process (PID=1017) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:21:41.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:21:41.717+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:21:41.717+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:21:42.172+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:21:42.203+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:21:42.202+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:21:42.214+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:21:42.214+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:21:42.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.527 seconds
[2026-01-09T16:22:12.606+0000] {processor.py:161} INFO - Started process (PID=1039) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:22:12.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:22:12.608+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:22:12.607+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:22:13.027+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:22:13.060+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:22:13.059+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:22:13.072+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:22:13.072+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:22:13.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.489 seconds
[2026-01-09T16:22:43.483+0000] {processor.py:161} INFO - Started process (PID=1061) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:22:43.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:22:43.486+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:22:43.485+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:22:43.904+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:22:43.936+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:22:43.936+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:22:43.950+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:22:43.950+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:22:43.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.495 seconds
[2026-01-09T16:23:14.347+0000] {processor.py:161} INFO - Started process (PID=1083) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:23:14.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:23:14.349+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:23:14.348+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:23:14.748+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:23:14.781+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:23:14.780+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:23:14.797+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:23:14.797+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:23:14.967+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.624 seconds
[2026-01-09T16:23:45.274+0000] {processor.py:161} INFO - Started process (PID=1105) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:23:45.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:23:45.277+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:23:45.276+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:23:45.708+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:23:45.743+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:23:45.742+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:23:45.759+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:23:45.759+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:23:45.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.511 seconds
[2026-01-09T16:24:16.295+0000] {processor.py:161} INFO - Started process (PID=1127) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:24:16.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:24:16.297+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:24:16.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:24:16.693+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:24:16.726+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:24:16.726+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:24:16.739+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:24:16.739+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:24:16.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.470 seconds
[2026-01-09T16:24:47.116+0000] {processor.py:161} INFO - Started process (PID=1149) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:24:47.118+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:24:47.119+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:24:47.118+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:24:47.552+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:24:47.584+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:24:47.583+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:24:47.596+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:24:47.596+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:24:47.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.506 seconds
[2026-01-09T16:25:18.006+0000] {processor.py:161} INFO - Started process (PID=1171) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:25:18.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:25:18.008+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:25:18.008+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:25:18.457+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:25:18.488+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:25:18.488+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:25:18.501+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:25:18.500+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:25:18.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.520 seconds
[2026-01-09T16:25:48.903+0000] {processor.py:161} INFO - Started process (PID=1193) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:25:48.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:25:48.905+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:25:48.905+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:25:49.381+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:25:49.414+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:25:49.413+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:25:49.425+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:25:49.425+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:25:49.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.705 seconds
[2026-01-09T16:26:19.888+0000] {processor.py:161} INFO - Started process (PID=1215) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:26:19.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:26:19.890+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:26:19.890+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:26:20.352+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:26:20.383+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:26:20.383+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:26:20.561+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:26:20.561+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:26:20.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.698 seconds
[2026-01-09T16:26:50.885+0000] {processor.py:161} INFO - Started process (PID=1237) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:26:50.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:26:50.887+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:26:50.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:26:51.365+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:26:51.404+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:26:51.403+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:26:51.420+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:26:51.420+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:26:51.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.567 seconds
[2026-01-09T16:27:21.975+0000] {processor.py:161} INFO - Started process (PID=1259) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:27:21.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:27:21.978+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:27:21.978+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:27:22.675+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:27:22.709+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:27:22.708+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:27:22.721+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:27:22.721+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:27:22.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.772 seconds
[2026-01-09T16:27:53.132+0000] {processor.py:161} INFO - Started process (PID=1281) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:27:53.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:27:53.134+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:27:53.133+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:27:53.583+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:27:53.615+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:27:53.615+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:27:53.628+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:27:53.627+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:27:53.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.522 seconds
[2026-01-09T16:28:24.038+0000] {processor.py:161} INFO - Started process (PID=1303) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:28:24.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:28:24.041+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:28:24.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:28:24.477+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:28:24.508+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:28:24.507+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:28:24.521+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:28:24.521+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:28:24.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.683 seconds
[2026-01-09T16:28:54.998+0000] {processor.py:161} INFO - Started process (PID=1325) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:28:55.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:28:55.000+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:28:55.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:28:55.415+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:28:55.448+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:28:55.448+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:28:55.668+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:28:55.667+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:28:55.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.696 seconds
[2026-01-09T16:29:26.071+0000] {processor.py:161} INFO - Started process (PID=1347) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:29:26.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:29:26.073+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:29:26.073+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:29:26.543+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:29:26.583+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:29:26.583+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:29:26.600+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:29:26.599+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:29:26.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.558 seconds
[2026-01-09T16:29:57.096+0000] {processor.py:161} INFO - Started process (PID=1369) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:29:57.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:29:57.098+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:29:57.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:29:57.524+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:29:57.561+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:29:57.560+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:29:57.577+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:29:57.577+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:29:57.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.507 seconds
[2026-01-09T16:30:28.006+0000] {processor.py:161} INFO - Started process (PID=1391) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:30:28.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:30:28.008+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:30:28.008+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:30:28.451+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:30:28.483+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:30:28.483+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:30:28.496+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:30:28.496+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:30:28.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.516 seconds
[2026-01-09T16:30:58.915+0000] {processor.py:161} INFO - Started process (PID=1413) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:30:58.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:30:58.917+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:30:58.917+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:30:59.349+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:30:59.384+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:30:59.383+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:30:59.398+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:30:59.398+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:30:59.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.528 seconds
[2026-01-09T16:31:29.861+0000] {processor.py:161} INFO - Started process (PID=1435) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:31:29.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:31:29.864+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:31:29.863+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:31:30.378+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:31:30.412+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:31:30.412+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:31:30.427+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:31:30.427+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:31:30.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.769 seconds
[2026-01-09T16:32:00.915+0000] {processor.py:161} INFO - Started process (PID=1457) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:32:00.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:32:00.918+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:32:00.918+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:32:01.347+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:32:01.380+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:32:01.380+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:32:01.591+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:32:01.590+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:32:01.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.702 seconds
[2026-01-09T16:32:32.001+0000] {processor.py:161} INFO - Started process (PID=1479) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:32:32.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:32:32.004+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:32:32.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:32:32.443+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:32:32.475+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:32:32.475+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:32:32.487+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:32:32.486+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:32:32.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.511 seconds
[2026-01-09T16:33:02.905+0000] {processor.py:161} INFO - Started process (PID=1501) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:33:02.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:33:02.907+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:33:02.907+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:33:03.333+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:33:03.367+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:33:03.367+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:33:03.380+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:33:03.380+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:33:03.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.501 seconds
[2026-01-09T16:33:33.809+0000] {processor.py:161} INFO - Started process (PID=1523) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:33:33.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:33:33.811+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:33:33.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:33:34.238+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:33:34.270+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:33:34.270+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:33:34.283+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:33:34.283+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:33:34.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.499 seconds
[2026-01-09T16:34:04.705+0000] {processor.py:161} INFO - Started process (PID=1545) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:34:04.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:34:04.707+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:34:04.707+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:34:05.120+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:34:05.150+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:34:05.149+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:34:05.339+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:34:05.338+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:34:05.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.659 seconds
[2026-01-09T16:34:35.647+0000] {processor.py:161} INFO - Started process (PID=1567) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:34:35.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:34:35.649+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:34:35.649+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:34:36.078+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:34:36.111+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:34:36.110+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:34:36.370+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:34:36.370+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:34:36.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.754 seconds
[2026-01-09T16:35:06.797+0000] {processor.py:161} INFO - Started process (PID=1589) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:35:06.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:35:06.799+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:35:06.798+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:35:07.254+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:35:07.293+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:35:07.292+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:35:07.309+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:35:07.309+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:35:07.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.540 seconds
[2026-01-09T16:35:37.804+0000] {processor.py:161} INFO - Started process (PID=1611) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:35:37.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:35:37.806+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:35:37.806+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:35:38.268+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:35:38.303+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:35:38.302+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:35:38.315+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:35:38.315+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:35:38.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.538 seconds
[2026-01-09T16:36:08.713+0000] {processor.py:161} INFO - Started process (PID=1633) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:36:08.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:36:08.716+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:36:08.715+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:36:09.135+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:36:09.168+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:36:09.167+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:36:09.182+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:36:09.181+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:36:09.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.494 seconds
[2026-01-09T16:36:39.595+0000] {processor.py:161} INFO - Started process (PID=1655) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:36:39.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:36:39.598+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:36:39.597+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:36:40.078+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:36:40.110+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:36:40.110+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:36:40.124+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:36:40.124+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:36:40.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.718 seconds
[2026-01-09T16:37:10.587+0000] {processor.py:161} INFO - Started process (PID=1677) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:37:10.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:37:10.589+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:37:10.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:37:11.069+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:37:11.100+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:37:11.099+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:37:11.266+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:37:11.265+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:37:11.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.701 seconds
[2026-01-09T16:37:41.560+0000] {processor.py:161} INFO - Started process (PID=1699) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:37:41.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:37:41.562+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:37:41.561+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:37:42.019+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:37:42.060+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:37:42.059+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:37:42.381+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:37:42.381+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:37:42.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.849 seconds
[2026-01-09T16:38:12.829+0000] {processor.py:161} INFO - Started process (PID=1721) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:38:12.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:38:12.831+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:38:12.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:38:13.260+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:38:13.295+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:38:13.294+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:38:13.308+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:38:13.308+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:38:13.329+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.503 seconds
[2026-01-09T16:38:43.698+0000] {processor.py:161} INFO - Started process (PID=1743) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:38:43.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:38:43.700+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:38:43.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:38:44.126+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:38:44.164+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:38:44.164+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:38:44.179+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:38:44.179+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:38:44.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.508 seconds
[2026-01-09T16:39:14.600+0000] {processor.py:161} INFO - Started process (PID=1765) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:39:14.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:39:14.603+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:39:14.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:39:15.025+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:39:15.059+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:39:15.058+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:39:15.074+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:39:15.074+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:39:15.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.502 seconds
[2026-01-09T16:39:45.495+0000] {processor.py:161} INFO - Started process (PID=1787) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:39:45.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:39:45.499+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:39:45.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:39:45.925+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:39:45.959+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:39:45.959+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:39:45.975+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:39:45.974+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:39:46.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.660 seconds
[2026-01-09T16:40:16.445+0000] {processor.py:161} INFO - Started process (PID=1809) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:40:16.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:40:16.448+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:40:16.447+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:40:16.885+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:40:16.918+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:40:16.917+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:40:17.122+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:40:17.122+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:40:17.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.702 seconds
[2026-01-09T16:40:47.539+0000] {processor.py:161} INFO - Started process (PID=1831) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:40:47.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:40:47.540+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:40:47.540+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:40:47.981+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:40:48.015+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:40:48.015+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:40:48.027+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:40:48.027+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:40:48.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.515 seconds
[2026-01-09T16:41:18.438+0000] {processor.py:161} INFO - Started process (PID=1853) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:41:18.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:41:18.440+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:41:18.440+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:41:18.879+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:41:18.916+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:41:18.915+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:41:18.928+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:41:18.928+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:41:18.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.516 seconds
[2026-01-09T16:41:49.317+0000] {processor.py:161} INFO - Started process (PID=1875) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:41:49.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:41:49.320+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:41:49.320+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:41:49.800+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:41:49.837+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:41:49.836+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:41:49.851+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:41:49.850+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:41:49.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.565 seconds
[2026-01-09T16:42:20.352+0000] {processor.py:161} INFO - Started process (PID=1897) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:42:20.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:42:20.354+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:42:20.354+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:42:20.775+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:42:20.806+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:42:20.806+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:42:20.983+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:42:20.983+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:42:21.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.653 seconds
[2026-01-09T16:42:51.325+0000] {processor.py:161} INFO - Started process (PID=1919) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:42:51.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:42:51.327+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:42:51.327+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:42:51.765+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:42:51.799+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:42:51.798+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:42:52.017+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:42:52.017+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:42:52.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.716 seconds
[2026-01-09T16:43:22.485+0000] {processor.py:161} INFO - Started process (PID=1941) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:43:22.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:43:22.488+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:43:22.487+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:43:22.892+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:43:22.930+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:43:22.929+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:43:22.945+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:43:22.945+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:43:22.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.495 seconds
[2026-01-09T16:43:53.374+0000] {processor.py:161} INFO - Started process (PID=1963) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:43:53.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:43:53.376+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:43:53.376+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:43:53.848+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:43:53.885+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:43:53.884+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:43:53.900+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:43:53.900+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:43:53.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.556 seconds
[2026-01-09T16:44:24.317+0000] {processor.py:161} INFO - Started process (PID=1985) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:44:24.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-09T16:44:24.320+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:44:24.320+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:44:24.721+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-09T16:44:24.751+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:44:24.750+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-09T16:44:24.762+0000] {logging_mixin.py:188} INFO - [2026-01-09T16:44:24.761+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-09T16:44:24.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.471 seconds
