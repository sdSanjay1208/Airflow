[2025-12-28T13:02:31.531+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:02:31.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:02:31.536+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:02:31.535+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:02:33.981+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:02:34.026+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:02:34.026+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:02:34.043+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:02:34.042+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:02:34.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 2.544 seconds
[2025-12-28T13:03:04.850+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:03:04.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:03:04.855+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:03:04.854+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:03:05.591+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:03:05.652+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:03:05.651+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:03:05.678+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:03:05.677+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:03:05.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.153 seconds
[2025-12-28T13:03:36.571+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:03:36.572+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:03:36.573+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:03:36.573+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:03:37.216+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:03:37.255+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:03:37.255+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:03:37.273+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:03:37.272+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:03:37.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.732 seconds
[2025-12-28T13:04:08.155+0000] {processor.py:161} INFO - Started process (PID=262) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:04:08.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:04:08.163+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:04:08.163+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:04:08.927+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:04:08.975+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:04:08.974+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:04:09.002+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:04:09.001+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:04:09.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.892 seconds
[2025-12-28T13:04:39.819+0000] {processor.py:161} INFO - Started process (PID=278) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:04:39.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:04:39.824+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:04:39.823+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:04:40.645+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:04:40.699+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:04:40.698+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:04:40.720+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:04:40.719+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:04:40.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.939 seconds
[2025-12-28T13:05:10.914+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:05:10.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:05:10.918+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:05:10.918+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:05:11.693+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:05:11.747+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:05:11.746+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:05:11.778+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:05:11.778+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:05:11.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.913 seconds
[2025-12-28T13:05:42.552+0000] {processor.py:161} INFO - Started process (PID=310) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:05:42.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:05:42.556+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:05:42.556+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:05:43.325+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:05:43.378+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:05:43.377+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:05:43.399+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:05:43.399+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:05:43.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.889 seconds
[2025-12-28T13:06:14.262+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:06:14.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:06:14.277+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:06:14.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:06:15.031+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:06:15.085+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:06:15.084+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:06:15.110+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:06:15.109+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:06:15.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.888 seconds
[2025-12-28T13:06:45.947+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:06:45.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:06:45.951+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:06:45.951+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:06:46.748+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:06:46.802+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:06:46.801+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:06:46.831+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:06:46.831+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:06:46.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.927 seconds
[2025-12-28T13:07:17.718+0000] {processor.py:161} INFO - Started process (PID=360) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:07:17.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:07:17.721+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:07:17.721+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:07:18.404+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:07:18.453+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:07:18.453+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:07:18.474+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:07:18.474+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:07:18.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.794 seconds
[2025-12-28T13:07:49.286+0000] {processor.py:161} INFO - Started process (PID=376) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:07:49.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:07:49.290+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:07:49.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:07:49.847+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:07:49.887+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:07:49.886+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:07:49.904+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:07:49.903+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:07:49.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.646 seconds
[2025-12-28T13:08:20.037+0000] {processor.py:161} INFO - Started process (PID=392) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:08:20.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:08:20.044+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:08:20.043+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:08:20.978+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:08:21.030+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:08:21.029+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:08:21.053+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:08:21.053+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:08:21.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.076 seconds
[2025-12-28T13:08:51.776+0000] {processor.py:161} INFO - Started process (PID=408) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:08:51.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:08:51.781+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:08:51.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:08:52.504+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:08:52.554+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:08:52.554+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:08:52.576+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:08:52.575+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:08:52.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.124 seconds
[2025-12-28T13:09:23.604+0000] {processor.py:161} INFO - Started process (PID=424) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:09:23.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:09:23.608+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:09:23.607+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:09:24.332+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:09:24.379+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:09:24.379+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:09:24.401+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:09:24.400+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:09:24.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.840 seconds
[2025-12-28T13:09:55.372+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:09:55.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:09:55.379+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:09:55.378+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:09:56.115+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:09:56.171+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:09:56.170+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:09:56.196+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:09:56.196+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:09:56.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.864 seconds
[2025-12-28T13:11:32.726+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:11:32.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:11:32.730+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:11:32.729+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:11:34.205+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:11:34.250+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:11:34.250+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:11:34.266+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:11:34.266+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:11:34.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.590 seconds
[2025-12-28T13:12:05.043+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:12:05.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:12:05.047+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:12:05.046+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:12:05.838+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:12:05.895+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:12:05.895+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:12:05.920+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:12:05.920+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:12:06.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.163 seconds
[2025-12-28T13:12:36.898+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:12:36.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:12:36.903+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:12:36.902+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:12:37.627+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:12:37.677+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:12:37.676+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:12:37.700+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:12:37.700+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:12:37.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.861 seconds
[2025-12-28T13:13:08.681+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:13:08.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:13:08.685+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:13:08.684+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:13:09.406+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:13:09.456+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:13:09.456+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:13:09.477+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:13:09.476+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:13:09.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.852 seconds
[2025-12-28T13:13:40.286+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:13:40.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:13:40.290+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:13:40.290+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:13:41.034+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:13:41.086+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:13:41.084+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:13:41.113+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:13:41.112+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:13:41.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.871 seconds
[2025-12-28T13:14:12.001+0000] {processor.py:161} INFO - Started process (PID=290) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:14:12.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:14:12.006+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:14:12.005+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:14:12.726+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:14:12.777+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:14:12.776+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:14:12.797+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:14:12.797+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:14:12.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.855 seconds
[2025-12-28T13:14:43.817+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:14:43.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:14:43.822+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:14:43.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:14:44.556+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:14:44.647+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:14:44.646+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:14:44.688+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:14:44.687+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:14:44.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.946 seconds
[2025-12-28T13:15:15.430+0000] {processor.py:161} INFO - Started process (PID=322) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:15:15.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:15:15.433+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:15:15.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:15:15.980+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:15:16.018+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:15:16.018+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:15:16.037+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:15:16.036+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:15:16.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.637 seconds
[2025-12-28T13:15:46.180+0000] {processor.py:161} INFO - Started process (PID=338) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:15:46.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:15:46.185+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:15:46.185+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:15:46.956+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:15:47.008+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:15:47.007+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:15:47.030+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:15:47.029+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:15:47.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.110 seconds
[2025-12-28T13:16:18.010+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:16:18.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:16:18.015+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:16:18.014+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:16:18.787+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:16:18.840+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:16:18.840+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:16:18.863+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:16:18.862+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:16:18.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.914 seconds
[2025-12-28T13:16:49.694+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:16:49.696+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:16:49.697+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:16:49.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:16:50.259+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:16:50.297+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:16:50.296+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:16:50.313+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:16:50.313+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:16:50.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.645 seconds
[2025-12-28T13:17:21.156+0000] {processor.py:161} INFO - Started process (PID=386) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:17:21.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:17:21.158+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:17:21.158+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:17:21.620+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:17:21.654+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:17:21.654+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:17:21.669+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:17:21.669+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:17:21.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.537 seconds
[2025-12-28T13:17:52.698+0000] {processor.py:161} INFO - Started process (PID=402) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:17:52.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:17:52.701+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:17:52.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:17:53.399+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:17:53.460+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:17:53.459+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:17:53.480+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:17:53.480+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:17:53.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.008 seconds
[2025-12-28T13:18:24.169+0000] {processor.py:161} INFO - Started process (PID=418) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:18:24.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:18:24.172+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:18:24.171+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:18:24.563+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:18:24.596+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:18:24.595+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:18:24.611+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:18:24.611+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:18:24.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.470 seconds
[2025-12-28T13:18:55.588+0000] {processor.py:161} INFO - Started process (PID=434) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:18:55.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:18:55.590+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:18:55.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:18:55.982+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:18:56.013+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:18:56.012+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:18:56.025+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:18:56.025+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:18:56.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.460 seconds
[2025-12-28T13:19:27.010+0000] {processor.py:161} INFO - Started process (PID=450) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:19:27.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:19:27.013+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:19:27.013+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:19:27.404+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:19:27.433+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:19:27.433+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:19:27.446+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:19:27.445+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:19:27.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.476 seconds
[2025-12-28T13:19:58.419+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:19:58.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:19:58.421+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:19:58.421+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:19:58.891+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:19:58.926+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:19:58.926+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:19:58.942+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:19:58.942+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:19:58.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.548 seconds
[2025-12-28T13:20:29.857+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:20:29.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:20:29.860+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:20:29.860+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:20:30.235+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:20:30.268+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:20:30.267+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:20:30.283+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:20:30.283+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:20:30.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.451 seconds
[2025-12-28T13:21:01.337+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:21:01.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:21:01.340+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:21:01.340+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:21:01.835+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:21:01.870+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:21:01.870+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:21:01.885+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:21:01.885+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:21:02.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.757 seconds
[2025-12-28T13:21:32.551+0000] {processor.py:161} INFO - Started process (PID=514) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:21:32.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:21:32.553+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:21:32.553+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:21:32.983+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:21:33.014+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:21:33.014+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:21:33.029+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:21:33.028+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:21:33.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.499 seconds
[2025-12-28T13:22:03.341+0000] {processor.py:161} INFO - Started process (PID=530) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:22:03.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:22:03.343+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:22:03.343+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:22:03.748+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:22:03.778+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:22:03.778+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:22:03.791+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:22:03.791+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:22:03.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.494 seconds
[2025-12-28T13:22:34.783+0000] {processor.py:161} INFO - Started process (PID=546) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:22:34.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:22:34.785+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:22:34.785+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:22:35.197+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:22:35.224+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:22:35.224+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:22:35.237+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:22:35.237+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:22:35.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.478 seconds
[2025-12-28T13:23:06.211+0000] {processor.py:161} INFO - Started process (PID=562) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:23:06.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:23:06.213+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:23:06.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:23:06.578+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:23:06.607+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:23:06.606+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:23:06.621+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:23:06.620+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:23:06.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.433 seconds
[2025-12-28T13:23:37.628+0000] {processor.py:161} INFO - Started process (PID=578) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:23:37.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:23:37.630+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:23:37.630+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:23:38.016+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:23:38.044+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:23:38.044+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:23:38.056+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:23:38.056+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:23:38.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.450 seconds
[2025-12-28T13:24:08.148+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:24:08.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:24:08.151+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:24:08.151+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:24:08.590+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:24:08.628+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:24:08.628+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:24:08.645+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:24:08.645+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:24:08.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.715 seconds
[2025-12-28T13:24:39.358+0000] {processor.py:161} INFO - Started process (PID=610) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:24:39.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:24:39.361+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:24:39.360+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:24:39.752+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:24:39.785+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:24:39.784+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:24:39.799+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:24:39.799+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:24:39.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.482 seconds
[2025-12-28T13:25:09.998+0000] {processor.py:161} INFO - Started process (PID=626) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:25:10.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:25:10.001+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:25:10.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:25:10.495+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:25:10.546+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:25:10.546+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:25:10.563+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:25:10.563+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:25:10.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.590 seconds
[2025-12-28T13:25:41.420+0000] {processor.py:161} INFO - Started process (PID=642) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:25:41.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:25:41.422+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:25:41.422+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:25:41.801+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:25:41.831+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:25:41.831+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:25:41.844+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:25:41.843+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:25:41.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.445 seconds
[2025-12-28T13:26:12.813+0000] {processor.py:161} INFO - Started process (PID=658) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:26:12.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:26:12.815+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:26:12.815+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:26:13.182+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:26:13.213+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:26:13.212+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:26:13.227+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:26:13.227+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:26:13.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.435 seconds
[2025-12-28T13:26:44.279+0000] {processor.py:161} INFO - Started process (PID=674) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:26:44.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:26:44.282+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:26:44.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:26:44.648+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:26:44.676+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:26:44.676+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:26:44.690+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:26:44.690+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:26:44.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.592 seconds
[2025-12-28T13:27:15.691+0000] {processor.py:161} INFO - Started process (PID=690) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:27:15.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:27:15.694+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:27:15.693+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:27:16.075+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:27:16.106+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:27:16.106+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:27:16.122+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:27:16.122+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:27:16.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.472 seconds
[2025-12-28T13:27:46.339+0000] {processor.py:161} INFO - Started process (PID=711) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:27:46.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:27:46.341+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:27:46.341+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:27:46.777+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:27:46.816+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:27:46.815+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:27:46.830+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:27:46.829+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:27:46.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.514 seconds
[2025-12-28T13:28:17.252+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:28:17.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:28:17.255+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:28:17.254+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:28:17.872+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:28:17.898+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:28:17.897+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:28:17.916+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:28:17.916+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:28:17.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.689 seconds
[2025-12-28T13:28:48.156+0000] {processor.py:161} INFO - Started process (PID=743) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:28:48.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:28:48.159+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:28:48.158+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:28:48.555+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:28:48.588+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:28:48.587+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:28:48.601+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:28:48.600+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:28:48.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.469 seconds
[2025-12-28T13:29:54.598+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:29:54.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:29:54.601+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:29:54.601+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:29:56.036+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:29:56.080+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:29:56.079+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:29:56.096+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:29:56.096+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:29:56.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.525 seconds
[2025-12-28T13:30:26.678+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:30:26.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:30:26.680+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:30:26.680+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:30:27.069+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:30:27.098+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:30:27.098+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:30:27.112+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:30:27.111+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:30:27.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.642 seconds
[2025-12-28T13:30:58.275+0000] {processor.py:161} INFO - Started process (PID=238) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:30:58.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:30:58.278+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:30:58.278+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:30:58.818+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:30:58.852+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:30:58.851+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:30:58.867+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:30:58.866+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:30:58.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.616 seconds
[2025-12-28T13:31:29.722+0000] {processor.py:161} INFO - Started process (PID=260) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:31:29.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:31:29.725+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:31:29.724+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:31:30.084+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:31:30.117+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:31:30.117+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:31:30.132+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:31:30.131+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:31:30.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.434 seconds
[2025-12-28T13:32:01.134+0000] {processor.py:161} INFO - Started process (PID=276) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:32:01.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:32:01.137+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:32:01.137+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:32:01.563+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:32:01.594+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:32:01.593+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:32:01.607+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:32:01.607+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:32:01.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.498 seconds
[2025-12-28T13:32:32.538+0000] {processor.py:161} INFO - Started process (PID=292) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:32:32.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:32:32.541+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:32:32.540+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:32:33.014+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:32:33.045+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:32:33.044+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:32:33.058+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:32:33.058+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:32:33.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.547 seconds
[2025-12-28T13:33:03.976+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:33:03.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:33:03.977+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:33:03.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:33:04.346+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:33:04.374+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:33:04.374+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:33:04.387+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:33:04.387+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:33:04.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.433 seconds
[2025-12-28T13:33:35.394+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:33:35.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:33:35.396+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:33:35.396+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:33:35.841+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:33:35.869+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:33:35.868+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:33:35.881+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:33:35.881+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:33:35.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.527 seconds
[2025-12-28T13:34:06.906+0000] {processor.py:161} INFO - Started process (PID=340) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:34:06.907+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:34:06.909+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:34:06.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:34:07.312+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:34:07.339+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:34:07.339+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:34:07.352+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:34:07.352+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:34:07.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.489 seconds
[2025-12-28T13:34:38.365+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:34:38.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:34:38.368+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:34:38.368+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:34:38.757+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:34:38.791+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:34:38.791+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:34:38.804+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:34:38.804+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:34:38.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.463 seconds
[2025-12-28T13:35:08.895+0000] {processor.py:161} INFO - Started process (PID=372) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:35:08.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:35:08.898+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:35:08.898+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:35:09.547+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:35:09.595+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:35:09.594+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:35:09.617+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:35:09.617+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:35:09.647+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.756 seconds
[2025-12-28T13:35:40.115+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:35:40.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:35:40.118+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:35:40.118+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:35:40.527+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:35:40.557+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:35:40.556+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:35:40.572+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:35:40.571+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:35:40.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.480 seconds
[2025-12-28T13:36:10.709+0000] {processor.py:161} INFO - Started process (PID=404) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:36:10.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:36:10.711+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:36:10.711+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:36:11.265+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:36:11.329+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:36:11.327+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:36:11.358+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:36:11.358+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:36:11.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.936 seconds
[2025-12-28T13:36:42.120+0000] {processor.py:161} INFO - Started process (PID=420) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:36:42.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:36:42.123+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:36:42.122+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:36:42.504+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:36:42.533+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:36:42.532+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:36:42.546+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:36:42.545+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:36:42.563+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.445 seconds
[2025-12-28T13:37:12.629+0000] {processor.py:161} INFO - Started process (PID=436) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:37:12.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:37:12.631+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:37:12.631+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:37:13.016+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:37:13.050+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:37:13.049+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:37:13.063+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:37:13.062+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:37:13.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.457 seconds
[2025-12-28T13:37:44.098+0000] {processor.py:161} INFO - Started process (PID=452) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:37:44.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:37:44.099+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:37:44.099+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:37:44.529+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:37:44.557+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:37:44.556+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:37:44.570+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:37:44.570+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:37:44.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.494 seconds
[2025-12-28T13:38:15.517+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:38:15.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:38:15.520+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:38:15.520+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:38:15.894+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:38:15.925+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:38:15.924+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:38:15.939+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:38:15.938+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:38:15.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.445 seconds
[2025-12-28T13:38:46.946+0000] {processor.py:161} INFO - Started process (PID=484) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:38:46.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:38:46.948+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:38:46.948+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:38:47.326+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:38:47.354+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:38:47.354+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:38:47.367+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:38:47.366+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:38:47.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.441 seconds
[2025-12-28T13:39:18.399+0000] {processor.py:161} INFO - Started process (PID=500) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:39:18.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:39:18.401+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:39:18.401+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:39:18.783+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:39:18.819+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:39:18.818+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:39:18.830+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:39:18.830+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:39:19.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.611 seconds
[2025-12-28T13:39:49.834+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:39:49.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:39:49.835+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:39:49.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:39:50.231+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:39:50.261+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:39:50.260+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:39:50.275+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:39:50.274+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:39:50.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.482 seconds
[2025-12-28T13:40:20.376+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:40:20.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:40:20.378+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:40:20.377+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:40:20.738+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:40:20.766+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:40:20.766+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:40:20.778+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:40:20.777+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:40:20.814+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.442 seconds
[2025-12-28T13:40:50.871+0000] {processor.py:161} INFO - Started process (PID=548) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:40:50.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:40:50.873+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:40:50.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:40:51.349+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:40:51.386+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:40:51.385+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:40:51.402+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:40:51.402+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:40:51.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.569 seconds
[2025-12-28T13:41:22.336+0000] {processor.py:161} INFO - Started process (PID=564) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:41:22.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:41:22.339+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:41:22.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:41:22.751+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:41:22.779+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:41:22.779+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:41:22.792+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:41:22.792+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:41:22.810+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.477 seconds
[2025-12-28T13:41:53.772+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:41:53.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:41:53.774+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:41:53.773+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:41:54.164+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:41:54.196+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:41:54.195+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:41:54.208+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:41:54.208+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:41:54.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.458 seconds
[2025-12-28T13:42:25.197+0000] {processor.py:161} INFO - Started process (PID=596) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:42:25.199+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:42:25.200+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:42:25.200+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:42:25.573+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:42:25.600+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:42:25.600+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:42:25.614+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:42:25.613+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:42:25.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.627 seconds
[2025-12-28T13:42:56.608+0000] {processor.py:161} INFO - Started process (PID=612) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:42:56.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:42:56.610+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:42:56.610+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:42:56.985+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:42:57.013+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:42:57.013+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:42:57.025+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:42:57.025+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:42:57.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.457 seconds
[2025-12-28T13:43:27.130+0000] {processor.py:161} INFO - Started process (PID=628) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:43:27.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-28T13:43:27.133+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:43:27.132+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:43:27.505+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-28T13:43:27.541+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:43:27.540+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-28T13:43:27.554+0000] {logging_mixin.py:188} INFO - [2025-12-28T13:43:27.554+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-28T13:43:27.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.449 seconds
