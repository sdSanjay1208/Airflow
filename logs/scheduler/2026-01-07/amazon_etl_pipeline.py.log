[2026-01-07T16:41:58.134+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:41:58.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:41:58.137+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:41:58.137+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:41:59.566+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:41:59.602+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:41:59.601+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:41:59.794+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:41:59.794+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:41:59.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.689 seconds
[2026-01-07T16:42:30.156+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:42:30.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:42:30.160+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:42:30.159+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:42:30.794+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:42:30.844+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:42:30.843+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:42:30.863+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:42:30.863+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:42:31.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.948 seconds
[2026-01-07T16:43:01.417+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:43:01.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:43:01.419+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:43:01.419+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:43:01.955+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:43:01.995+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:43:01.995+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:43:02.011+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:43:02.010+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:43:02.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.623 seconds
[2026-01-07T16:43:32.425+0000] {processor.py:161} INFO - Started process (PID=268) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:43:32.426+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:43:32.427+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:43:32.427+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:43:32.871+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:43:32.909+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:43:32.908+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:43:32.925+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:43:32.925+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:43:32.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.528 seconds
[2026-01-07T16:44:03.386+0000] {processor.py:161} INFO - Started process (PID=290) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:44:03.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:44:03.389+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:44:03.389+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:44:03.827+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:44:03.861+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:44:03.861+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:44:03.874+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:44:03.874+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:44:03.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.522 seconds
[2026-01-07T16:44:34.296+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:44:34.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:44:34.298+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:44:34.298+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:44:34.750+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:44:34.784+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:44:34.784+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:44:34.801+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:44:34.801+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:44:34.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.535 seconds
[2026-01-07T16:45:05.280+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:45:05.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:45:05.285+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:45:05.285+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:45:05.743+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:45:05.776+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:45:05.775+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:45:05.789+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:45:05.789+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:45:05.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.540 seconds
[2026-01-07T16:45:36.242+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:45:36.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:45:36.244+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:45:36.244+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:45:36.692+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:45:36.735+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:45:36.735+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:45:36.754+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:45:36.753+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:45:36.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.544 seconds
[2026-01-07T16:46:07.242+0000] {processor.py:161} INFO - Started process (PID=378) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:46:07.244+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:46:07.245+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:46:07.245+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:46:07.702+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:46:07.734+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:46:07.734+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:46:07.750+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:46:07.750+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:46:07.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.535 seconds
[2026-01-07T16:46:38.170+0000] {processor.py:161} INFO - Started process (PID=400) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:46:38.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:46:38.172+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:46:38.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:46:38.685+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:46:38.742+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:46:38.741+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:46:38.761+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:46:38.761+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:46:38.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.621 seconds
[2026-01-07T16:47:09.230+0000] {processor.py:161} INFO - Started process (PID=422) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:47:09.231+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:47:09.233+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:47:09.232+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:47:09.681+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:47:09.718+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:47:09.717+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:47:09.734+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:47:09.734+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:47:09.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.535 seconds
[2026-01-07T16:47:40.205+0000] {processor.py:161} INFO - Started process (PID=444) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:47:40.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:47:40.207+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:47:40.207+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:47:40.651+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:47:40.683+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:47:40.682+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:47:40.695+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:47:40.695+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:47:40.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.514 seconds
[2026-01-07T16:48:11.106+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:48:11.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:48:11.108+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:48:11.108+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:48:11.566+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:48:11.604+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:48:11.603+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:48:11.619+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:48:11.618+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:48:11.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.744 seconds
[2026-01-07T16:48:42.139+0000] {processor.py:161} INFO - Started process (PID=488) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:48:42.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:48:42.141+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:48:42.141+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:48:42.571+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:48:42.604+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:48:42.603+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:48:42.617+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:48:42.617+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:48:42.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.504 seconds
[2026-01-07T16:49:13.060+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:49:13.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:49:13.062+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:49:13.062+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:49:13.495+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:49:13.532+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:49:13.531+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:49:13.547+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:49:13.546+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:49:13.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.516 seconds
[2026-01-07T16:49:43.967+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:49:43.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:49:43.970+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:49:43.969+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:49:44.414+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:49:44.446+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:49:44.445+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:49:44.460+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:49:44.459+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:49:44.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.517 seconds
[2026-01-07T16:50:14.854+0000] {processor.py:161} INFO - Started process (PID=554) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:50:14.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:50:14.856+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:50:14.856+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:50:15.267+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:50:15.301+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:50:15.301+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:50:15.317+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:50:15.317+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:50:15.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.490 seconds
[2026-01-07T16:50:45.727+0000] {processor.py:161} INFO - Started process (PID=576) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:50:45.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:50:45.730+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:50:45.730+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:50:46.191+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:50:46.238+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:50:46.238+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:50:46.258+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:50:46.258+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:50:46.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.567 seconds
[2026-01-07T16:51:16.687+0000] {processor.py:161} INFO - Started process (PID=598) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:51:16.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:51:16.690+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:51:16.689+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:51:17.270+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:51:17.318+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:51:17.317+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:51:17.350+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:51:17.350+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:51:17.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.874 seconds
[2026-01-07T16:51:47.860+0000] {processor.py:161} INFO - Started process (PID=620) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:51:47.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:51:47.863+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:51:47.863+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:51:48.320+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:51:48.362+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:51:48.362+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:51:48.380+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:51:48.379+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:51:48.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.550 seconds
[2026-01-07T16:52:18.791+0000] {processor.py:161} INFO - Started process (PID=642) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:52:18.792+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:52:18.793+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:52:18.793+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:52:19.243+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:52:19.281+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:52:19.280+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:52:19.295+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:52:19.295+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:52:19.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.535 seconds
[2026-01-07T16:52:49.724+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:52:49.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:52:49.726+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:52:49.726+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:52:50.168+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:52:50.202+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:52:50.202+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:52:50.215+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:52:50.215+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:52:50.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.517 seconds
[2026-01-07T16:53:20.632+0000] {processor.py:161} INFO - Started process (PID=686) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:53:20.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:53:20.634+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:53:20.634+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:53:21.048+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:53:21.083+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:53:21.083+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:53:21.098+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:53:21.098+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:53:21.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.492 seconds
[2026-01-07T16:53:51.521+0000] {processor.py:161} INFO - Started process (PID=708) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:53:51.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:53:51.523+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:53:51.523+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:53:51.977+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:53:52.009+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:53:52.009+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:53:52.023+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:53:52.023+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:53:52.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.713 seconds
[2026-01-07T16:54:22.527+0000] {processor.py:161} INFO - Started process (PID=730) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:54:22.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:54:22.530+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:54:22.529+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:54:22.970+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:54:23.005+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:54:23.005+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:54:23.189+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:54:23.189+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:54:23.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.685 seconds
[2026-01-07T16:54:53.496+0000] {processor.py:161} INFO - Started process (PID=752) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:54:53.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:54:53.498+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:54:53.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:54:53.908+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:54:53.942+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:54:53.942+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:54:53.959+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:54:53.959+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:54:53.987+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.495 seconds
[2026-01-07T16:55:24.417+0000] {processor.py:161} INFO - Started process (PID=774) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:55:24.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:55:24.420+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:55:24.420+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:55:24.899+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:55:24.936+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:55:24.935+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:55:24.950+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:55:24.950+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:55:24.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.565 seconds
[2026-01-07T16:55:55.380+0000] {processor.py:161} INFO - Started process (PID=796) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:55:55.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:55:55.382+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:55:55.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:55:55.813+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:55:55.846+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:55:55.846+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:55:55.860+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:55:55.859+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:55:55.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.504 seconds
[2026-01-07T16:56:26.322+0000] {processor.py:161} INFO - Started process (PID=818) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:56:26.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:56:26.324+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:56:26.324+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:56:26.820+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:56:26.851+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:56:26.851+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:56:26.865+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:56:26.865+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:56:26.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.568 seconds
[2026-01-07T16:56:57.286+0000] {processor.py:161} INFO - Started process (PID=840) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:56:57.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:56:57.288+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:56:57.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:56:57.756+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:56:57.794+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:56:57.793+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:56:57.811+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:56:57.810+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:56:58.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.738 seconds
[2026-01-07T16:57:28.311+0000] {processor.py:161} INFO - Started process (PID=862) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:57:28.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:57:28.314+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:57:28.313+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:57:28.786+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:57:28.830+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:57:28.830+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:57:29.013+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:57:29.012+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:57:29.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.729 seconds
[2026-01-07T16:57:59.327+0000] {processor.py:161} INFO - Started process (PID=884) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:57:59.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:57:59.330+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:57:59.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:57:59.821+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:57:59.858+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:57:59.857+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:57:59.871+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:57:59.871+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:57:59.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.569 seconds
[2026-01-07T16:58:30.285+0000] {processor.py:161} INFO - Started process (PID=906) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:58:30.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:58:30.288+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:58:30.287+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:58:30.708+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:58:30.739+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:58:30.739+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:58:30.753+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:58:30.752+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:58:30.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.490 seconds
[2026-01-07T16:59:01.221+0000] {processor.py:161} INFO - Started process (PID=928) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:59:01.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:59:01.224+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:59:01.224+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:59:01.680+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:59:01.715+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:59:01.714+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:59:01.731+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:59:01.731+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:59:01.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.536 seconds
[2026-01-07T16:59:32.157+0000] {processor.py:161} INFO - Started process (PID=950) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:59:32.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T16:59:32.159+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:59:32.159+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:59:32.600+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T16:59:32.640+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:59:32.639+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T16:59:32.655+0000] {logging_mixin.py:188} INFO - [2026-01-07T16:59:32.655+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T16:59:32.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.529 seconds
[2026-01-07T17:00:03.092+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:00:03.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:00:03.095+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:00:03.094+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:00:03.540+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:00:03.571+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:00:03.571+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:00:03.585+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:00:03.585+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:00:03.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.687 seconds
[2026-01-07T17:00:34.091+0000] {processor.py:161} INFO - Started process (PID=994) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:00:34.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:00:34.094+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:00:34.094+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:00:34.531+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:00:34.568+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:00:34.568+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:00:34.584+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:00:34.583+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:00:34.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.524 seconds
[2026-01-07T17:01:05.013+0000] {processor.py:161} INFO - Started process (PID=1016) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:01:05.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:01:05.015+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:01:05.015+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:01:05.440+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:01:05.471+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:01:05.470+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:01:05.483+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:01:05.483+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:01:05.504+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.494 seconds
[2026-01-07T17:01:35.902+0000] {processor.py:161} INFO - Started process (PID=1038) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:01:35.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:01:35.904+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:01:35.904+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:01:36.368+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:01:36.403+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:01:36.402+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:01:36.416+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:01:36.416+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:01:36.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.540 seconds
[2026-01-07T17:02:06.872+0000] {processor.py:161} INFO - Started process (PID=1060) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:02:06.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:02:06.876+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:02:06.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:02:07.323+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:02:07.359+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:02:07.358+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:02:07.373+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:02:07.373+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:02:07.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.530 seconds
[2026-01-07T17:02:37.819+0000] {processor.py:161} INFO - Started process (PID=1082) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:02:37.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:02:37.821+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:02:37.821+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:02:38.265+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:02:38.305+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:02:38.304+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:02:38.326+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:02:38.325+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:02:38.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.738 seconds
[2026-01-07T17:03:08.840+0000] {processor.py:161} INFO - Started process (PID=1104) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:03:08.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:03:08.842+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:03:08.842+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:03:09.323+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:03:09.362+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:03:09.362+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:03:09.381+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:03:09.381+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:03:09.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.573 seconds
[2026-01-07T17:09:04.486+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:09:04.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:09:04.489+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:09:04.488+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:09:05.621+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:09:05.660+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:09:05.659+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:09:05.680+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:09:05.680+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:09:05.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.436 seconds
[2026-01-07T17:09:36.227+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:09:36.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:09:36.230+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:09:36.229+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:09:36.691+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:09:36.724+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:09:36.723+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:09:36.738+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:09:36.738+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:09:36.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.701 seconds
[2026-01-07T17:10:07.247+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:10:07.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:10:07.250+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:10:07.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:10:07.698+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:10:07.733+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:10:07.732+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:10:07.748+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:10:07.748+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:10:07.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.529 seconds
[2026-01-07T17:10:38.169+0000] {processor.py:161} INFO - Started process (PID=268) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:10:38.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:10:38.172+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:10:38.171+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:10:38.622+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:10:38.656+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:10:38.656+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:10:38.667+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:10:38.667+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:10:38.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.527 seconds
[2026-01-07T17:11:09.082+0000] {processor.py:161} INFO - Started process (PID=290) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:11:09.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:11:09.085+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:11:09.084+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:11:09.529+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:11:09.561+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:11:09.561+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:11:09.576+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:11:09.576+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:11:09.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.520 seconds
[2026-01-07T17:11:39.982+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:11:39.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:11:39.985+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:11:39.984+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:11:40.587+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:11:40.619+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:11:40.619+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:11:40.633+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:11:40.633+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:11:40.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.683 seconds
[2026-01-07T17:12:11.097+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:12:11.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:12:11.099+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:12:11.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:12:11.496+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:12:11.528+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:12:11.527+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:12:11.541+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:12:11.541+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:12:11.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.468 seconds
[2026-01-07T17:12:41.963+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:12:41.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:12:41.965+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:12:41.965+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:12:42.393+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:12:42.425+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:12:42.424+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:12:42.442+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:12:42.442+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:12:42.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.510 seconds
[2026-01-07T17:13:12.847+0000] {processor.py:161} INFO - Started process (PID=378) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:13:12.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:13:12.850+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:13:12.849+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:13:13.282+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:13:13.317+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:13:13.317+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:13:13.333+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:13:13.332+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:13:13.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.512 seconds
[2026-01-07T17:13:43.729+0000] {processor.py:161} INFO - Started process (PID=400) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:13:43.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:13:43.731+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:13:43.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:13:44.129+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:13:44.162+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:13:44.161+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:13:44.174+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:13:44.174+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:13:44.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.468 seconds
[2026-01-07T17:14:14.586+0000] {processor.py:161} INFO - Started process (PID=422) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:14:14.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:14:14.588+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:14:14.588+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:14:14.988+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:14:15.019+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:14:15.018+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:14:15.033+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:14:15.032+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:14:15.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.470 seconds
[2026-01-07T17:14:45.454+0000] {processor.py:161} INFO - Started process (PID=444) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:14:45.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:14:45.456+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:14:45.456+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:14:45.846+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:14:45.875+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:14:45.874+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:14:45.887+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:14:45.887+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:14:45.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.455 seconds
[2026-01-07T17:15:16.300+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:15:16.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:15:16.302+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:15:16.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:15:16.707+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:15:16.737+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:15:16.737+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:15:16.749+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:15:16.749+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:15:16.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.622 seconds
[2026-01-07T17:15:47.215+0000] {processor.py:161} INFO - Started process (PID=488) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:15:47.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:15:47.217+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:15:47.217+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:15:47.732+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:15:47.760+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:15:47.760+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:15:47.773+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:15:47.773+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:15:47.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.581 seconds
[2026-01-07T17:16:18.148+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:16:18.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:16:18.150+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:16:18.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:16:18.573+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:16:18.603+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:16:18.602+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:16:18.615+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:16:18.614+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:16:18.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.489 seconds
[2026-01-07T17:16:49.031+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:16:49.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:16:49.033+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:16:49.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:16:49.434+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:16:49.463+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:16:49.463+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:16:49.475+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:16:49.475+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:16:49.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.467 seconds
[2026-01-07T17:17:19.919+0000] {processor.py:161} INFO - Started process (PID=554) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:17:19.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-07T17:17:19.923+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:17:19.922+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:17:20.364+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-07T17:17:20.395+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:17:20.394+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-07T17:17:20.406+0000] {logging_mixin.py:188} INFO - [2026-01-07T17:17:20.405+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-07T17:17:20.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.511 seconds
