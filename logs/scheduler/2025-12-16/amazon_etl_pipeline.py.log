[2025-12-16T09:34:45.007+0000] {processor.py:161} INFO - Started process (PID=822) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:34:45.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:34:45.009+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:34:45.009+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:34:45.037+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:34:45.033+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:34:45.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:34:45.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.059 seconds
[2025-12-16T09:35:15.291+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:35:15.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:35:15.294+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:35:15.294+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:35:15.311+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:35:15.308+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:35:15.313+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:35:15.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.047 seconds
[2025-12-16T09:35:45.585+0000] {processor.py:161} INFO - Started process (PID=842) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:35:45.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:35:45.587+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:35:45.587+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:35:45.602+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:35:45.599+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:35:45.603+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:35:45.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.041 seconds
[2025-12-16T09:36:15.848+0000] {processor.py:161} INFO - Started process (PID=852) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:36:15.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:36:15.851+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:36:15.850+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:36:15.867+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:36:15.864+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:36:15.868+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:36:15.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.067 seconds
[2025-12-16T09:36:46.122+0000] {processor.py:161} INFO - Started process (PID=862) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:36:46.123+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:36:46.124+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:36:46.124+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:36:46.144+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:36:46.139+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:36:46.145+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:36:46.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.054 seconds
[2025-12-16T09:37:16.391+0000] {processor.py:161} INFO - Started process (PID=872) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:37:16.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:37:16.393+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:37:16.393+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:37:16.411+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:37:16.408+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:37:16.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:37:16.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.047 seconds
[2025-12-16T09:37:46.653+0000] {processor.py:161} INFO - Started process (PID=882) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:37:46.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:37:46.657+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:37:46.657+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:37:46.679+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:37:46.675+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:37:46.681+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:37:46.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.082 seconds
[2025-12-16T09:38:16.934+0000] {processor.py:161} INFO - Started process (PID=892) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:38:16.935+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:38:16.936+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:38:16.935+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:38:16.953+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:38:16.950+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:38:16.954+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:38:16.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.065 seconds
[2025-12-16T09:38:47.199+0000] {processor.py:161} INFO - Started process (PID=902) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:38:47.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:38:47.201+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:38:47.201+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:38:47.219+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:38:47.216+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:38:47.220+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:38:47.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.054 seconds
[2025-12-16T09:39:17.452+0000] {processor.py:161} INFO - Started process (PID=912) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:39:17.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:39:17.455+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:39:17.455+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:39:17.470+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:39:17.467+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:39:17.471+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:39:17.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.047 seconds
[2025-12-16T09:39:47.740+0000] {processor.py:161} INFO - Started process (PID=922) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:39:47.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:39:47.743+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:39:47.742+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:39:47.760+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:39:47.757+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from scripts.csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'scripts.csv_to_raw'
[2025-12-16T09:39:47.761+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:39:47.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.067 seconds
[2025-12-16T09:40:02.908+0000] {processor.py:161} INFO - Started process (PID=927) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:40:02.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:40:02.910+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:40:02.910+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:40:02.938+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:40:02.935+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'csv_to_raw'
[2025-12-16T09:40:02.940+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:40:02.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.059 seconds
[2025-12-16T09:40:33.187+0000] {processor.py:161} INFO - Started process (PID=937) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:40:33.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:40:33.189+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:40:33.189+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:40:33.207+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:40:33.203+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 6, in <module>
    from csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'csv_to_raw'
[2025-12-16T09:40:33.208+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:40:33.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.050 seconds
[2025-12-16T09:40:55.420+0000] {processor.py:161} INFO - Started process (PID=947) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:40:55.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:40:55.422+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:40:55.422+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:40:55.454+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:40:55.450+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 5, in <module>
    from csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'csv_to_raw'
[2025-12-16T09:40:55.455+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:40:55.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.082 seconds
[2025-12-16T09:41:25.715+0000] {processor.py:161} INFO - Started process (PID=957) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:41:25.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:41:25.716+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:41:25.716+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:41:25.732+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:41:25.729+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 5, in <module>
    from csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'csv_to_raw'
[2025-12-16T09:41:25.733+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:41:25.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.064 seconds
[2025-12-16T09:41:56.003+0000] {processor.py:161} INFO - Started process (PID=967) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:41:56.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:41:56.006+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:41:56.006+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:41:56.027+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:41:56.023+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 5, in <module>
    from csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'csv_to_raw'
[2025-12-16T09:41:56.028+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:41:56.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.054 seconds
[2025-12-16T09:42:26.283+0000] {processor.py:161} INFO - Started process (PID=977) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:42:26.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:42:26.285+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:42:26.284+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:42:26.300+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:42:26.297+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/amazon_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/amazon_etl_pipeline.py", line 5, in <module>
    from csv_to_raw import csv_to_raw
ModuleNotFoundError: No module named 'csv_to_raw'
[2025-12-16T09:42:26.301+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:42:26.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.058 seconds
[2025-12-16T09:42:37.435+0000] {processor.py:161} INFO - Started process (PID=982) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:42:37.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:42:37.437+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:42:37.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:42:38.263+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:42:38.871+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:42:38.870+0000] {override.py:1769} INFO - Created Permission View: can read on DAG:amazon_etl_pipeline
[2025-12-16T09:42:38.880+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:42:38.880+0000] {override.py:1769} INFO - Created Permission View: can edit on DAG:amazon_etl_pipeline
[2025-12-16T09:42:38.885+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:42:38.885+0000] {override.py:1769} INFO - Created Permission View: can delete on DAG:amazon_etl_pipeline
[2025-12-16T09:42:38.886+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:42:38.886+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:42:38.897+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:42:38.896+0000] {dag.py:3069} INFO - Creating ORM DAG for amazon_etl_pipeline
[2025-12-16T09:42:38.897+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:42:38.897+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:42:38.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.490 seconds
[2025-12-16T09:43:09.675+0000] {processor.py:161} INFO - Started process (PID=996) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:43:09.677+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:43:09.679+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:43:09.678+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:43:10.087+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:43:10.117+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:43:10.116+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:43:10.130+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:43:10.129+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:43:10.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.480 seconds
[2025-12-16T09:43:40.999+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:43:41.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:43:41.001+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:43:41.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:43:41.391+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:43:41.424+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:43:41.423+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:43:41.438+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:43:41.438+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:43:41.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.646 seconds
[2025-12-16T09:44:12.320+0000] {processor.py:161} INFO - Started process (PID=1018) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:44:12.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:44:12.323+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:44:12.323+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:44:12.680+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:44:12.710+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:44:12.709+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:44:12.885+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:44:12.885+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:44:12.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.585 seconds
[2025-12-16T09:44:43.649+0000] {processor.py:161} INFO - Started process (PID=1029) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:44:43.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:44:43.652+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:44:43.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:44:44.220+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:44:44.253+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:44:44.253+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:44:44.267+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:44:44.267+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:44:44.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.642 seconds
[2025-12-16T09:45:15.002+0000] {processor.py:161} INFO - Started process (PID=1043) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:45:15.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:45:15.004+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:45:15.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:45:15.362+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:45:15.390+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:45:15.390+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:45:15.402+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:45:15.402+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:45:15.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.443 seconds
[2025-12-16T09:45:45.531+0000] {processor.py:161} INFO - Started process (PID=1059) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:45:45.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:45:45.533+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:45:45.533+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:45:45.895+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:45:45.928+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:45:45.927+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:45:45.941+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:45:45.941+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:45:45.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.431 seconds
[2025-12-16T09:46:16.742+0000] {processor.py:161} INFO - Started process (PID=1070) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:46:16.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:46:16.744+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:46:16.744+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:46:17.125+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:46:17.154+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:46:17.153+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:46:17.167+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:46:17.166+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:46:17.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.620 seconds
[2025-12-16T09:46:48.087+0000] {processor.py:161} INFO - Started process (PID=1081) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:46:48.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:46:48.089+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:46:48.089+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:46:48.599+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:46:48.627+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:46:48.626+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:46:48.811+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:46:48.811+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:46:48.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.764 seconds
[2025-12-16T09:47:19.474+0000] {processor.py:161} INFO - Started process (PID=1092) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:47:19.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:47:19.478+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:47:19.477+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:47:19.869+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:47:20.067+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:47:20.066+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:47:20.076+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:47:20.076+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:47:20.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.643 seconds
[2025-12-16T09:47:50.798+0000] {processor.py:161} INFO - Started process (PID=1103) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:47:50.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:47:50.801+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:47:50.800+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:47:51.162+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:47:51.191+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:47:51.191+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:47:51.203+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:47:51.203+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:47:51.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.428 seconds
[2025-12-16T09:48:21.307+0000] {processor.py:161} INFO - Started process (PID=1114) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:48:21.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:48:21.309+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:48:21.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:48:21.695+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:48:21.726+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:48:21.725+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:48:21.739+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:48:21.739+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:48:21.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.472 seconds
[2025-12-16T09:48:52.511+0000] {processor.py:161} INFO - Started process (PID=1125) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:48:52.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:48:52.513+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:48:52.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:48:52.888+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:48:52.919+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:48:52.918+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:48:52.932+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:48:52.932+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:48:52.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.464 seconds
[2025-12-16T09:49:23.854+0000] {processor.py:161} INFO - Started process (PID=1136) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:49:23.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:49:23.857+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:49:23.857+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:49:24.244+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:49:24.278+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:49:24.278+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:49:24.297+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:49:24.296+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:49:24.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.615 seconds
[2025-12-16T09:49:55.209+0000] {processor.py:161} INFO - Started process (PID=1147) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:49:55.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:49:55.211+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:49:55.211+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:49:55.581+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:49:55.610+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:49:55.610+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:49:55.790+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:49:55.789+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:49:55.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.603 seconds
[2025-12-16T09:50:26.574+0000] {processor.py:161} INFO - Started process (PID=1158) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:50:26.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:50:26.576+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:50:26.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:50:26.938+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:50:27.129+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:50:27.129+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:50:27.139+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:50:27.139+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:50:27.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.586 seconds
[2025-12-16T09:50:57.906+0000] {processor.py:161} INFO - Started process (PID=1169) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:50:57.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:50:57.909+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:50:57.909+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:50:58.268+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:50:58.294+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:50:58.294+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:50:58.307+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:50:58.307+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:50:58.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.422 seconds
[2025-12-16T09:51:28.377+0000] {processor.py:161} INFO - Started process (PID=1180) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:51:28.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:51:28.379+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:51:28.379+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:51:28.748+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:51:28.777+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:51:28.777+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:51:28.789+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:51:28.789+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:51:28.805+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.431 seconds
[2025-12-16T09:51:59.575+0000] {processor.py:161} INFO - Started process (PID=1191) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:51:59.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:51:59.577+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:51:59.577+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:51:59.951+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:51:59.977+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:51:59.977+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:51:59.989+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:51:59.988+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:52:00.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.597 seconds
[2025-12-16T09:52:30.904+0000] {processor.py:161} INFO - Started process (PID=1202) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:52:30.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:52:30.906+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:52:30.906+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:52:31.258+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:52:31.287+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:52:31.287+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:52:31.467+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:52:31.467+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:52:31.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.583 seconds
[2025-12-16T09:53:02.234+0000] {processor.py:161} INFO - Started process (PID=1213) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:53:02.235+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:53:02.235+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:53:02.235+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:53:02.564+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:53:02.742+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:53:02.742+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:53:02.752+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:53:02.751+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:53:02.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.560 seconds
[2025-12-16T09:53:33.563+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:53:33.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:53:33.565+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:53:33.565+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:53:33.917+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:53:33.946+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:53:33.946+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:53:33.959+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:53:33.958+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:53:33.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.435 seconds
[2025-12-16T09:54:04.879+0000] {processor.py:161} INFO - Started process (PID=1235) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:54:04.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:54:04.881+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:54:04.880+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:54:05.223+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:54:05.252+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:54:05.252+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:54:05.265+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:54:05.265+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:54:05.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.416 seconds
[2025-12-16T09:54:35.358+0000] {processor.py:161} INFO - Started process (PID=1246) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:54:35.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:54:35.360+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:54:35.359+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:54:35.717+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:54:35.745+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:54:35.745+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:54:35.757+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:54:35.757+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:54:35.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.441 seconds
[2025-12-16T09:55:06.598+0000] {processor.py:161} INFO - Started process (PID=1257) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:55:06.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:55:06.601+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:55:06.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:55:07.041+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:55:07.071+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:55:07.071+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:55:07.085+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:55:07.084+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:55:07.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.690 seconds
[2025-12-16T09:55:37.928+0000] {processor.py:161} INFO - Started process (PID=1268) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:55:37.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:55:37.930+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:55:37.930+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:55:38.279+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:55:38.310+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:55:38.309+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:55:38.491+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:55:38.491+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:55:38.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.588 seconds
[2025-12-16T09:56:09.261+0000] {processor.py:161} INFO - Started process (PID=1279) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:56:09.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:56:09.263+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:56:09.263+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:56:09.621+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:56:09.816+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:56:09.816+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:56:09.832+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:56:09.831+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:56:09.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.618 seconds
[2025-12-16T09:56:40.581+0000] {processor.py:161} INFO - Started process (PID=1290) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:56:40.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:56:40.584+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:56:40.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:56:40.921+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:56:40.949+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:56:40.948+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:56:40.963+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:56:40.963+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:56:40.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.403 seconds
[2025-12-16T09:57:11.910+0000] {processor.py:161} INFO - Started process (PID=1301) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:57:11.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:57:11.912+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:57:11.912+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:57:12.271+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:57:12.298+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:57:12.298+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:57:12.311+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:57:12.311+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:57:12.329+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.422 seconds
[2025-12-16T09:57:43.241+0000] {processor.py:161} INFO - Started process (PID=1312) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:57:43.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:57:43.243+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:57:43.242+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:57:43.602+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:57:43.632+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:57:43.631+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:57:43.643+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:57:43.643+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:57:43.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.427 seconds
[2025-12-16T09:58:14.575+0000] {processor.py:161} INFO - Started process (PID=1323) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:58:14.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:58:14.578+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:58:14.577+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:58:14.922+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:58:14.951+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:58:14.951+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:58:14.963+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:58:14.963+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:58:15.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.558 seconds
[2025-12-16T09:58:45.917+0000] {processor.py:161} INFO - Started process (PID=1334) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:58:45.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:58:45.919+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:58:45.919+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:58:46.265+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:58:46.447+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:58:46.447+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:58:46.457+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:58:46.457+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:58:46.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.558 seconds
[2025-12-16T09:59:17.233+0000] {processor.py:161} INFO - Started process (PID=1345) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:59:17.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:59:17.235+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:59:17.235+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:59:17.645+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:59:17.678+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:59:17.677+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:59:17.691+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:59:17.691+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:59:17.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.486 seconds
[2025-12-16T09:59:48.568+0000] {processor.py:161} INFO - Started process (PID=1356) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:59:48.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T09:59:48.571+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:59:48.571+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:59:48.929+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T09:59:48.959+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:59:48.958+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T09:59:48.972+0000] {logging_mixin.py:188} INFO - [2025-12-16T09:59:48.972+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T09:59:49.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.438 seconds
[2025-12-16T10:00:19.851+0000] {processor.py:161} INFO - Started process (PID=1367) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:00:19.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:00:19.853+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:00:19.853+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:00:20.223+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:00:20.250+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:00:20.249+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:00:20.261+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:00:20.261+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:00:20.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.450 seconds
[2025-12-16T10:00:51.176+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:00:51.177+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:00:51.178+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:00:51.178+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:00:51.516+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:00:51.545+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:00:51.545+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:00:51.559+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:00:51.559+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:00:51.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.578 seconds
[2025-12-16T10:01:22.509+0000] {processor.py:161} INFO - Started process (PID=1389) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:01:22.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:01:22.511+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:01:22.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:01:22.850+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:01:22.879+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:01:22.878+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:01:23.043+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:01:23.042+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:01:23.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.560 seconds
[2025-12-16T10:01:53.855+0000] {processor.py:161} INFO - Started process (PID=1400) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:01:53.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:01:53.858+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:01:53.857+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:01:54.331+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:01:54.579+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:01:54.579+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:01:54.592+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:01:54.591+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:01:54.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.761 seconds
[2025-12-16T10:02:25.193+0000] {processor.py:161} INFO - Started process (PID=1411) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:02:25.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:02:25.195+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:02:25.194+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:02:25.542+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:02:25.569+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:02:25.569+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:02:25.581+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:02:25.581+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:02:25.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.410 seconds
[2025-12-16T10:02:56.524+0000] {processor.py:161} INFO - Started process (PID=1422) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:02:56.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:02:56.527+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:02:56.527+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:02:56.982+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:02:57.024+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:02:57.023+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:02:57.042+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:02:57.041+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:02:57.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.568 seconds
[2025-12-16T10:03:27.931+0000] {processor.py:161} INFO - Started process (PID=1438) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:03:27.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:03:27.934+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:03:27.934+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:03:28.275+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:03:28.303+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:03:28.303+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:03:28.316+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:03:28.316+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:03:28.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.428 seconds
[2025-12-16T10:03:58.423+0000] {processor.py:161} INFO - Started process (PID=1449) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:03:58.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:03:58.426+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:03:58.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:03:58.814+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:03:58.847+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:03:58.846+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:03:58.861+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:03:58.861+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:03:59.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.634 seconds
[2025-12-16T10:05:14.093+0000] {processor.py:161} INFO - Started process (PID=193) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:05:14.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:05:14.097+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:05:14.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:05:15.721+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:05:15.766+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:05:15.765+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:05:15.779+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:05:15.779+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:05:15.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.715 seconds
[2025-12-16T10:05:46.598+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:05:46.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:05:46.601+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:05:46.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:05:46.959+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:05:46.988+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:05:46.988+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:05:47.001+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:05:47.001+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:05:47.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.424 seconds
[2025-12-16T10:06:17.101+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:06:17.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:06:17.105+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:06:17.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:06:17.471+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:06:17.504+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:06:17.503+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:06:17.517+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:06:17.517+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:06:17.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.442 seconds
[2025-12-16T10:06:48.326+0000] {processor.py:161} INFO - Started process (PID=233) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:06:48.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:06:48.330+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:06:48.330+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:06:48.760+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:06:48.792+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:06:48.792+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:06:48.807+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:06:48.807+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:06:48.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.525 seconds
[2025-12-16T10:07:18.917+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:07:18.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:07:18.921+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:07:18.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:07:19.612+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:07:19.683+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:07:19.682+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:07:19.708+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:07:19.708+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:07:19.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.828 seconds
[2025-12-16T10:07:49.989+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:07:49.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:07:49.992+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:07:49.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:07:50.475+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:07:50.514+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:07:50.513+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:07:50.540+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:07:50.540+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:07:50.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.596 seconds
[2025-12-16T10:08:21.400+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:08:21.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:08:21.404+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:08:21.403+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:08:21.902+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:08:21.939+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:08:21.939+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:08:21.956+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:08:21.955+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:08:21.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.583 seconds
[2025-12-16T10:08:52.781+0000] {processor.py:161} INFO - Started process (PID=281) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:08:52.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:08:52.784+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:08:52.784+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:08:53.110+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:08:53.140+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:08:53.140+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:08:53.153+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:08:53.152+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:08:53.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.404 seconds
[2025-12-16T10:09:23.249+0000] {processor.py:161} INFO - Started process (PID=292) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:09:23.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:09:23.252+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:09:23.251+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:09:23.610+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:09:23.639+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:09:23.638+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:09:23.650+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:09:23.650+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:09:23.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.446 seconds
[2025-12-16T10:09:54.457+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:09:54.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:09:54.459+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:09:54.459+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:09:54.799+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:09:54.830+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:09:54.829+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:09:54.844+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:09:54.844+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:09:54.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.407 seconds
[2025-12-16T10:10:24.931+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:10:24.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:10:24.933+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:10:24.933+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:10:25.322+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:10:25.355+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:10:25.355+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:10:25.370+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:10:25.369+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:10:25.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.463 seconds
[2025-12-16T10:10:56.138+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:10:56.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:10:56.139+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:10:56.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:10:56.507+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:10:56.536+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:10:56.536+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:10:56.548+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:10:56.548+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:10:56.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.451 seconds
[2025-12-16T10:11:27.480+0000] {processor.py:161} INFO - Started process (PID=339) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:11:27.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:11:27.482+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:11:27.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:11:27.851+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:11:27.881+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:11:27.880+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:11:27.893+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:11:27.893+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:11:27.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.437 seconds
[2025-12-16T10:11:58.834+0000] {processor.py:161} INFO - Started process (PID=350) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:11:58.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:11:58.836+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:11:58.836+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:11:59.170+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:11:59.197+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:11:59.196+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:11:59.208+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:11:59.208+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:11:59.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.414 seconds
[2025-12-16T10:12:30.176+0000] {processor.py:161} INFO - Started process (PID=361) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:12:30.177+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:12:30.178+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:12:30.178+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:12:30.644+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:12:30.687+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:12:30.687+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:12:30.702+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:12:30.701+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:12:30.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.558 seconds
[2025-12-16T10:13:01.487+0000] {processor.py:161} INFO - Started process (PID=372) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:13:01.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:13:01.489+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:13:01.489+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:13:01.848+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:13:01.881+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:13:01.881+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:13:01.896+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:13:01.895+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:13:01.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.432 seconds
[2025-12-16T10:13:31.994+0000] {processor.py:161} INFO - Started process (PID=383) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:13:31.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:13:31.997+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:13:31.996+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:13:32.360+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:13:32.400+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:13:32.399+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:13:32.418+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:13:32.418+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:13:32.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.464 seconds
[2025-12-16T10:14:03.220+0000] {processor.py:161} INFO - Started process (PID=394) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:14:03.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:14:03.223+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:14:03.222+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:14:03.632+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:14:03.667+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:14:03.667+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:14:03.683+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:14:03.683+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:14:03.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.489 seconds
[2025-12-16T10:14:34.570+0000] {processor.py:161} INFO - Started process (PID=408) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:14:34.572+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:14:34.574+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:14:34.574+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:14:35.035+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:14:35.074+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:14:35.074+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:14:35.091+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:14:35.090+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:14:35.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.554 seconds
[2025-12-16T10:15:05.954+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:15:05.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:15:05.957+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:15:05.957+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:15:06.454+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:15:06.515+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:15:06.514+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:15:06.543+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:15:06.543+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:15:06.583+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.633 seconds
[2025-12-16T10:15:37.375+0000] {processor.py:161} INFO - Started process (PID=430) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:15:37.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:15:37.378+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:15:37.378+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:15:37.871+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:15:37.911+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:15:37.910+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:15:37.929+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:15:37.929+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:15:37.956+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.587 seconds
[2025-12-16T10:16:08.765+0000] {processor.py:161} INFO - Started process (PID=444) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:16:08.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:16:08.767+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:16:08.767+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:16:09.137+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:16:09.167+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:16:09.166+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:16:09.179+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:16:09.179+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:16:09.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.438 seconds
[2025-12-16T10:16:39.268+0000] {processor.py:161} INFO - Started process (PID=455) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:16:39.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:16:39.271+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:16:39.270+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:16:39.667+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:16:39.706+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:16:39.705+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:16:39.721+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:16:39.721+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:16:39.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.485 seconds
[2025-12-16T10:17:10.484+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:17:10.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:17:10.486+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:17:10.486+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:17:10.840+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:17:10.870+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:17:10.869+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:17:10.875+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:17:10.875+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:17:10.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.441 seconds
[2025-12-16T10:17:41.802+0000] {processor.py:161} INFO - Started process (PID=477) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:17:41.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:17:41.804+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:17:41.804+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:17:42.178+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:17:42.208+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:17:42.207+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:17:42.222+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:17:42.222+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:17:42.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.462 seconds
[2025-12-16T10:18:13.161+0000] {processor.py:161} INFO - Started process (PID=491) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:18:13.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:18:13.164+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:18:13.163+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:18:13.538+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:18:13.571+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:18:13.570+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:18:13.585+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:18:13.585+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:18:13.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.449 seconds
[2025-12-16T10:18:44.501+0000] {processor.py:161} INFO - Started process (PID=502) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:18:44.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:18:44.503+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:18:44.503+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:18:44.866+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:18:44.905+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:18:44.905+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:18:44.924+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:18:44.924+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:18:44.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.468 seconds
[2025-12-16T10:19:15.820+0000] {processor.py:161} INFO - Started process (PID=513) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:19:15.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:19:15.822+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:19:15.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:19:16.224+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:19:16.256+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:19:16.255+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:19:16.268+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:19:16.268+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:19:16.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.489 seconds
[2025-12-16T10:19:47.165+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:19:47.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:19:47.168+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:19:47.167+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:19:47.631+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:19:47.663+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:19:47.663+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:19:47.677+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:19:47.677+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:19:47.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.535 seconds
[2025-12-16T10:20:18.524+0000] {processor.py:161} INFO - Started process (PID=535) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:20:18.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:20:18.526+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:20:18.525+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:20:18.909+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:20:18.939+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:20:18.938+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:20:18.951+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:20:18.951+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:20:18.970+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.450 seconds
[2025-12-16T10:20:49.819+0000] {processor.py:161} INFO - Started process (PID=546) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:20:49.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:20:49.821+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:20:49.821+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:20:50.170+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:20:50.206+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:20:50.205+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:20:50.229+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:20:50.228+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:20:50.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.447 seconds
[2025-12-16T10:21:21.158+0000] {processor.py:161} INFO - Started process (PID=557) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:21:21.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:21:21.160+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:21:21.160+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:21:21.516+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:21:21.546+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:21:21.546+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:21:21.560+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:21:21.559+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:21:21.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.428 seconds
[2025-12-16T10:21:51.654+0000] {processor.py:161} INFO - Started process (PID=568) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:21:51.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:21:51.657+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:21:51.657+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:21:52.023+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:21:52.052+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:21:52.052+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:21:52.065+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:21:52.065+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:21:52.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.451 seconds
[2025-12-16T10:22:22.862+0000] {processor.py:161} INFO - Started process (PID=579) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:22:22.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:22:22.864+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:22:22.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:22:23.211+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:22:23.244+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:22:23.243+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:22:23.257+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:22:23.256+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:22:23.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.440 seconds
[2025-12-16T10:22:54.191+0000] {processor.py:161} INFO - Started process (PID=590) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:22:54.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:22:54.193+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:22:54.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:22:54.541+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:22:54.569+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:22:54.569+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:22:54.581+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:22:54.581+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:22:54.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.432 seconds
[2025-12-16T10:23:25.508+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:23:25.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:23:25.511+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:23:25.510+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:23:25.880+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:23:25.907+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:23:25.907+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:23:25.918+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:23:25.918+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:23:25.955+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.451 seconds
[2025-12-16T10:23:56.814+0000] {processor.py:161} INFO - Started process (PID=612) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:23:56.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:23:56.818+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:23:56.817+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:23:57.222+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:23:57.252+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:23:57.251+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:23:57.263+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:23:57.263+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:23:57.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.478 seconds
[2025-12-16T10:24:27.374+0000] {processor.py:161} INFO - Started process (PID=628) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:24:27.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:24:27.376+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:24:27.376+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:24:27.730+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:24:27.756+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:24:27.755+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:24:27.767+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:24:27.767+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:24:27.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.592 seconds
[2025-12-16T10:24:58.579+0000] {processor.py:161} INFO - Started process (PID=639) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:24:58.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:24:58.582+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:24:58.581+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:24:58.939+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:24:58.969+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:24:58.969+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:24:58.984+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:24:58.984+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:24:59.013+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.438 seconds
[2025-12-16T10:25:29.081+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:25:29.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:25:29.084+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:25:29.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:25:29.436+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:25:29.469+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:25:29.469+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:25:29.494+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:25:29.494+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:25:29.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.443 seconds
[2025-12-16T10:26:00.291+0000] {processor.py:161} INFO - Started process (PID=661) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:26:00.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:26:00.294+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:26:00.294+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:26:00.624+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:26:00.651+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:26:00.651+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:26:00.664+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:26:00.663+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:26:00.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.407 seconds
[2025-12-16T10:26:30.772+0000] {processor.py:161} INFO - Started process (PID=672) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:26:30.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:26:30.774+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:26:30.773+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:26:31.299+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:26:31.327+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:26:31.327+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:26:31.339+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:26:31.339+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:26:31.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.587 seconds
[2025-12-16T10:27:01.981+0000] {processor.py:161} INFO - Started process (PID=683) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:27:01.982+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:27:01.983+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:27:01.982+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:27:02.359+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:27:02.387+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:27:02.387+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:27:02.399+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:27:02.399+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:27:02.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.440 seconds
[2025-12-16T10:27:33.316+0000] {processor.py:161} INFO - Started process (PID=694) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:27:33.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:27:33.319+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:27:33.318+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:27:33.708+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:27:33.737+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:27:33.737+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:27:33.752+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:27:33.752+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:27:33.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.464 seconds
[2025-12-16T10:28:04.657+0000] {processor.py:161} INFO - Started process (PID=705) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:28:04.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:28:04.660+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:28:04.659+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:28:05.010+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:28:05.040+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:28:05.040+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:28:05.053+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:28:05.052+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:28:05.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.437 seconds
[2025-12-16T10:28:35.157+0000] {processor.py:161} INFO - Started process (PID=716) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:28:35.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:28:35.159+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:28:35.159+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:28:35.577+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:28:35.608+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:28:35.608+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:28:35.622+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:28:35.621+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:28:35.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.487 seconds
[2025-12-16T10:29:06.351+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:29:06.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:29:06.353+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:29:06.353+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:29:06.736+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:29:06.763+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:29:06.762+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:29:06.776+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:29:06.776+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:29:06.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.465 seconds
[2025-12-16T10:29:37.695+0000] {processor.py:161} INFO - Started process (PID=738) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:29:37.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:29:37.698+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:29:37.698+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:29:38.032+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:29:38.059+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:29:38.059+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:29:38.070+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:29:38.070+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:29:38.107+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.415 seconds
[2025-12-16T10:30:09.031+0000] {processor.py:161} INFO - Started process (PID=749) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:30:09.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:30:09.033+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:30:09.033+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:30:09.364+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:30:09.391+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:30:09.390+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:30:09.402+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:30:09.402+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:30:09.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.414 seconds
[2025-12-16T10:30:39.531+0000] {processor.py:161} INFO - Started process (PID=760) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:30:39.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:30:39.533+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:30:39.533+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:30:39.881+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:30:39.912+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:30:39.912+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:30:39.927+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:30:39.926+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:30:39.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.417 seconds
[2025-12-16T10:31:10.748+0000] {processor.py:161} INFO - Started process (PID=771) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:31:10.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:31:10.750+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:31:10.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:31:11.093+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:31:11.122+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:31:11.122+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:31:11.133+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:31:11.133+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:31:11.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.426 seconds
[2025-12-16T10:31:41.223+0000] {processor.py:161} INFO - Started process (PID=782) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:31:41.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:31:41.225+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:31:41.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:31:41.608+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:31:41.639+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:31:41.639+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:31:41.651+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:31:41.651+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:31:41.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.451 seconds
[2025-12-16T10:32:12.434+0000] {processor.py:161} INFO - Started process (PID=793) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:32:12.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:32:12.436+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:32:12.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:32:12.830+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:32:12.873+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:32:12.872+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:32:12.887+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:32:12.887+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:32:12.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.477 seconds
[2025-12-16T10:32:43.812+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:32:43.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:32:43.814+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:32:43.814+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:32:44.217+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:32:44.246+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:32:44.246+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:32:44.259+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:32:44.258+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:32:44.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.472 seconds
[2025-12-16T10:33:15.120+0000] {processor.py:161} INFO - Started process (PID=815) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:33:15.122+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:33:15.123+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:33:15.123+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:33:15.684+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:33:15.721+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:33:15.721+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:33:15.737+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:33:15.737+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:33:15.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.816 seconds
[2025-12-16T10:33:46.447+0000] {processor.py:161} INFO - Started process (PID=826) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:33:46.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:33:46.449+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:33:46.449+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:33:46.881+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:33:46.916+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:33:46.916+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:33:46.929+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:33:46.929+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:33:46.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.508 seconds
[2025-12-16T10:34:17.833+0000] {processor.py:161} INFO - Started process (PID=837) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:34:17.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:34:17.835+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:34:17.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:34:18.250+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:34:18.281+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:34:18.281+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:34:18.295+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:34:18.295+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:34:18.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.485 seconds
[2025-12-16T10:34:48.398+0000] {processor.py:161} INFO - Started process (PID=848) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:34:48.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:34:48.400+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:34:48.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:34:48.905+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:34:48.945+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:34:48.945+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:34:48.960+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:34:48.960+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:34:48.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.587 seconds
[2025-12-16T10:35:19.653+0000] {processor.py:161} INFO - Started process (PID=859) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:35:19.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:35:19.655+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:35:19.655+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:35:20.064+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:35:20.098+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:35:20.097+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:35:20.113+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:35:20.113+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:35:20.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.487 seconds
[2025-12-16T10:35:50.986+0000] {processor.py:161} INFO - Started process (PID=870) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:35:50.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:35:50.989+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:35:50.989+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:35:51.637+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:35:51.677+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:35:51.676+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:35:51.691+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:35:51.690+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:35:51.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.732 seconds
[2025-12-16T10:36:22.344+0000] {processor.py:161} INFO - Started process (PID=881) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:36:22.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:36:22.347+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:36:22.347+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:36:22.775+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:36:22.808+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:36:22.807+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:36:22.823+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:36:22.823+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:36:23.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.678 seconds
[2025-12-16T10:36:53.681+0000] {processor.py:161} INFO - Started process (PID=892) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:36:53.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:36:53.683+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:36:53.683+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:36:54.120+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:36:54.155+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:36:54.154+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:36:54.171+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:36:54.171+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:36:54.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.521 seconds
[2025-12-16T10:37:25.085+0000] {processor.py:161} INFO - Started process (PID=967) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:37:25.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:37:25.093+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:37:25.092+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:38:34.743+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:38:34.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:38:34.754+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:38:34.754+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:38:36.945+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:38:36.998+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:38:36.998+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:38:37.015+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:38:37.015+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:38:37.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 2.306 seconds
[2025-12-16T10:39:07.315+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:39:07.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:39:07.319+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:39:07.318+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:39:07.793+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:39:07.829+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:39:07.828+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:39:07.846+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:39:07.845+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:39:07.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.563 seconds
[2025-12-16T10:39:38.731+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:39:38.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:39:38.744+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:39:38.743+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:39:39.267+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:39:39.306+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:39:39.305+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:39:39.324+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:39:39.323+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:39:39.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.629 seconds
[2025-12-16T10:40:10.152+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:40:10.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:40:10.155+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:40:10.155+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:40:10.747+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:40:10.809+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:40:10.808+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:40:10.840+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:40:10.840+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:40:10.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.730 seconds
[2025-12-16T10:40:41.551+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:40:41.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:40:41.554+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:40:41.554+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:40:42.093+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:40:42.139+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:40:42.138+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:40:42.158+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:40:42.157+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:40:42.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.643 seconds
[2025-12-16T10:41:12.980+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:41:12.982+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:41:12.984+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:41:12.984+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:41:13.538+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:41:13.574+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:41:13.573+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:41:13.589+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:41:13.588+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:41:13.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.640 seconds
[2025-12-16T10:41:44.396+0000] {processor.py:161} INFO - Started process (PID=271) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:41:44.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:41:44.398+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:41:44.398+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:41:44.927+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:41:44.976+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:41:44.976+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:41:44.997+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:41:44.996+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:41:45.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.640 seconds
[2025-12-16T10:42:15.729+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:42:15.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:42:15.732+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:42:15.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:42:16.192+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:42:16.229+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:42:16.229+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:42:16.246+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:42:16.246+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:42:16.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.567 seconds
[2025-12-16T10:42:47.091+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:42:47.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:42:47.093+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:42:47.093+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:42:47.510+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:42:47.546+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:42:47.546+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:42:47.562+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:42:47.561+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:42:47.586+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.499 seconds
[2025-12-16T10:43:18.443+0000] {processor.py:161} INFO - Started process (PID=304) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:43:18.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:43:18.447+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:43:18.446+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:43:18.924+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:43:18.961+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:43:18.961+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:43:18.979+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:43:18.979+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:43:19.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.565 seconds
[2025-12-16T10:43:49.832+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:43:49.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:43:49.835+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:43:49.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:43:50.282+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:43:50.313+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:43:50.313+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:43:50.328+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:43:50.327+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:43:50.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.521 seconds
[2025-12-16T10:44:21.221+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:44:21.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:44:21.224+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:44:21.223+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:44:21.682+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:44:21.719+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:44:21.719+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:44:21.735+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:44:21.735+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:44:21.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.541 seconds
[2025-12-16T10:44:52.605+0000] {processor.py:161} INFO - Started process (PID=340) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:44:52.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:44:52.609+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:44:52.608+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:44:53.104+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:44:53.145+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:44:53.144+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:44:53.162+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:44:53.161+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:44:53.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.587 seconds
[2025-12-16T10:45:23.994+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:45:23.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:45:23.997+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:45:23.996+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:45:24.434+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:45:24.469+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:45:24.469+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:45:24.485+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:45:24.485+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:45:24.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.521 seconds
[2025-12-16T10:45:55.403+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:45:55.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:45:55.406+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:45:55.405+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:45:55.850+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:45:55.886+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:45:55.886+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:45:55.902+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:45:55.902+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:45:55.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.530 seconds
[2025-12-16T10:46:26.762+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:46:26.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:46:26.765+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:46:26.765+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:46:27.227+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:46:27.261+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:46:27.260+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:46:27.279+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:46:27.278+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:46:27.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.547 seconds
[2025-12-16T10:46:58.108+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:46:58.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:46:58.112+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:46:58.111+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:46:58.519+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:46:58.552+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:46:58.551+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:46:58.565+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:46:58.565+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:46:58.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.499 seconds
[2025-12-16T10:47:29.487+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:47:29.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:47:29.489+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:47:29.489+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:47:29.926+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:47:29.959+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:47:29.959+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:47:29.976+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:47:29.976+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:47:30.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.519 seconds
[2025-12-16T10:48:00.815+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:48:00.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:48:00.818+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:48:00.817+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:48:01.273+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:48:01.305+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:48:01.304+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:48:01.319+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:48:01.319+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:48:01.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.529 seconds
[2025-12-16T10:48:32.177+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:48:32.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:48:32.180+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:48:32.180+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:48:32.704+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:48:32.747+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:48:32.747+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:48:32.767+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:48:32.766+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:48:32.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.623 seconds
[2025-12-16T10:49:03.521+0000] {processor.py:161} INFO - Started process (PID=428) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:49:03.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:49:03.524+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:49:03.524+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:49:03.941+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:49:03.983+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:49:03.983+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:49:04.003+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:49:04.002+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:49:04.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.514 seconds
[2025-12-16T10:49:34.893+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:49:34.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:49:34.896+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:49:34.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:49:35.366+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:49:35.409+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:49:35.408+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:49:35.424+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:49:35.424+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:49:35.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.559 seconds
[2025-12-16T10:50:06.251+0000] {processor.py:161} INFO - Started process (PID=450) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:50:06.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:50:06.253+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:50:06.253+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:50:06.645+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:50:06.675+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:50:06.674+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:50:06.688+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:50:06.687+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:50:06.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.465 seconds
[2025-12-16T10:50:37.587+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:50:37.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:50:37.589+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:50:37.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:50:38.038+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:50:38.070+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:50:38.069+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:50:38.083+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:50:38.083+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:50:38.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.545 seconds
[2025-12-16T10:51:08.913+0000] {processor.py:161} INFO - Started process (PID=472) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:51:08.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:51:08.915+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:51:08.915+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:51:09.316+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:51:09.349+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:51:09.349+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:51:09.364+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:51:09.363+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:51:09.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.477 seconds
[2025-12-16T10:51:40.255+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:51:40.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:51:40.258+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:51:40.257+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:51:40.912+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:51:40.953+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:51:40.952+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:51:40.970+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:51:40.970+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:51:40.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.748 seconds
[2025-12-16T10:52:11.565+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:52:11.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:52:11.567+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:52:11.567+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:52:11.973+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:52:12.004+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:52:12.004+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:52:12.018+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:52:12.018+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:52:12.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.495 seconds
[2025-12-16T10:52:42.891+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:52:42.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:52:42.894+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:52:42.893+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:52:43.344+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:52:43.383+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:52:43.382+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:52:43.398+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:52:43.398+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:52:43.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.535 seconds
[2025-12-16T10:54:52.588+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:54:52.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:54:52.593+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:54:52.593+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:54:54.387+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:54:54.432+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:54:54.432+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:54:54.447+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:54:54.447+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:54:54.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.914 seconds
[2025-12-16T10:55:25.040+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:55:25.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:55:25.043+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:55:25.043+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:55:25.439+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:55:25.471+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:55:25.471+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:55:25.486+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:55:25.486+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:55:25.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.472 seconds
[2025-12-16T10:55:56.371+0000] {processor.py:161} INFO - Started process (PID=221) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:55:56.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:55:56.374+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:55:56.373+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:55:56.775+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:55:56.809+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:55:56.809+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:55:56.824+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:55:56.824+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:55:56.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.484 seconds
[2025-12-16T10:56:27.709+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:56:27.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:56:27.711+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:56:27.711+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:56:28.196+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:56:28.233+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:56:28.232+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:56:28.248+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:56:28.247+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:56:28.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.561 seconds
[2025-12-16T10:56:59.036+0000] {processor.py:161} INFO - Started process (PID=243) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:56:59.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:56:59.038+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:56:59.038+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:56:59.414+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:56:59.449+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:56:59.448+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:56:59.465+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:56:59.464+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:56:59.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.454 seconds
[2025-12-16T10:57:30.374+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:57:30.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:57:30.377+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:57:30.376+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:57:30.756+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:57:30.789+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:57:30.789+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:57:30.803+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:57:30.803+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:57:30.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.456 seconds
[2025-12-16T10:58:01.693+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:58:01.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:58:01.695+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:58:01.695+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:58:02.094+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:58:02.125+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:58:02.124+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:58:02.138+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:58:02.138+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:58:02.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.468 seconds
[2025-12-16T10:58:32.230+0000] {processor.py:161} INFO - Started process (PID=276) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:58:32.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:58:32.233+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:58:32.233+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:58:32.662+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:58:32.695+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:58:32.694+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:58:32.709+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:58:32.708+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:58:32.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.507 seconds
[2025-12-16T10:59:03.475+0000] {processor.py:161} INFO - Started process (PID=290) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:59:03.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:59:03.479+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:59:03.478+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:59:04.124+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:59:04.169+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:59:04.168+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:59:04.188+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:59:04.188+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:59:04.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.751 seconds
[2025-12-16T10:59:34.855+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:59:34.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T10:59:34.859+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:59:34.859+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:59:35.381+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T10:59:35.427+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:59:35.426+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T10:59:35.452+0000] {logging_mixin.py:188} INFO - [2025-12-16T10:59:35.452+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T10:59:35.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.632 seconds
[2025-12-16T11:00:06.268+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:00:06.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:00:06.271+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:00:06.271+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:00:06.828+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:00:06.871+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:00:06.870+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:00:06.886+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:00:06.886+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:00:06.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.647 seconds
[2025-12-16T11:00:37.706+0000] {processor.py:161} INFO - Started process (PID=323) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:00:37.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:00:37.709+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:00:37.709+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:00:38.250+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:00:38.289+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:00:38.289+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:00:38.314+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:00:38.314+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:00:38.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.654 seconds
[2025-12-16T11:01:09.093+0000] {processor.py:161} INFO - Started process (PID=337) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:01:09.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:01:09.095+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:01:09.095+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:01:09.490+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:01:09.522+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:01:09.522+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:01:09.536+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:01:09.535+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:01:09.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.466 seconds
[2025-12-16T11:01:39.614+0000] {processor.py:161} INFO - Started process (PID=348) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:01:39.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:01:39.617+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:01:39.617+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:01:40.043+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:01:40.083+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:01:40.082+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:01:40.099+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:01:40.098+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:01:40.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.515 seconds
[2025-12-16T11:02:10.818+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:02:10.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:02:10.821+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:02:10.820+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:02:11.250+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:02:11.283+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:02:11.282+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:02:11.296+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:02:11.296+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:02:11.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.509 seconds
[2025-12-16T11:02:42.184+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:02:42.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:02:42.208+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:02:42.207+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:02:42.721+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:02:42.760+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:02:42.759+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:02:42.779+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:02:42.778+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:02:42.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.634 seconds
[2025-12-16T11:03:13.490+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:03:13.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:03:13.492+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:03:13.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:03:13.949+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:03:13.989+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:03:13.988+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:03:14.006+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:03:14.006+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:03:14.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.544 seconds
[2025-12-16T11:03:44.852+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:03:44.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:03:44.855+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:03:44.855+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:03:45.386+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:03:45.422+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:03:45.421+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:03:45.438+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:03:45.438+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:03:45.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.619 seconds
[2025-12-16T11:04:16.197+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:04:16.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:04:16.199+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:04:16.199+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:04:16.617+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:04:16.652+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:04:16.651+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:04:16.668+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:04:16.668+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:04:16.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.500 seconds
[2025-12-16T11:04:46.810+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:04:46.812+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:04:46.813+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:04:46.813+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:04:47.341+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:04:47.389+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:04:47.388+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:04:47.407+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:04:47.406+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:04:47.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.633 seconds
[2025-12-16T11:05:18.065+0000] {processor.py:161} INFO - Started process (PID=428) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:05:18.067+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:05:18.069+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:05:18.068+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:05:18.539+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:05:18.573+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:05:18.573+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:05:18.588+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:05:18.588+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:05:18.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.550 seconds
[2025-12-16T11:05:49.406+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:05:49.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:05:49.409+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:05:49.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:05:49.839+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:05:49.870+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:05:49.869+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:05:49.882+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:05:49.882+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:05:49.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.501 seconds
[2025-12-16T11:06:20.758+0000] {processor.py:161} INFO - Started process (PID=450) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:06:20.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:06:20.761+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:06:20.760+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:06:21.187+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:06:21.221+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:06:21.221+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:06:21.236+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:06:21.235+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:06:21.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.504 seconds
[2025-12-16T11:06:52.080+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:06:52.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:06:52.083+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:06:52.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:06:52.541+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:06:52.581+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:06:52.580+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:06:52.596+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:06:52.596+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:06:52.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.543 seconds
[2025-12-16T11:07:23.417+0000] {processor.py:161} INFO - Started process (PID=472) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:07:23.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:07:23.420+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:07:23.419+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:07:23.850+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:07:23.885+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:07:23.884+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:07:23.900+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:07:23.900+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:07:23.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.510 seconds
[2025-12-16T11:07:54.778+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:07:54.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:07:54.780+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:07:54.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:07:55.187+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:07:55.217+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:07:55.217+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:07:55.231+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:07:55.231+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:07:55.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.477 seconds
[2025-12-16T11:08:26.147+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:08:26.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:08:26.149+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:08:26.149+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:08:26.526+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:08:26.556+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:08:26.555+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:08:26.569+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:08:26.569+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:08:26.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.446 seconds
[2025-12-16T11:08:57.483+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:08:57.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:08:57.486+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:08:57.486+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:08:57.872+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:08:57.905+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:08:57.904+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:08:57.919+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:08:57.919+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:08:57.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.464 seconds
[2025-12-16T11:09:28.830+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:09:28.831+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:09:28.833+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:09:28.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:09:29.357+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:09:29.398+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:09:29.398+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:09:29.417+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:09:29.417+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:09:29.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.620 seconds
[2025-12-16T11:10:00.210+0000] {processor.py:161} INFO - Started process (PID=527) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:10:00.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:10:00.213+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:10:00.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:10:00.635+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:10:00.667+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:10:00.667+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:10:00.681+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:10:00.680+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:10:00.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.495 seconds
[2025-12-16T11:10:31.509+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:10:31.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:10:31.511+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:10:31.510+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:10:31.981+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:10:32.013+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:10:32.013+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:10:32.028+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:10:32.028+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:10:32.050+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.545 seconds
[2025-12-16T11:11:02.839+0000] {processor.py:161} INFO - Started process (PID=549) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:11:02.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:11:02.842+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:11:02.842+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:11:03.235+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:11:03.268+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:11:03.267+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:11:03.281+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:11:03.281+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:11:03.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.465 seconds
[2025-12-16T11:12:02.318+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:12:02.320+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:12:02.325+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:12:02.325+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:12:03.946+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:12:03.989+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:12:03.989+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:12:04.008+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:12:04.008+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:12:04.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.729 seconds
[2025-12-16T11:12:34.792+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:12:34.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:12:34.794+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:12:34.794+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:12:35.268+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:12:35.300+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:12:35.300+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:12:35.314+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:12:35.313+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:12:35.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.548 seconds
[2025-12-16T11:13:06.201+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:13:06.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:13:06.204+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:13:06.203+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:13:06.622+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:13:06.655+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:13:06.654+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:13:06.670+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:13:06.670+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:13:06.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.495 seconds
[2025-12-16T11:13:36.814+0000] {processor.py:161} INFO - Started process (PID=234) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:13:36.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:13:36.819+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:13:36.818+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:13:37.480+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:13:37.530+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:13:37.529+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:13:37.553+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:13:37.553+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:13:37.586+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.781 seconds
[2025-12-16T11:14:07.867+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:14:07.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:14:07.870+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:14:07.870+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:14:08.404+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:14:08.445+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:14:08.444+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:14:08.461+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:14:08.461+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:14:08.487+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.625 seconds
[2025-12-16T11:14:39.288+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:14:39.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:14:39.292+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:14:39.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:14:39.882+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:14:39.925+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:14:39.924+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:14:39.943+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:14:39.943+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:14:39.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.689 seconds
[2025-12-16T11:15:10.700+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:15:10.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:15:10.703+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:15:10.703+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:15:11.202+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:15:11.243+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:15:11.242+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:15:11.260+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:15:11.259+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:15:11.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.593 seconds
[2025-12-16T11:15:42.103+0000] {processor.py:161} INFO - Started process (PID=278) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:15:42.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:15:42.106+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:15:42.106+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:15:42.600+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:15:42.640+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:15:42.639+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:15:42.658+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:15:42.658+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:15:42.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.608 seconds
[2025-12-16T11:16:13.519+0000] {processor.py:161} INFO - Started process (PID=298) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:16:13.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:16:13.522+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:16:13.522+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:16:13.941+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:16:13.971+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:16:13.971+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:16:13.984+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:16:13.983+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:16:14.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.491 seconds
[2025-12-16T11:16:44.110+0000] {processor.py:161} INFO - Started process (PID=309) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:16:44.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:16:44.114+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:16:44.113+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:16:44.586+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:16:44.622+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:16:44.621+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:16:44.638+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:16:44.638+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:16:44.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.555 seconds
[2025-12-16T11:17:15.380+0000] {processor.py:161} INFO - Started process (PID=323) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:17:15.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:17:15.384+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:17:15.384+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:17:15.912+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:17:15.958+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:17:15.957+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:17:15.977+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:17:15.977+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:17:16.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.633 seconds
[2025-12-16T11:17:46.832+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:17:46.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:17:46.836+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:17:46.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:17:47.417+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:17:47.465+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:17:47.465+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:17:47.485+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:17:47.485+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:17:47.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.688 seconds
[2025-12-16T11:18:18.242+0000] {processor.py:161} INFO - Started process (PID=345) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:18:18.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:18:18.245+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:18:18.244+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:18:18.784+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:18:18.825+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:18:18.825+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:18:18.844+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:18:18.844+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:18:18.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.634 seconds
[2025-12-16T11:18:49.634+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:18:49.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:18:49.638+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:18:49.638+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:18:50.188+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:18:50.232+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:18:50.231+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:18:50.253+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:18:50.252+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:18:50.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.654 seconds
[2025-12-16T11:19:21.068+0000] {processor.py:161} INFO - Started process (PID=367) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:19:21.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:19:21.071+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:19:21.071+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:19:21.620+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:19:21.662+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:19:21.662+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:19:21.681+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:19:21.680+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:19:21.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.648 seconds
[2025-12-16T11:19:52.538+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:19:52.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:19:52.542+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:19:52.542+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:19:53.078+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:19:53.126+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:19:53.125+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:19:53.154+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:19:53.154+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:19:53.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.655 seconds
[2025-12-16T11:20:23.898+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:20:23.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:20:23.900+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:20:23.900+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:20:24.301+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:20:24.336+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:20:24.335+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:20:24.350+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:20:24.349+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:20:24.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.476 seconds
[2025-12-16T11:20:55.257+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:20:55.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:20:55.259+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:20:55.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:20:55.727+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:20:55.765+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:20:55.764+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:20:55.780+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:20:55.780+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:20:55.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.552 seconds
[2025-12-16T11:21:26.608+0000] {processor.py:161} INFO - Started process (PID=420) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:21:26.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:21:26.611+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:21:26.610+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:21:27.152+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:21:27.221+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:21:27.219+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:21:27.246+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:21:27.246+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:21:27.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.679 seconds
[2025-12-16T11:21:57.972+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:21:57.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:21:57.976+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:21:57.976+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:21:58.454+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:21:58.488+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:21:58.488+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:21:58.504+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:21:58.503+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:21:58.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.559 seconds
[2025-12-16T11:22:29.342+0000] {processor.py:161} INFO - Started process (PID=442) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:22:29.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:22:29.345+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:22:29.344+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:22:29.768+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:22:29.798+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:22:29.798+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:22:29.814+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:22:29.814+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:22:29.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.497 seconds
[2025-12-16T11:22:59.946+0000] {processor.py:161} INFO - Started process (PID=453) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:22:59.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:22:59.952+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:22:59.951+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:23:00.519+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:23:00.559+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:23:00.558+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:23:00.574+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:23:00.574+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:23:00.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.662 seconds
[2025-12-16T11:23:31.161+0000] {processor.py:161} INFO - Started process (PID=464) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:23:31.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:23:31.164+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:23:31.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:23:31.690+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:23:31.730+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:23:31.730+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:23:31.748+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:23:31.747+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:23:31.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.619 seconds
[2025-12-16T11:24:02.527+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:24:02.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:24:02.530+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:24:02.530+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:24:02.983+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:24:03.017+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:24:03.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:24:03.033+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:24:03.032+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:24:03.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.531 seconds
[2025-12-16T11:24:33.127+0000] {processor.py:161} INFO - Started process (PID=486) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:24:33.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:24:33.129+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:24:33.129+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:24:33.571+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:24:33.608+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:24:33.608+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:24:33.625+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:24:33.624+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:24:33.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.527 seconds
[2025-12-16T11:25:04.333+0000] {processor.py:161} INFO - Started process (PID=497) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:25:04.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:25:04.336+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:25:04.336+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:25:04.748+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:25:04.779+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:25:04.778+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:25:04.793+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:25:04.793+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:25:04.833+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.504 seconds
[2025-12-16T11:25:35.693+0000] {processor.py:161} INFO - Started process (PID=508) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:25:35.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:25:35.696+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:25:35.695+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:25:36.165+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:25:36.201+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:25:36.201+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:25:36.217+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:25:36.217+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:25:36.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.552 seconds
[2025-12-16T11:26:07.017+0000] {processor.py:161} INFO - Started process (PID=519) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:26:07.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:26:07.019+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:26:07.019+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:26:07.446+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:26:07.480+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:26:07.479+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:26:07.495+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:26:07.495+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:26:07.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.506 seconds
[2025-12-16T11:26:38.419+0000] {processor.py:161} INFO - Started process (PID=530) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:26:38.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:26:38.422+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:26:38.422+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:26:38.961+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:26:39.003+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:26:39.003+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:26:39.022+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:26:39.022+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:26:39.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.641 seconds
[2025-12-16T11:27:09.811+0000] {processor.py:161} INFO - Started process (PID=541) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:27:09.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:27:09.814+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:27:09.814+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:27:10.360+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:27:10.430+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:27:10.429+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:27:10.452+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:27:10.452+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:27:10.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.676 seconds
[2025-12-16T11:27:41.182+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:27:41.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:27:41.186+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:27:41.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:27:41.713+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:27:41.749+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:27:41.748+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:27:41.763+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:27:41.763+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:27:41.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.607 seconds
[2025-12-16T11:28:12.548+0000] {processor.py:161} INFO - Started process (PID=563) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:28:12.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:28:12.551+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:28:12.551+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:28:12.980+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:28:13.013+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:28:13.012+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:28:13.027+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:28:13.027+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:28:13.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.508 seconds
[2025-12-16T11:28:43.932+0000] {processor.py:161} INFO - Started process (PID=574) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:28:43.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:28:43.935+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:28:43.935+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:28:44.361+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:28:44.392+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:28:44.391+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:28:44.406+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:28:44.405+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:28:44.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.496 seconds
[2025-12-16T11:29:15.334+0000] {processor.py:161} INFO - Started process (PID=585) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:29:15.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:29:15.337+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:29:15.337+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:29:15.809+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:29:15.844+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:29:15.843+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:29:15.859+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:29:15.858+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:29:15.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.553 seconds
[2025-12-16T11:29:46.746+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:29:46.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:29:46.749+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:29:46.749+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:29:47.340+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:29:47.370+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:29:47.370+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:29:47.383+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:29:47.382+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:29:47.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.658 seconds
[2025-12-16T11:30:18.131+0000] {processor.py:161} INFO - Started process (PID=612) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:30:18.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:30:18.134+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:30:18.134+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:30:18.512+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:30:18.543+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:30:18.543+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:30:18.557+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:30:18.557+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:30:18.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.449 seconds
[2025-12-16T11:30:49.468+0000] {processor.py:161} INFO - Started process (PID=623) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:30:49.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:30:49.470+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:30:49.470+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:30:49.827+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:30:49.860+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:30:49.859+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:30:49.874+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:30:49.873+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:30:49.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.450 seconds
[2025-12-16T11:31:19.980+0000] {processor.py:161} INFO - Started process (PID=634) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:31:19.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:31:19.982+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:31:19.982+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:31:20.404+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:31:20.442+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:31:20.442+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:31:20.456+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:31:20.456+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:31:20.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.703 seconds
[2025-12-16T11:31:51.183+0000] {processor.py:161} INFO - Started process (PID=645) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:31:51.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:31:51.185+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:31:51.185+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:31:51.582+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:31:51.613+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:31:51.613+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:31:51.629+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:31:51.628+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:31:51.647+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.468 seconds
[2025-12-16T11:32:22.541+0000] {processor.py:161} INFO - Started process (PID=656) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:32:22.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:32:22.545+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:32:22.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:32:22.966+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:32:23.010+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:32:23.009+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:32:23.028+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:32:23.027+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:32:23.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.520 seconds
[2025-12-16T11:32:53.873+0000] {processor.py:161} INFO - Started process (PID=667) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:32:53.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:32:53.876+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:32:53.876+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:32:54.245+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:32:54.276+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:32:54.275+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:32:54.289+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:32:54.289+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:32:54.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.436 seconds
[2025-12-16T11:33:24.395+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:33:24.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:33:24.397+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:33:24.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:33:24.748+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:33:24.782+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:33:24.781+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:33:24.795+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:33:24.794+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:33:24.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.427 seconds
[2025-12-16T11:33:55.599+0000] {processor.py:161} INFO - Started process (PID=689) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:33:55.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:33:55.602+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:33:55.601+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:33:55.964+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:33:55.992+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:33:55.992+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:33:56.004+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:33:56.004+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:33:56.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.427 seconds
[2025-12-16T11:34:26.930+0000] {processor.py:161} INFO - Started process (PID=700) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:34:26.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:34:26.933+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:34:26.932+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:34:27.313+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:34:27.344+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:34:27.343+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:34:27.358+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:34:27.358+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:34:27.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.470 seconds
[2025-12-16T11:34:58.265+0000] {processor.py:161} INFO - Started process (PID=711) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:34:58.267+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:34:58.267+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:34:58.267+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:34:58.611+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:34:58.642+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:34:58.642+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:34:58.655+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:34:58.655+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:34:58.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.431 seconds
[2025-12-16T11:35:29.593+0000] {processor.py:161} INFO - Started process (PID=722) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:35:29.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:35:29.595+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:35:29.595+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:35:29.975+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:35:30.006+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:35:30.005+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:35:30.018+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:35:30.018+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:35:30.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.467 seconds
[2025-12-16T11:36:00.910+0000] {processor.py:161} INFO - Started process (PID=733) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:36:00.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:36:00.913+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:36:00.913+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:36:01.260+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:36:01.288+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:36:01.287+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:36:01.300+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:36:01.299+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:36:01.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.410 seconds
[2025-12-16T11:36:32.232+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:36:32.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:36:32.234+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:36:32.234+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:36:32.619+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:36:32.652+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:36:32.652+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:36:32.668+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:36:32.668+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:36:32.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.462 seconds
[2025-12-16T11:37:03.595+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:37:03.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:37:03.597+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:37:03.597+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:37:03.978+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:37:04.010+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:37:04.009+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:37:04.021+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:37:04.021+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:37:04.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.602 seconds
[2025-12-16T11:37:34.893+0000] {processor.py:161} INFO - Started process (PID=766) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:37:34.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:37:34.896+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:37:34.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:37:35.263+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:37:35.291+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:37:35.291+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:37:35.305+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:37:35.305+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:37:35.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.435 seconds
[2025-12-16T11:38:05.384+0000] {processor.py:161} INFO - Started process (PID=777) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:38:05.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:38:05.387+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:38:05.386+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:38:05.739+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:38:05.770+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:38:05.770+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:38:05.783+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:38:05.783+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:38:05.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.442 seconds
[2025-12-16T11:38:36.596+0000] {processor.py:161} INFO - Started process (PID=788) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:38:36.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:38:36.598+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:38:36.598+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:38:36.946+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:38:36.979+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:38:36.978+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:38:36.991+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:38:36.991+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:38:37.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.418 seconds
[2025-12-16T11:39:07.921+0000] {processor.py:161} INFO - Started process (PID=799) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:39:07.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:39:07.923+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:39:07.923+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:39:08.295+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:39:08.328+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:39:08.327+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:39:08.342+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:39:08.341+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:39:08.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.446 seconds
[2025-12-16T11:39:39.269+0000] {processor.py:161} INFO - Started process (PID=810) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:39:39.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:39:39.273+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:39:39.272+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:39:39.659+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:39:39.691+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:39:39.690+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:39:39.704+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:39:39.704+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:39:39.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.482 seconds
[2025-12-16T11:40:10.616+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:40:10.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:40:10.618+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:40:10.618+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:40:11.050+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:40:11.090+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:40:11.089+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:40:11.111+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:40:11.110+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:40:11.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.696 seconds
[2025-12-16T11:40:41.959+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:40:41.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:40:41.961+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:40:41.961+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:40:42.493+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:40:42.544+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:40:42.543+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:40:42.563+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:40:42.563+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:40:42.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.636 seconds
[2025-12-16T11:41:13.289+0000] {processor.py:161} INFO - Started process (PID=843) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:41:13.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:41:13.292+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:41:13.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:41:13.768+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:41:13.803+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:41:13.802+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:41:13.817+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:41:13.817+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:41:13.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.571 seconds
[2025-12-16T11:41:44.635+0000] {processor.py:161} INFO - Started process (PID=854) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:41:44.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:41:44.638+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:41:44.638+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:41:45.002+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:41:45.031+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:41:45.031+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:41:45.044+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:41:45.044+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:41:45.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.429 seconds
[2025-12-16T11:42:16.020+0000] {processor.py:161} INFO - Started process (PID=865) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:42:16.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:42:16.022+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:42:16.022+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:42:16.401+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:42:16.429+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:42:16.429+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:42:16.442+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:42:16.442+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:42:16.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.468 seconds
[2025-12-16T11:42:47.299+0000] {processor.py:161} INFO - Started process (PID=876) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:42:47.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:42:47.302+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:42:47.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:42:47.645+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:42:47.673+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:42:47.673+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:42:47.685+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:42:47.685+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:42:47.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.570 seconds
[2025-12-16T11:43:18.646+0000] {processor.py:161} INFO - Started process (PID=887) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:43:18.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:43:18.648+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:43:18.648+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:43:19.017+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:43:19.046+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:43:19.046+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:43:19.061+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:43:19.060+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:43:19.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.457 seconds
[2025-12-16T11:43:49.951+0000] {processor.py:161} INFO - Started process (PID=898) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:43:49.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:43:49.953+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:43:49.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:43:50.292+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:43:50.321+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:43:50.321+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:43:50.333+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:43:50.333+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:43:50.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.422 seconds
[2025-12-16T11:44:21.273+0000] {processor.py:161} INFO - Started process (PID=909) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:44:21.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:44:21.276+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:44:21.275+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:44:21.638+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:44:21.668+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:44:21.668+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:44:21.681+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:44:21.681+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:44:21.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.448 seconds
[2025-12-16T11:44:52.593+0000] {processor.py:161} INFO - Started process (PID=920) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:44:52.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:44:52.595+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:44:52.595+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:44:52.973+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:44:53.003+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:44:53.003+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:44:53.015+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:44:53.015+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:44:53.033+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.443 seconds
[2025-12-16T11:45:23.926+0000] {processor.py:161} INFO - Started process (PID=931) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:45:23.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:45:23.929+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:45:23.928+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:45:24.331+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:45:24.360+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:45:24.359+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:45:24.373+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:45:24.373+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:45:24.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.475 seconds
[2025-12-16T11:45:55.247+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:45:55.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:45:55.249+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:45:55.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:45:55.586+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:45:55.614+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:45:55.614+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:45:55.628+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:45:55.627+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:45:55.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.576 seconds
[2025-12-16T11:46:26.586+0000] {processor.py:161} INFO - Started process (PID=953) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:46:26.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:46:26.588+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:46:26.588+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:46:26.920+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:46:26.949+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:46:26.949+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:46:26.962+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:46:26.962+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:46:27.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.419 seconds
[2025-12-16T11:46:57.094+0000] {processor.py:161} INFO - Started process (PID=969) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:46:57.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:46:57.096+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:46:57.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:46:57.429+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:46:57.459+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:46:57.458+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:46:57.470+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:46:57.470+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:46:57.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.415 seconds
[2025-12-16T11:47:28.330+0000] {processor.py:161} INFO - Started process (PID=980) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:47:28.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:47:28.333+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:47:28.333+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:47:28.741+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:47:28.775+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:47:28.775+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:47:28.791+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:47:28.791+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:47:28.814+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.488 seconds
[2025-12-16T11:47:59.680+0000] {processor.py:161} INFO - Started process (PID=991) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:47:59.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:47:59.683+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:47:59.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:48:00.036+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:48:00.063+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:48:00.063+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:48:00.075+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:48:00.075+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:48:00.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.415 seconds
[2025-12-16T11:48:30.179+0000] {processor.py:161} INFO - Started process (PID=1002) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:48:30.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:48:30.181+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:48:30.181+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:48:30.516+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:48:30.547+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:48:30.546+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:48:30.561+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:48:30.561+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:48:30.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.594 seconds
[2025-12-16T11:49:01.383+0000] {processor.py:161} INFO - Started process (PID=1013) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:49:01.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:49:01.387+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:49:01.387+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:49:01.753+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:49:01.784+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:49:01.784+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:49:01.959+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:49:01.959+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:49:01.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.617 seconds
[2025-12-16T11:49:32.716+0000] {processor.py:161} INFO - Started process (PID=1024) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:49:32.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:49:32.718+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:49:32.718+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:49:33.081+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:49:33.111+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:49:33.111+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:49:33.124+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:49:33.123+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:49:33.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.450 seconds
[2025-12-16T11:50:04.043+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:50:04.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:50:04.045+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:50:04.045+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:50:04.433+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:50:04.469+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:50:04.469+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:50:04.483+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:50:04.483+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:50:04.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.462 seconds
[2025-12-16T11:50:35.392+0000] {processor.py:161} INFO - Started process (PID=1046) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:50:35.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:50:35.395+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:50:35.395+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:50:35.764+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:50:35.797+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:50:35.796+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:50:35.810+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:50:35.810+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:50:35.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.459 seconds
[2025-12-16T11:51:06.730+0000] {processor.py:161} INFO - Started process (PID=1057) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:51:06.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:51:06.733+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:51:06.733+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:51:07.089+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:51:07.118+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:51:07.118+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:51:07.130+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:51:07.130+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:51:07.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.442 seconds
[2025-12-16T11:51:38.049+0000] {processor.py:161} INFO - Started process (PID=1068) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:51:38.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:51:38.051+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:51:38.051+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:51:38.409+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:51:38.436+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:51:38.436+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:51:38.449+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:51:38.449+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:51:38.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.621 seconds
[2025-12-16T11:52:09.432+0000] {processor.py:161} INFO - Started process (PID=1079) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:52:09.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:52:09.434+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:52:09.434+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:52:09.786+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:52:09.816+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:52:09.816+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:52:09.829+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:52:09.829+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:52:09.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.439 seconds
[2025-12-16T11:52:40.762+0000] {processor.py:161} INFO - Started process (PID=1090) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:52:40.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:52:40.765+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:52:40.765+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:52:41.105+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:52:41.132+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:52:41.132+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:52:41.144+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:52:41.144+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:52:41.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.424 seconds
[2025-12-16T11:53:12.080+0000] {processor.py:161} INFO - Started process (PID=1101) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:53:12.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:53:12.082+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:53:12.081+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:53:12.422+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:53:12.450+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:53:12.450+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:53:12.462+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:53:12.462+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:53:12.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.402 seconds
[2025-12-16T11:53:42.583+0000] {processor.py:161} INFO - Started process (PID=1112) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:53:42.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:53:42.585+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:53:42.585+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:53:42.938+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:53:42.967+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:53:42.967+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:53:42.979+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:53:42.979+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:53:42.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.416 seconds
[2025-12-16T11:54:13.793+0000] {processor.py:161} INFO - Started process (PID=1123) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:54:13.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:54:13.795+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:54:13.794+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:54:14.131+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:54:14.159+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:54:14.158+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:54:14.170+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:54:14.170+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:54:14.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.564 seconds
[2025-12-16T11:54:45.128+0000] {processor.py:161} INFO - Started process (PID=1134) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:54:45.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:54:45.130+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:54:45.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:54:45.517+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:54:45.544+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:54:45.544+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:54:45.718+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:54:45.717+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:54:45.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.614 seconds
[2025-12-16T11:55:16.456+0000] {processor.py:161} INFO - Started process (PID=1145) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:55:16.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:55:16.459+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:55:16.458+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:55:16.806+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:55:16.833+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:55:16.833+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:55:16.845+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:55:16.845+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:55:16.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.409 seconds
[2025-12-16T11:55:47.768+0000] {processor.py:161} INFO - Started process (PID=1156) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:55:47.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:55:47.770+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:55:47.769+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:55:48.103+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:55:48.129+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:55:48.129+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:55:48.140+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:55:48.140+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:55:48.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.392 seconds
[2025-12-16T11:56:18.229+0000] {processor.py:161} INFO - Started process (PID=1167) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:56:18.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:56:18.231+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:56:18.230+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:56:18.584+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:56:18.614+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:56:18.614+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:56:18.627+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:56:18.627+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:56:18.664+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.439 seconds
[2025-12-16T11:56:49.443+0000] {processor.py:161} INFO - Started process (PID=1178) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:56:49.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:56:49.445+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:56:49.445+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:56:49.783+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:56:49.811+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:56:49.810+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:56:49.822+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:56:49.822+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:56:49.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.400 seconds
[2025-12-16T11:57:20.822+0000] {processor.py:161} INFO - Started process (PID=1189) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:57:20.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:57:20.824+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:57:20.824+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:57:21.207+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:57:21.238+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:57:21.238+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:57:21.252+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:57:21.252+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:57:21.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.649 seconds
[2025-12-16T11:57:52.097+0000] {processor.py:161} INFO - Started process (PID=1200) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:57:52.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:57:52.099+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:57:52.099+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:57:52.456+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:57:52.486+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:57:52.485+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:57:52.498+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:57:52.498+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:57:52.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.423 seconds
[2025-12-16T11:58:23.440+0000] {processor.py:161} INFO - Started process (PID=1211) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:58:23.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:58:23.442+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:58:23.442+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:58:23.876+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:58:23.909+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:58:23.909+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:58:23.922+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:58:23.922+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:58:23.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.507 seconds
[2025-12-16T11:58:54.766+0000] {processor.py:161} INFO - Started process (PID=1222) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:58:54.768+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:58:54.769+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:58:54.769+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:58:55.138+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:58:55.168+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:58:55.168+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:58:55.181+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:58:55.181+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:58:55.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.438 seconds
[2025-12-16T11:59:25.258+0000] {processor.py:161} INFO - Started process (PID=1233) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:59:25.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:59:25.261+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:59:25.260+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:59:25.713+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:59:25.750+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:59:25.749+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:59:25.766+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:59:25.765+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:59:25.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.534 seconds
[2025-12-16T11:59:56.472+0000] {processor.py:161} INFO - Started process (PID=1244) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:59:56.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T11:59:56.475+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:59:56.474+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:59:56.829+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T11:59:56.885+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:59:56.885+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T11:59:56.898+0000] {logging_mixin.py:188} INFO - [2025-12-16T11:59:56.897+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T11:59:57.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.624 seconds
[2025-12-16T12:00:27.800+0000] {processor.py:161} INFO - Started process (PID=1255) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:00:27.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:00:27.803+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:00:27.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:00:28.148+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:00:28.195+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:00:28.195+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:00:28.362+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:00:28.362+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:00:28.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.581 seconds
[2025-12-16T12:01:47.851+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:01:47.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:01:47.854+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:01:47.854+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:01:49.190+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:01:49.227+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:01:49.227+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:01:49.239+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:01:49.239+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:01:49.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.413 seconds
[2025-12-16T12:02:19.435+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:02:19.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:02:19.438+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:02:19.438+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:02:19.832+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:02:19.865+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:02:19.864+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:02:19.878+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:02:19.878+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:02:19.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.468 seconds
[2025-12-16T12:02:50.635+0000] {processor.py:161} INFO - Started process (PID=221) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:02:50.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:02:50.638+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:02:50.637+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:02:51.001+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:02:51.030+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:02:51.030+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:02:51.042+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:02:51.042+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:02:51.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.431 seconds
[2025-12-16T12:03:21.987+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:03:21.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:03:21.989+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:03:21.988+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:03:22.348+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:03:22.378+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:03:22.378+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:03:22.392+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:03:22.392+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:03:22.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.426 seconds
[2025-12-16T12:03:53.323+0000] {processor.py:161} INFO - Started process (PID=243) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:03:53.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:03:53.325+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:03:53.325+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:03:53.678+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:03:53.708+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:03:53.707+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:03:53.719+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:03:53.719+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:03:53.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.417 seconds
[2025-12-16T12:04:24.644+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:04:24.646+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:04:24.647+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:04:24.647+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:04:25.010+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:04:25.042+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:04:25.042+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:04:25.055+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:04:25.055+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:04:25.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.431 seconds
[2025-12-16T12:04:55.970+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:04:55.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:04:55.972+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:04:55.972+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:04:56.323+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:04:56.351+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:04:56.351+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:04:56.364+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:04:56.364+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:04:56.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.415 seconds
[2025-12-16T12:05:26.449+0000] {processor.py:161} INFO - Started process (PID=276) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:05:26.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:05:26.451+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:05:26.451+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:05:26.805+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:05:26.837+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:05:26.837+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:05:26.850+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:05:26.850+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:05:26.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.445 seconds
[2025-12-16T12:05:57.662+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:05:57.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:05:57.665+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:05:57.665+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:05:58.012+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:05:58.042+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:05:58.041+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:05:58.055+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:05:58.054+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:05:58.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.437 seconds
[2025-12-16T12:06:29.012+0000] {processor.py:161} INFO - Started process (PID=298) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:06:29.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:06:29.014+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:06:29.014+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:06:29.370+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:06:29.399+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:06:29.399+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:06:29.412+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:06:29.412+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:06:29.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.422 seconds
[2025-12-16T12:06:59.519+0000] {processor.py:161} INFO - Started process (PID=309) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:06:59.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:06:59.520+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:06:59.520+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:06:59.871+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:06:59.901+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:06:59.901+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:06:59.914+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:06:59.914+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:06:59.952+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.437 seconds
[2025-12-16T12:07:30.732+0000] {processor.py:161} INFO - Started process (PID=320) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:07:30.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:07:30.734+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:07:30.734+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:07:31.075+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:07:31.104+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:07:31.103+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:07:31.118+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:07:31.118+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:07:31.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.427 seconds
[2025-12-16T12:08:02.068+0000] {processor.py:161} INFO - Started process (PID=331) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:08:02.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:08:02.070+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:08:02.070+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:08:02.415+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:08:02.444+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:08:02.444+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:08:02.457+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:08:02.457+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:08:02.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.432 seconds
[2025-12-16T12:08:33.387+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:08:33.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:08:33.390+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:08:33.390+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:08:33.802+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:08:33.836+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:08:33.835+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:08:33.851+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:08:33.851+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:08:33.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.489 seconds
[2025-12-16T12:09:04.728+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:09:04.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:09:04.731+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:09:04.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:09:05.095+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:09:05.126+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:09:05.126+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:09:05.138+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:09:05.138+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:09:05.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.456 seconds
[2025-12-16T12:09:36.077+0000] {processor.py:161} INFO - Started process (PID=364) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:09:36.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:09:36.079+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:09:36.078+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:09:36.416+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:09:36.444+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:09:36.444+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:09:36.456+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:09:36.456+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:09:36.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.422 seconds
[2025-12-16T12:10:07.400+0000] {processor.py:161} INFO - Started process (PID=375) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:10:07.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:10:07.402+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:10:07.402+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:10:07.770+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:10:07.803+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:10:07.803+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:10:07.817+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:10:07.816+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:10:07.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.459 seconds
[2025-12-16T12:10:38.749+0000] {processor.py:161} INFO - Started process (PID=386) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:10:38.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:10:38.751+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:10:38.751+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:10:39.099+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:10:39.128+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:10:39.127+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:10:39.140+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:10:39.140+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:10:39.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.433 seconds
[2025-12-16T12:11:09.236+0000] {processor.py:161} INFO - Started process (PID=397) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:11:09.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:11:09.238+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:11:09.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:11:09.692+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:11:09.726+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:11:09.726+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:11:09.741+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:11:09.741+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:11:09.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.532 seconds
[2025-12-16T12:11:40.450+0000] {processor.py:161} INFO - Started process (PID=408) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:11:40.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:11:40.453+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:11:40.452+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:11:40.830+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:11:40.875+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:11:40.874+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:11:40.893+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:11:40.893+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:11:40.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.494 seconds
[2025-12-16T12:12:11.834+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:12:11.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:12:11.837+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:12:11.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:12:12.374+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:12:12.409+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:12:12.408+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:12:12.422+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:12:12.422+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:12:12.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.610 seconds
[2025-12-16T12:12:43.172+0000] {processor.py:161} INFO - Started process (PID=430) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:12:43.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:12:43.175+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:12:43.174+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:12:43.540+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:12:43.579+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:12:43.578+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:12:43.592+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:12:43.591+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:12:43.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.448 seconds
[2025-12-16T12:13:14.501+0000] {processor.py:161} INFO - Started process (PID=441) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:13:14.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:13:14.503+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:13:14.502+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:13:14.862+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:13:14.892+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:13:14.892+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:13:14.905+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:13:14.905+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:13:14.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.429 seconds
[2025-12-16T12:13:44.995+0000] {processor.py:161} INFO - Started process (PID=452) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:13:44.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:13:44.997+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:13:44.997+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:13:45.381+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:13:45.424+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:13:45.423+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:13:45.441+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:13:45.441+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:13:45.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.472 seconds
[2025-12-16T12:14:16.234+0000] {processor.py:161} INFO - Started process (PID=463) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:14:16.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:14:16.237+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:14:16.237+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:14:16.586+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:14:16.614+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:14:16.614+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:14:16.627+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:14:16.626+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:14:16.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.416 seconds
[2025-12-16T12:14:47.537+0000] {processor.py:161} INFO - Started process (PID=474) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:14:47.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:14:47.539+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:14:47.539+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:14:47.932+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:14:47.961+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:14:47.961+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:14:47.973+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:14:47.973+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:14:47.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.460 seconds
[2025-12-16T12:15:18.837+0000] {processor.py:161} INFO - Started process (PID=485) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:15:18.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:15:18.840+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:15:18.840+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:15:19.207+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:15:19.234+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:15:19.234+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:15:19.247+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:15:19.247+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:15:19.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.442 seconds
[2025-12-16T12:15:50.152+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:15:50.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:15:50.154+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:15:50.154+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:15:50.517+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:15:50.546+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:15:50.546+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:15:50.559+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:15:50.559+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:15:50.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.449 seconds
[2025-12-16T12:16:21.487+0000] {processor.py:161} INFO - Started process (PID=507) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:16:21.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:16:21.490+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:16:21.490+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:16:21.918+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:16:21.946+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:16:21.946+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:16:21.958+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:16:21.958+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:16:21.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.493 seconds
[2025-12-16T12:16:52.831+0000] {processor.py:161} INFO - Started process (PID=518) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:16:52.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:16:52.833+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:16:52.833+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:16:53.181+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:16:53.208+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:16:53.208+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:16:53.219+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:16:53.219+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:16:53.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.429 seconds
[2025-12-16T12:17:24.115+0000] {processor.py:161} INFO - Started process (PID=529) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:17:24.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:17:24.118+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:17:24.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:17:24.529+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:17:24.562+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:17:24.561+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:17:24.578+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:17:24.577+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:17:24.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.713 seconds
[2025-12-16T12:17:55.445+0000] {processor.py:161} INFO - Started process (PID=540) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:17:55.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:17:55.447+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:17:55.447+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:17:55.848+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:17:55.878+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:17:55.877+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:17:56.051+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:17:56.050+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:17:56.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.628 seconds
[2025-12-16T12:18:26.781+0000] {processor.py:161} INFO - Started process (PID=551) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:18:26.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:18:26.784+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:18:26.783+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:18:27.186+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:18:27.218+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:18:27.218+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:18:27.232+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:18:27.232+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:18:27.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.498 seconds
[2025-12-16T12:18:58.106+0000] {processor.py:161} INFO - Started process (PID=562) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:18:58.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:18:58.109+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:18:58.109+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:18:58.485+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:18:58.514+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:18:58.513+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:18:58.526+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:18:58.526+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:18:58.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.442 seconds
[2025-12-16T12:19:29.440+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:19:29.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:19:29.443+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:19:29.442+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:19:29.805+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:19:29.838+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:19:29.838+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:19:29.852+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:19:29.852+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:19:29.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.433 seconds
[2025-12-16T12:19:59.974+0000] {processor.py:161} INFO - Started process (PID=589) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:19:59.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:19:59.976+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:19:59.976+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:20:00.321+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:20:00.351+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:20:00.350+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:20:00.363+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:20:00.363+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:20:00.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.430 seconds
[2025-12-16T12:20:31.189+0000] {processor.py:161} INFO - Started process (PID=600) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:20:31.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:20:31.192+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:20:31.191+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:20:31.607+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:20:31.641+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:20:31.640+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:20:31.658+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:20:31.657+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:20:31.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.707 seconds
[2025-12-16T12:21:02.513+0000] {processor.py:161} INFO - Started process (PID=611) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:21:02.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:21:02.516+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:21:02.516+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:21:02.889+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:21:02.916+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:21:02.916+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:21:02.929+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:21:02.929+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:21:02.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.436 seconds
[2025-12-16T12:21:33.846+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:21:33.848+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:21:33.849+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:21:33.849+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:21:34.216+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:21:34.246+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:21:34.245+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:21:34.258+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:21:34.258+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:21:34.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.434 seconds
[2025-12-16T12:23:07.665+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:23:07.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:23:07.669+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:23:07.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:23:09.716+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:23:09.752+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:23:09.751+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:23:09.765+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:23:09.765+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:23:09.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 2.126 seconds
[2025-12-16T12:23:40.005+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:23:40.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:23:40.007+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:23:40.007+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:23:40.392+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:23:40.421+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:23:40.421+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:23:40.434+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:23:40.434+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:23:40.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.626 seconds
[2025-12-16T12:24:10.699+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:24:10.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:24:10.703+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:24:10.703+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:24:11.464+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:24:11.505+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:24:11.505+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:24:11.526+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:24:11.525+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:24:11.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.863 seconds
[2025-12-16T12:24:41.803+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:24:41.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:24:41.807+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:24:41.806+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:24:42.313+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:24:42.350+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:24:42.350+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:24:42.367+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:24:42.367+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:24:42.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.593 seconds
[2025-12-16T12:25:13.192+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:25:13.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:25:13.195+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:25:13.194+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:25:13.653+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:25:13.688+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:25:13.688+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:25:13.704+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:25:13.703+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:25:13.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.539 seconds
[2025-12-16T12:25:44.569+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:25:44.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:25:44.571+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:25:44.571+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:25:45.024+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:25:45.061+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:25:45.061+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:25:45.077+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:25:45.077+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:25:45.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.538 seconds
[2025-12-16T12:26:15.224+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:26:15.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:26:15.230+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:26:15.229+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:26:16.061+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:26:16.095+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:26:16.095+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:26:16.112+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:26:16.112+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:26:16.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.923 seconds
[2025-12-16T12:26:46.405+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:26:46.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:26:46.408+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:26:46.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:26:46.909+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:26:46.946+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:26:46.945+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:26:46.961+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:26:46.961+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:26:47.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.788 seconds
[2025-12-16T12:27:17.806+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:27:17.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:27:17.809+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:27:17.809+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:27:18.443+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:27:18.484+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:27:18.483+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:27:18.503+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:27:18.503+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:27:18.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.730 seconds
[2025-12-16T12:27:48.689+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:27:48.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:27:48.702+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:27:48.698+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:27:49.862+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:27:49.935+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:27:49.934+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:27:49.966+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:27:49.965+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:27:50.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.337 seconds
[2025-12-16T12:28:20.386+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:28:20.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:28:20.390+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:28:20.390+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:28:21.371+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:28:21.429+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:28:21.429+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:28:21.457+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:28:21.456+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:28:21.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.128 seconds
[2025-12-16T12:28:51.656+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:28:51.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:28:51.661+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:28:51.661+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:28:52.360+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:28:52.409+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:28:52.408+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:28:52.432+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:28:52.432+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:28:52.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.847 seconds
[2025-12-16T12:29:23.103+0000] {processor.py:161} INFO - Started process (PID=340) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:29:23.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:29:23.107+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:29:23.106+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:29:23.849+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:29:23.898+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:29:23.897+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:29:23.918+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:29:23.918+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:29:23.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.858 seconds
[2025-12-16T12:29:54.626+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:29:54.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:29:54.629+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:29:54.628+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:29:55.294+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:29:55.330+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:29:55.330+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:29:55.349+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:29:55.349+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:29:55.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.005 seconds
[2025-12-16T12:30:25.906+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:30:25.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:30:25.909+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:30:25.909+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:30:26.470+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:30:26.512+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:30:26.511+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:30:26.534+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:30:26.534+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:30:26.563+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.662 seconds
[2025-12-16T12:30:57.221+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:30:57.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:30:57.224+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:30:57.224+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:30:57.773+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:30:57.814+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:30:57.814+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:30:57.833+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:30:57.833+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:30:58.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.974 seconds
[2025-12-16T12:31:28.466+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:31:28.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:31:28.468+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:31:28.468+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:31:29.098+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:31:29.139+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:31:29.139+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:31:29.158+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:31:29.158+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:31:29.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.724 seconds
[2025-12-16T12:31:59.954+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:31:59.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:31:59.970+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:31:59.968+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:32:00.849+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:32:00.891+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:32:00.890+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:32:00.911+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:32:00.911+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:32:00.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.007 seconds
[2025-12-16T12:32:31.273+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:32:31.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:32:31.277+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:32:31.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:32:31.943+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:32:31.988+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:32:31.986+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:32:32.007+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:32:32.007+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:32:32.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.779 seconds
[2025-12-16T12:33:02.622+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:33:02.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:33:02.625+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:33:02.625+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:33:03.144+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:33:03.184+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:33:03.183+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:33:03.205+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:33:03.205+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:33:03.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.831 seconds
[2025-12-16T12:33:34.014+0000] {processor.py:161} INFO - Started process (PID=428) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:33:34.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:33:34.017+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:33:34.017+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:33:34.568+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:33:34.607+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:33:34.607+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:33:34.624+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:33:34.624+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:33:34.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.639 seconds
[2025-12-16T12:34:05.398+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:34:05.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:34:05.401+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:34:05.401+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:34:05.939+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:34:05.976+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:34:05.975+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:34:05.994+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:34:05.993+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:34:06.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.626 seconds
[2025-12-16T12:34:36.794+0000] {processor.py:161} INFO - Started process (PID=450) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:34:36.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:34:36.797+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:34:36.796+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:34:37.378+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:34:37.418+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:34:37.417+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:34:37.435+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:34:37.435+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:34:37.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.672 seconds
[2025-12-16T12:35:08.207+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:35:08.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:35:08.211+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:35:08.211+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:35:08.740+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:35:08.784+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:35:08.783+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:35:08.805+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:35:08.804+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:35:08.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.635 seconds
[2025-12-16T12:35:39.586+0000] {processor.py:161} INFO - Started process (PID=472) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:35:39.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:35:39.590+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:35:39.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:35:40.164+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:35:40.205+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:35:40.205+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:35:40.226+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:35:40.226+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:35:40.466+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.886 seconds
[2025-12-16T12:36:10.950+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:36:10.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:36:10.954+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:36:10.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:36:11.472+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:36:11.513+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:36:11.513+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:36:11.533+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:36:11.532+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:36:11.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.616 seconds
[2025-12-16T12:36:42.396+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:36:42.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:36:42.399+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:36:42.398+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:36:42.918+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:36:42.961+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:36:42.960+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:36:42.978+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:36:42.978+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:36:43.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.612 seconds
[2025-12-16T12:37:13.812+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:37:13.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:37:13.816+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:37:13.815+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:37:14.399+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:37:14.444+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:37:14.444+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:37:14.463+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:37:14.462+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:37:14.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.685 seconds
[2025-12-16T12:37:45.197+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:37:45.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:37:45.200+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:37:45.199+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:37:45.722+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:37:45.756+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:37:45.755+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:37:45.771+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:37:45.770+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:37:45.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.601 seconds
[2025-12-16T12:38:16.529+0000] {processor.py:161} INFO - Started process (PID=527) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:38:16.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:38:16.531+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:38:16.531+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:38:17.003+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:38:17.039+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:38:17.038+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:38:17.053+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:38:17.053+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:38:17.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.553 seconds
[2025-12-16T12:38:47.907+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:38:47.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:38:47.910+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:38:47.909+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:38:48.370+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:38:48.406+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:38:48.405+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:38:48.422+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:38:48.421+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:38:48.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.741 seconds
[2025-12-16T12:39:19.260+0000] {processor.py:161} INFO - Started process (PID=550) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:39:19.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:39:19.263+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:39:19.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:39:19.943+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:39:19.980+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:39:19.980+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:39:20.212+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:39:20.211+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:39:20.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.988 seconds
[2025-12-16T12:39:50.556+0000] {processor.py:161} INFO - Started process (PID=563) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:39:50.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:39:50.563+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:39:50.562+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:39:51.061+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:39:51.110+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:39:51.109+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:39:51.127+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:39:51.127+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:39:51.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.602 seconds
[2025-12-16T12:40:21.958+0000] {processor.py:161} INFO - Started process (PID=574) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:40:21.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:40:21.961+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:40:21.960+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:40:22.336+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:40:22.363+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:40:22.362+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:40:22.376+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:40:22.376+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:40:22.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.440 seconds
[2025-12-16T12:40:52.482+0000] {processor.py:161} INFO - Started process (PID=590) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:40:52.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:40:52.484+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:40:52.484+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:40:52.860+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:40:52.893+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:40:52.893+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:40:52.906+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:40:52.906+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:40:52.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.446 seconds
[2025-12-16T12:41:23.698+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:41:23.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:41:23.700+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:41:23.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:41:24.043+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:41:24.072+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:41:24.072+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:41:24.084+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:41:24.084+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:41:24.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.431 seconds
[2025-12-16T12:41:54.188+0000] {processor.py:161} INFO - Started process (PID=612) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:41:54.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:41:54.191+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:41:54.191+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:41:54.545+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:41:54.574+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:41:54.573+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:41:54.587+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:41:54.587+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:41:54.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.726 seconds
[2025-12-16T12:42:25.391+0000] {processor.py:161} INFO - Started process (PID=623) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:42:25.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:42:25.393+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:42:25.393+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:42:25.749+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:42:25.779+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:42:25.778+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:42:25.792+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:42:25.792+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:42:25.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.422 seconds
[2025-12-16T12:42:56.739+0000] {processor.py:161} INFO - Started process (PID=634) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:42:56.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:42:56.741+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:42:56.741+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:42:57.094+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:42:57.125+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:42:57.124+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:42:57.137+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:42:57.137+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:42:57.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.441 seconds
[2025-12-16T12:43:27.272+0000] {processor.py:161} INFO - Started process (PID=645) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:43:27.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:43:27.274+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:43:27.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:43:27.673+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:43:27.703+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:43:27.703+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:43:27.715+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:43:27.715+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:43:27.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.469 seconds
[2025-12-16T12:43:58.378+0000] {processor.py:161} INFO - Started process (PID=656) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:43:58.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:43:58.380+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:43:58.380+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:43:58.866+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:43:58.908+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:43:58.907+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:43:58.923+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:43:58.923+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:43:58.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.570 seconds
[2025-12-16T12:44:29.741+0000] {processor.py:161} INFO - Started process (PID=667) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:44:29.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:44:29.743+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:44:29.743+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:44:30.129+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:44:30.161+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:44:30.161+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:44:30.175+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:44:30.174+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:44:30.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.620 seconds
[2025-12-16T12:45:01.092+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:45:01.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:45:01.095+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:45:01.094+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:45:01.568+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:45:01.606+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:45:01.605+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:45:01.807+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:45:01.807+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:45:01.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.737 seconds
[2025-12-16T12:45:32.434+0000] {processor.py:161} INFO - Started process (PID=689) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:45:32.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:45:32.436+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:45:32.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:45:32.835+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:45:32.865+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:45:32.865+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:45:32.878+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:45:32.878+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:45:32.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.467 seconds
[2025-12-16T12:46:03.776+0000] {processor.py:161} INFO - Started process (PID=700) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:46:03.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:46:03.778+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:46:03.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:46:04.143+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:46:04.172+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:46:04.172+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:46:04.185+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:46:04.184+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:46:04.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.449 seconds
[2025-12-16T12:46:35.112+0000] {processor.py:161} INFO - Started process (PID=711) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:46:35.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:46:35.115+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:46:35.115+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:46:35.474+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:46:35.501+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:46:35.500+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:46:35.513+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:46:35.513+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:46:35.547+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.439 seconds
[2025-12-16T12:47:06.427+0000] {processor.py:161} INFO - Started process (PID=722) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:47:06.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:47:06.429+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:47:06.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:47:06.779+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:47:06.806+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:47:06.805+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:47:06.818+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:47:06.818+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:47:06.834+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.410 seconds
[2025-12-16T12:47:37.753+0000] {processor.py:161} INFO - Started process (PID=733) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:47:37.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:47:37.755+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:47:37.755+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:47:38.174+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:47:38.205+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:47:38.205+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:47:38.219+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:47:38.219+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:47:38.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.676 seconds
[2025-12-16T12:48:09.100+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:48:09.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:48:09.102+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:48:09.102+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:48:09.499+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:48:09.530+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:48:09.529+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:48:09.543+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:48:09.543+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:48:09.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.485 seconds
[2025-12-16T12:48:40.441+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:48:40.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:48:40.443+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:48:40.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:48:40.807+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:48:40.839+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:48:40.839+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:48:40.860+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:48:40.860+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:48:40.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.462 seconds
[2025-12-16T12:49:11.887+0000] {processor.py:161} INFO - Started process (PID=766) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:49:11.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:49:11.893+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:49:11.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:49:13.110+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:49:13.194+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:49:13.193+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:49:13.239+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:49:13.239+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:49:13.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.414 seconds
[2025-12-16T12:49:44.159+0000] {processor.py:161} INFO - Started process (PID=777) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:49:44.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:49:44.165+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:49:44.165+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:49:44.758+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:49:44.792+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:49:44.792+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:49:44.805+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:49:44.805+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:49:44.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.670 seconds
[2025-12-16T12:50:15.511+0000] {processor.py:161} INFO - Started process (PID=788) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:50:15.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:50:15.513+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:50:15.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:50:15.932+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:50:15.968+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:50:15.967+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:50:15.984+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:50:15.983+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:50:16.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.697 seconds
[2025-12-16T12:50:46.867+0000] {processor.py:161} INFO - Started process (PID=799) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:50:46.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:50:46.869+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:50:46.869+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:50:47.244+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:50:47.275+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:50:47.274+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:50:47.441+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:50:47.440+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:50:47.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.616 seconds
[2025-12-16T12:51:18.177+0000] {processor.py:161} INFO - Started process (PID=810) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:51:18.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:51:18.179+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:51:18.179+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:51:18.555+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:51:18.587+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:51:18.586+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:51:18.600+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:51:18.600+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:51:18.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.445 seconds
[2025-12-16T12:51:49.496+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:51:49.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:51:49.498+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:51:49.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:51:49.870+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:51:49.901+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:51:49.900+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:51:49.914+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:51:49.914+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:51:49.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.444 seconds
[2025-12-16T12:52:20.814+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:52:20.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:52:20.816+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:52:20.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:52:21.237+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:52:21.265+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:52:21.264+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:52:21.277+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:52:21.276+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:52:21.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.506 seconds
[2025-12-16T12:52:52.126+0000] {processor.py:161} INFO - Started process (PID=843) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:52:52.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:52:52.128+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:52:52.128+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:52:52.484+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:52:52.512+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:52:52.512+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:52:52.526+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:52:52.526+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:52:52.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.429 seconds
[2025-12-16T12:53:23.493+0000] {processor.py:161} INFO - Started process (PID=854) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:53:23.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:53:23.495+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:53:23.495+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:53:23.862+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:53:23.890+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:53:23.889+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:53:23.904+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:53:23.904+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:53:24.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.592 seconds
[2025-12-16T12:54:41.735+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:54:41.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:54:41.738+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:54:41.738+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:54:43.251+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:54:43.289+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:54:43.288+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:54:43.302+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:54:43.302+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:54:43.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.591 seconds
[2025-12-16T12:55:14.206+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:55:14.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:55:14.208+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:55:14.208+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:55:14.563+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:55:14.593+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:55:14.593+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:55:14.606+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:55:14.606+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:55:14.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.618 seconds
[2025-12-16T12:55:45.552+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:55:45.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:55:45.556+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:55:45.556+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:55:46.197+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:55:46.262+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:55:46.261+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:55:46.293+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:55:46.292+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:55:46.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.775 seconds
[2025-12-16T12:56:16.917+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:56:16.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:56:16.921+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:56:16.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:56:17.558+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:56:17.600+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:56:17.600+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:56:17.632+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:56:17.632+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:56:17.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.766 seconds
[2025-12-16T12:56:48.277+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:56:48.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:56:48.281+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:56:48.280+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:56:48.793+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:56:48.859+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:56:48.859+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:56:48.874+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:56:48.873+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:56:48.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.626 seconds
[2025-12-16T12:57:19.648+0000] {processor.py:161} INFO - Started process (PID=260) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:57:19.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:57:19.651+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:57:19.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:57:20.177+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:57:20.218+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:57:20.218+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:57:20.235+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:57:20.235+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:57:20.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.617 seconds
[2025-12-16T12:57:51.050+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:57:51.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:57:51.053+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:57:51.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:57:51.596+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:57:51.631+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:57:51.631+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:57:51.649+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:57:51.649+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:57:51.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.629 seconds
[2025-12-16T12:58:22.537+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:58:22.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:58:22.539+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:58:22.539+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:58:22.945+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:58:22.975+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:58:22.975+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:58:22.988+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:58:22.988+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:58:23.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.646 seconds
[2025-12-16T12:58:53.912+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:58:53.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:58:53.914+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:58:53.913+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:58:54.300+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:58:54.330+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:58:54.330+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:58:54.344+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:58:54.343+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:58:54.383+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.475 seconds
[2025-12-16T12:59:25.247+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:59:25.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:59:25.249+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:59:25.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:59:25.624+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:59:25.652+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:59:25.652+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:59:25.665+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:59:25.664+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:59:25.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.459 seconds
[2025-12-16T12:59:56.602+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:59:56.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T12:59:56.606+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:59:56.606+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:59:57.278+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T12:59:57.321+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:59:57.320+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T12:59:57.344+0000] {logging_mixin.py:188} INFO - [2025-12-16T12:59:57.343+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T12:59:57.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.780 seconds
[2025-12-16T13:00:27.912+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:00:27.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:00:27.915+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:00:27.914+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:00:28.335+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:00:28.366+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:00:28.365+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:00:28.379+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:00:28.379+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:00:28.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.511 seconds
[2025-12-16T13:00:59.261+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:00:59.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:00:59.263+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:00:59.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:00:59.622+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:00:59.650+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:00:59.649+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:00:59.662+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:00:59.661+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:00:59.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.444 seconds
[2025-12-16T13:01:29.794+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:01:29.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:01:29.796+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:01:29.796+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:01:30.186+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:01:30.225+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:01:30.224+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:01:30.241+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:01:30.241+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:01:30.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.652 seconds
[2025-12-16T13:02:00.999+0000] {processor.py:161} INFO - Started process (PID=365) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:02:01.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:02:01.001+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:02:01.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:02:01.468+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:02:01.505+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:02:01.504+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:02:01.521+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:02:01.521+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:02:01.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.547 seconds
[2025-12-16T13:02:32.352+0000] {processor.py:161} INFO - Started process (PID=376) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:02:32.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:02:32.355+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:02:32.354+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:02:32.793+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:02:32.826+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:02:32.825+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:02:32.838+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:02:32.838+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:02:32.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.510 seconds
[2025-12-16T13:03:03.703+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:03:03.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:03:03.706+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:03:03.706+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:03:04.089+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:03:04.117+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:03:04.117+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:03:04.130+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:03:04.130+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:03:04.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.448 seconds
[2025-12-16T13:03:35.052+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:03:35.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:03:35.054+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:03:35.054+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:03:35.513+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:03:35.552+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:03:35.551+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:03:35.568+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:03:35.567+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:03:35.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.546 seconds
[2025-12-16T13:04:06.390+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:04:06.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:04:06.394+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:04:06.393+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:04:06.793+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:04:06.823+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:04:06.823+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:04:06.835+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:04:06.835+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:04:06.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.470 seconds
[2025-12-16T13:04:37.794+0000] {processor.py:161} INFO - Started process (PID=420) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:04:37.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:04:37.803+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:04:37.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:04:38.348+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:04:38.379+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:04:38.379+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:04:38.394+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:04:38.393+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:04:38.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.644 seconds
[2025-12-16T13:05:39.103+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:05:39.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:05:39.110+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:05:39.109+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:05:40.557+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:05:40.600+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:05:40.600+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:05:40.618+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:05:40.618+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:05:40.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.549 seconds
[2025-12-16T13:06:10.831+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:06:10.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:06:10.834+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:06:10.834+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:06:11.339+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:06:11.376+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:06:11.375+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:06:11.390+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:06:11.390+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:06:11.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.824 seconds
[2025-12-16T13:06:41.886+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:06:41.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:06:41.889+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:06:41.888+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:06:42.397+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:06:42.434+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:06:42.434+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:06:42.453+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:06:42.452+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:06:42.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.598 seconds
[2025-12-16T13:07:13.199+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:07:13.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:07:13.204+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:07:13.204+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:07:13.650+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:07:13.686+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:07:13.686+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:07:13.703+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:07:13.703+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:07:13.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.536 seconds
[2025-12-16T13:07:44.566+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:07:44.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:07:44.569+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:07:44.568+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:07:45.096+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:07:45.140+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:07:45.139+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:07:45.158+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:07:45.158+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:07:45.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.625 seconds
[2025-12-16T13:08:15.970+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:08:15.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:08:15.976+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:08:15.975+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:08:16.687+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:08:16.733+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:08:16.733+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:08:16.751+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:08:16.750+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:08:16.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.821 seconds
[2025-12-16T13:08:47.364+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:08:47.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:08:47.367+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:08:47.367+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:08:47.942+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:08:47.987+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:08:47.986+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:08:48.008+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:08:48.007+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:08:48.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.678 seconds
[2025-12-16T13:09:18.767+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:09:18.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:09:18.771+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:09:18.771+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:09:19.291+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:09:19.332+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:09:19.332+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:09:19.351+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:09:19.351+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:09:19.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.856 seconds
[2025-12-16T13:09:50.140+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:09:50.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:09:50.144+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:09:50.143+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:09:50.699+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:09:50.744+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:09:50.743+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:09:50.763+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:09:50.763+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:09:50.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.657 seconds
[2025-12-16T13:10:21.508+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:10:21.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:10:21.511+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:10:21.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:10:22.000+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:10:22.043+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:10:22.042+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:10:22.061+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:10:22.061+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:10:22.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.585 seconds
[2025-12-16T13:10:52.884+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:10:52.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:10:52.888+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:10:52.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:10:53.434+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:10:53.478+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:10:53.477+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:10:53.497+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:10:53.497+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:10:53.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.646 seconds
[2025-12-16T13:11:24.227+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:11:24.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:11:24.230+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:11:24.230+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:11:24.786+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:11:24.826+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:11:24.825+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:11:24.845+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:11:24.844+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:11:24.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.651 seconds
[2025-12-16T13:11:55.586+0000] {processor.py:161} INFO - Started process (PID=340) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:11:55.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:11:55.589+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:11:55.588+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:11:56.114+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:11:56.158+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:11:56.157+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:11:56.178+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:11:56.177+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:11:56.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.630 seconds
[2025-12-16T13:12:26.944+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:12:26.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:12:26.948+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:12:26.947+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:12:27.519+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:12:27.558+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:12:27.557+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:12:27.576+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:12:27.576+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:12:27.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.900 seconds
[2025-12-16T13:12:58.334+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:12:58.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:12:58.337+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:12:58.337+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:12:58.883+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:12:58.925+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:12:58.924+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:12:58.945+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:12:58.945+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:12:58.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.649 seconds
[2025-12-16T13:13:29.684+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:13:29.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:13:29.687+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:13:29.687+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:13:30.178+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:13:30.217+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:13:30.216+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:13:30.234+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:13:30.233+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:13:30.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.585 seconds
[2025-12-16T13:14:01.071+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:14:01.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:14:01.075+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:14:01.074+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:14:01.644+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:14:01.683+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:14:01.683+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:14:01.701+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:14:01.701+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:14:01.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.665 seconds
[2025-12-16T13:14:32.427+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:14:32.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:14:32.430+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:14:32.430+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:14:32.914+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:14:32.954+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:14:32.954+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:14:32.972+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:14:32.972+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:14:32.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.576 seconds
[2025-12-16T13:15:03.801+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:15:03.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:15:03.805+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:15:03.805+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:15:04.390+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:15:04.431+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:15:04.430+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:15:04.448+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:15:04.448+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:15:04.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.934 seconds
[2025-12-16T13:15:35.011+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:15:35.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:15:35.014+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:15:35.013+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:15:35.501+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:15:35.541+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:15:35.541+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:15:35.559+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:15:35.559+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:15:35.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.578 seconds
[2025-12-16T13:16:06.354+0000] {processor.py:161} INFO - Started process (PID=428) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:16:06.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:16:06.357+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:16:06.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:16:06.909+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:16:06.949+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:16:06.949+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:16:06.967+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:16:06.966+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:16:06.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.646 seconds
[2025-12-16T13:16:37.700+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:16:37.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:16:37.702+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:16:37.702+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:16:38.233+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:16:38.274+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:16:38.273+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:16:38.291+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:16:38.291+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:16:38.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.622 seconds
[2025-12-16T13:17:09.138+0000] {processor.py:161} INFO - Started process (PID=450) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:17:09.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:17:09.142+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:17:09.141+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:17:09.704+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:17:09.742+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:17:09.742+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:17:09.759+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:17:09.759+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:17:09.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.653 seconds
[2025-12-16T13:17:40.527+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:17:40.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:17:40.531+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:17:40.531+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:17:41.017+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:17:41.054+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:17:41.053+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:17:41.070+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:17:41.070+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:17:41.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.573 seconds
[2025-12-16T13:18:11.924+0000] {processor.py:161} INFO - Started process (PID=472) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:18:11.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:18:11.928+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:18:11.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:18:12.477+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:18:12.519+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:18:12.519+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:18:12.539+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:18:12.539+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:18:12.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.866 seconds
[2025-12-16T13:18:43.291+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:18:43.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:18:43.295+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:18:43.294+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:18:43.818+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:18:43.858+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:18:43.857+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:18:43.876+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:18:43.875+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:18:43.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.615 seconds
[2025-12-16T13:19:14.655+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:19:14.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:19:14.658+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:19:14.657+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:19:15.215+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:19:15.256+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:19:15.255+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:19:15.272+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:19:15.272+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:19:15.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.648 seconds
[2025-12-16T13:19:46.028+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:19:46.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:19:46.030+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:19:46.030+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:19:46.549+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:19:46.588+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:19:46.588+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:19:46.606+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:19:46.606+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:19:46.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.609 seconds
[2025-12-16T13:20:17.370+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:20:17.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:20:17.373+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:20:17.373+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:20:17.970+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:20:18.012+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:20:18.012+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:20:18.030+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:20:18.030+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:20:18.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.690 seconds
[2025-12-16T13:20:48.730+0000] {processor.py:161} INFO - Started process (PID=527) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:20:48.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:20:48.733+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:20:48.733+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:20:49.262+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:20:49.298+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:20:49.297+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:20:49.314+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:20:49.313+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:20:49.339+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.615 seconds
[2025-12-16T13:21:20.126+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:21:20.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:21:20.130+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:21:20.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:21:20.712+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:21:20.754+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:21:20.753+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:21:20.774+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:21:20.774+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:21:21.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.920 seconds
[2025-12-16T13:21:51.546+0000] {processor.py:161} INFO - Started process (PID=554) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:21:51.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:21:51.549+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:21:51.549+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:21:52.029+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:21:52.070+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:21:52.070+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:21:52.090+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:21:52.090+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:21:52.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.576 seconds
[2025-12-16T13:22:22.912+0000] {processor.py:161} INFO - Started process (PID=565) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:22:22.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:22:22.916+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:22:22.916+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:22:23.460+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:22:23.505+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:22:23.505+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:22:23.524+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:22:23.524+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:22:23.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.643 seconds
[2025-12-16T13:22:54.340+0000] {processor.py:161} INFO - Started process (PID=579) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:22:54.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:22:54.343+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:22:54.342+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:22:54.721+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:22:54.748+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:22:54.747+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:22:54.760+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:22:54.760+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:22:54.801+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.464 seconds
[2025-12-16T13:23:25.680+0000] {processor.py:161} INFO - Started process (PID=590) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:23:25.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:23:25.682+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:23:25.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:23:26.066+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:23:26.095+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:23:26.095+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:23:26.108+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:23:26.108+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:23:26.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.469 seconds
[2025-12-16T13:23:57.008+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:23:57.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:23:57.010+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:23:57.010+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:23:57.364+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:23:57.393+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:23:57.392+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:23:57.407+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:23:57.406+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:23:57.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.423 seconds
[2025-12-16T13:24:28.332+0000] {processor.py:161} INFO - Started process (PID=612) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:24:28.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:24:28.334+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:24:28.334+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:24:28.751+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:24:28.783+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:24:28.782+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:24:28.797+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:24:28.797+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:24:29.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.682 seconds
[2025-12-16T13:24:59.642+0000] {processor.py:161} INFO - Started process (PID=623) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:24:59.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:24:59.644+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:24:59.644+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:25:00.100+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:25:00.136+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:25:00.136+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:25:00.152+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:25:00.152+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:25:00.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.536 seconds
[2025-12-16T13:25:31.005+0000] {processor.py:161} INFO - Started process (PID=634) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:25:31.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:25:31.007+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:25:31.007+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:25:31.375+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:25:31.405+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:25:31.404+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:25:31.417+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:25:31.417+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:25:31.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.432 seconds
[2025-12-16T13:26:01.508+0000] {processor.py:161} INFO - Started process (PID=645) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:26:01.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:26:01.510+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:26:01.510+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:26:01.881+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:26:01.910+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:26:01.910+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:26:01.922+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:26:01.922+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:26:01.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.455 seconds
[2025-12-16T13:26:32.719+0000] {processor.py:161} INFO - Started process (PID=656) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:26:32.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:26:32.722+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:26:32.721+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:26:33.116+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:26:33.145+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:26:33.144+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:26:33.159+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:26:33.159+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:26:33.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.463 seconds
[2025-12-16T13:27:04.071+0000] {processor.py:161} INFO - Started process (PID=667) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:27:04.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:27:04.074+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:27:04.074+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:27:04.466+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:27:04.495+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:27:04.495+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:27:04.508+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:27:04.508+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:27:04.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.636 seconds
[2025-12-16T13:27:35.428+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:27:35.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:27:35.430+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:27:35.430+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:27:35.814+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:27:35.847+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:27:35.846+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:27:36.029+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:27:36.028+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:27:36.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.622 seconds
[2025-12-16T13:28:06.809+0000] {processor.py:161} INFO - Started process (PID=689) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:28:06.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:28:06.812+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:28:06.812+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:28:07.275+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:28:07.309+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:28:07.308+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:28:07.323+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:28:07.323+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:28:07.345+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.541 seconds
[2025-12-16T13:28:38.155+0000] {processor.py:161} INFO - Started process (PID=700) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:28:38.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:28:38.158+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:28:38.157+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:28:38.528+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:28:38.555+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:28:38.555+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:28:38.567+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:28:38.566+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:28:38.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.434 seconds
[2025-12-16T13:29:08.661+0000] {processor.py:161} INFO - Started process (PID=711) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:29:08.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:29:08.663+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:29:08.663+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:29:09.031+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:29:09.063+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:29:09.062+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:29:09.078+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:29:09.078+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:29:09.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.443 seconds
[2025-12-16T13:29:39.874+0000] {processor.py:161} INFO - Started process (PID=722) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:29:39.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:29:39.876+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:29:39.876+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:29:40.358+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:29:40.395+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:29:40.394+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:29:40.409+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:29:40.409+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:29:40.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.585 seconds
[2025-12-16T13:30:11.288+0000] {processor.py:161} INFO - Started process (PID=733) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:30:11.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:30:11.290+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:30:11.290+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:30:11.703+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:30:11.731+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:30:11.730+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:30:11.743+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:30:11.743+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:30:12.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.750 seconds
[2025-12-16T13:30:42.693+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:30:42.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:30:42.696+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:30:42.695+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:30:43.072+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:30:43.103+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:30:43.102+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:30:43.118+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:30:43.118+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:30:43.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.449 seconds
[2025-12-16T13:31:14.010+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:31:14.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:31:14.012+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:31:14.011+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:31:14.386+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:31:14.414+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:31:14.414+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:31:14.426+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:31:14.426+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:31:14.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.456 seconds
[2025-12-16T13:31:45.354+0000] {processor.py:161} INFO - Started process (PID=766) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:31:45.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:31:45.357+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:31:45.357+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:31:45.804+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:31:45.838+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:31:45.838+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:31:45.853+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:31:45.852+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:31:45.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.549 seconds
[2025-12-16T13:32:16.700+0000] {processor.py:161} INFO - Started process (PID=777) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:32:16.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:32:16.704+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:32:16.703+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:32:17.421+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:32:17.460+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:32:17.460+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:32:17.475+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:32:17.475+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:32:17.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.804 seconds
[2025-12-16T13:32:48.045+0000] {processor.py:161} INFO - Started process (PID=788) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:32:48.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:32:48.048+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:32:48.048+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:32:48.449+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:32:48.479+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:32:48.478+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:32:48.493+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:32:48.493+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:32:48.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.671 seconds
[2025-12-16T13:33:19.360+0000] {processor.py:161} INFO - Started process (PID=799) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:33:19.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:33:19.362+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:33:19.362+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:33:19.720+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:33:19.749+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:33:19.749+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:33:19.925+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:33:19.924+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:33:19.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.605 seconds
[2025-12-16T13:33:50.694+0000] {processor.py:161} INFO - Started process (PID=810) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:33:50.696+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:33:50.697+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:33:50.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:33:51.060+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:33:51.090+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:33:51.089+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:33:51.103+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:33:51.102+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:33:51.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.450 seconds
[2025-12-16T13:34:22.005+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:34:22.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:34:22.007+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:34:22.007+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:34:22.370+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:34:22.400+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:34:22.399+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:34:22.412+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:34:22.411+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:34:22.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.449 seconds
[2025-12-16T13:34:53.319+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:34:53.320+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:34:53.321+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:34:53.321+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:34:53.675+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:34:53.702+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:34:53.701+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:34:53.713+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:34:53.713+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:34:53.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.414 seconds
[2025-12-16T13:35:23.799+0000] {processor.py:161} INFO - Started process (PID=843) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:35:23.801+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:35:23.802+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:35:23.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:35:24.178+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:35:24.209+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:35:24.209+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:35:24.222+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:35:24.222+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:35:24.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.445 seconds
[2025-12-16T13:35:55.068+0000] {processor.py:161} INFO - Started process (PID=854) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:35:55.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:35:55.070+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:35:55.070+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:35:55.425+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:35:55.454+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:35:55.453+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:35:55.620+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:35:55.620+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:35:55.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.572 seconds
[2025-12-16T13:36:26.348+0000] {processor.py:161} INFO - Started process (PID=865) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:36:26.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:36:26.350+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:36:26.350+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:36:26.718+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:36:26.746+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:36:26.746+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:36:26.924+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:36:26.924+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:36:26.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.615 seconds
[2025-12-16T13:36:57.688+0000] {processor.py:161} INFO - Started process (PID=876) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:36:57.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:36:57.691+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:36:57.690+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:36:58.082+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:36:58.111+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:36:58.111+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:36:58.124+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:36:58.124+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:36:58.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.477 seconds
[2025-12-16T13:37:29.014+0000] {processor.py:161} INFO - Started process (PID=887) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:37:29.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:37:29.016+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:37:29.016+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:37:29.374+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:37:29.406+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:37:29.405+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:37:29.420+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:37:29.419+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:37:29.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.429 seconds
[2025-12-16T13:38:00.378+0000] {processor.py:161} INFO - Started process (PID=898) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:38:00.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:38:00.382+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:38:00.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:38:00.829+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:38:00.865+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:38:00.864+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:38:00.880+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:38:00.880+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:38:00.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.548 seconds
[2025-12-16T13:38:31.714+0000] {processor.py:161} INFO - Started process (PID=909) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:38:31.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:38:31.716+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:38:31.716+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:38:32.074+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:38:32.103+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:38:32.102+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:38:32.115+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:38:32.115+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:38:32.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.614 seconds
[2025-12-16T13:39:03.095+0000] {processor.py:161} INFO - Started process (PID=925) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:39:03.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:39:03.097+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:39:03.097+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:39:03.443+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:39:03.470+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:39:03.470+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:39:03.636+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:39:03.635+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:39:03.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.581 seconds
[2025-12-16T13:39:34.445+0000] {processor.py:161} INFO - Started process (PID=936) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:39:34.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:39:34.448+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:39:34.447+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:39:35.066+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:39:35.110+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:39:35.110+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:39:35.129+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:39:35.129+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:39:35.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.716 seconds
[2025-12-16T13:40:05.807+0000] {processor.py:161} INFO - Started process (PID=947) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:40:05.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:40:05.809+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:40:05.809+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:40:06.177+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:40:06.204+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:40:06.203+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:40:06.215+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:40:06.215+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:40:06.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.450 seconds
[2025-12-16T13:40:37.156+0000] {processor.py:161} INFO - Started process (PID=958) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:40:37.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:40:37.159+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:40:37.159+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:40:37.519+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:40:37.548+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:40:37.548+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:40:37.560+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:40:37.560+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:40:37.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.444 seconds
[2025-12-16T13:41:07.681+0000] {processor.py:161} INFO - Started process (PID=969) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:41:07.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:41:07.683+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:41:07.683+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:41:08.059+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:41:08.091+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:41:08.091+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:41:08.105+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:41:08.104+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:41:08.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.448 seconds
[2025-12-16T13:41:38.889+0000] {processor.py:161} INFO - Started process (PID=980) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:41:38.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:41:38.892+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:41:38.891+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:41:39.242+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:41:39.271+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:41:39.270+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:41:39.284+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:41:39.283+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:41:39.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.605 seconds
[2025-12-16T13:42:10.237+0000] {processor.py:161} INFO - Started process (PID=991) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:42:10.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:42:10.240+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:42:10.240+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:42:10.621+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:42:10.649+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:42:10.649+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:42:10.822+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:42:10.822+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:42:10.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.607 seconds
[2025-12-16T13:42:41.567+0000] {processor.py:161} INFO - Started process (PID=1002) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:42:41.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:42:41.569+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:42:41.569+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:42:41.923+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:42:41.951+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:42:41.950+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:42:41.963+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:42:41.962+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:42:42.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.436 seconds
[2025-12-16T13:43:12.898+0000] {processor.py:161} INFO - Started process (PID=1013) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:43:12.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:43:12.901+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:43:12.900+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:43:13.277+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:43:13.306+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:43:13.305+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:43:13.318+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:43:13.318+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:43:13.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.443 seconds
[2025-12-16T13:43:44.233+0000] {processor.py:161} INFO - Started process (PID=1024) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:43:44.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:43:44.236+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:43:44.235+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:43:44.596+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:43:44.625+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:43:44.625+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:43:44.637+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:43:44.637+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:43:44.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.424 seconds
[2025-12-16T13:44:15.571+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:44:15.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:44:15.574+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:44:15.573+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:44:15.930+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:44:15.958+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:44:15.957+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:44:15.970+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:44:15.970+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:44:16.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.595 seconds
[2025-12-16T13:44:46.893+0000] {processor.py:161} INFO - Started process (PID=1046) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:44:46.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:44:46.897+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:44:46.896+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:44:47.375+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:44:47.409+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:44:47.409+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:44:47.616+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:44:47.616+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:44:47.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.753 seconds
[2025-12-16T13:45:18.272+0000] {processor.py:161} INFO - Started process (PID=1057) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:45:18.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:45:18.274+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:45:18.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:45:18.645+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:45:18.676+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:45:18.676+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:45:18.869+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:45:18.869+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:45:18.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.616 seconds
[2025-12-16T13:45:49.639+0000] {processor.py:161} INFO - Started process (PID=1068) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:45:49.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:45:49.641+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:45:49.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:45:50.030+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:45:50.062+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:45:50.062+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:45:50.076+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:45:50.076+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:45:50.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.479 seconds
[2025-12-16T13:46:20.958+0000] {processor.py:161} INFO - Started process (PID=1079) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:46:20.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:46:20.961+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:46:20.961+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:46:21.367+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:46:21.404+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:46:21.403+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:46:21.420+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:46:21.420+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:46:21.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.491 seconds
[2025-12-16T13:48:04.665+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:48:04.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:48:04.669+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:48:04.669+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:48:06.255+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:48:06.297+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:48:06.297+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:48:06.313+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:48:06.313+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:48:06.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.674 seconds
[2025-12-16T13:48:37.235+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:48:37.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:48:37.237+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:48:37.237+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:48:37.623+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:48:37.652+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:48:37.651+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:48:37.665+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:48:37.665+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:48:37.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.655 seconds
[2025-12-16T13:49:08.577+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:49:08.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:49:08.581+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:49:08.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:49:09.355+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:49:09.415+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:49:09.415+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:49:09.447+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:49:09.447+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:49:09.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.909 seconds
[2025-12-16T13:49:40.034+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:49:40.035+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:49:40.036+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:49:40.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:49:40.523+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:49:40.571+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:49:40.570+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:49:40.604+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:49:40.603+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:49:40.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.610 seconds
[2025-12-16T13:50:11.438+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:50:11.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:50:11.442+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:50:11.441+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:50:12.025+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:50:12.112+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:50:12.111+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:50:12.142+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:50:12.142+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:50:12.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.756 seconds
[2025-12-16T13:50:42.803+0000] {processor.py:161} INFO - Started process (PID=260) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:50:42.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:50:42.806+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:50:42.805+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:50:43.435+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:50:43.471+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:50:43.470+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:50:43.486+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:50:43.485+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:50:43.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.728 seconds
[2025-12-16T13:51:14.233+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:51:14.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:51:14.238+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:51:14.237+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:51:14.990+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:51:15.038+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:51:15.037+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:51:15.067+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:51:15.067+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:51:15.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.893 seconds
[2025-12-16T13:51:45.645+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:51:45.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:51:45.648+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:51:45.648+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:51:46.229+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:51:46.278+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:51:46.277+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:51:46.303+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:51:46.303+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:51:46.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.893 seconds
[2025-12-16T13:52:17.018+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:52:17.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:52:17.021+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:52:17.020+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:52:17.527+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:52:17.568+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:52:17.567+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:52:17.586+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:52:17.586+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:52:17.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.598 seconds
[2025-12-16T13:52:48.401+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:52:48.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:52:48.404+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:52:48.404+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:52:48.952+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:52:48.990+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:52:48.990+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:52:49.008+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:52:49.008+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:52:49.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.640 seconds
[2025-12-16T13:53:19.829+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:53:19.831+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:53:19.833+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:53:19.833+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:53:20.356+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:53:20.395+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:53:20.395+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:53:20.412+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:53:20.411+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:53:20.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.616 seconds
[2025-12-16T13:53:51.213+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:53:51.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:53:51.216+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:53:51.215+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:53:51.779+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:53:51.813+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:53:51.813+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:53:51.829+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:53:51.829+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:53:51.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.644 seconds
[2025-12-16T13:54:22.585+0000] {processor.py:161} INFO - Started process (PID=340) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:54:22.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:54:22.588+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:54:22.588+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:54:23.097+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:54:23.135+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:54:23.134+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:54:23.153+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:54:23.152+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:54:23.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.599 seconds
[2025-12-16T13:54:53.940+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:54:53.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:54:53.943+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:54:53.942+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:54:54.424+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:54:54.459+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:54:54.459+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:54:54.477+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:54:54.477+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:54:54.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.835 seconds
[2025-12-16T13:55:25.660+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:55:25.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:55:25.663+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:55:25.662+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:55:26.224+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:55:26.272+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:55:26.271+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:55:26.291+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:55:26.291+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:55:26.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.673 seconds
[2025-12-16T13:55:56.466+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:55:56.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:55:56.469+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:55:56.469+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:55:57.006+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:55:57.048+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:55:57.047+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:55:57.066+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:55:57.066+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:55:57.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.637 seconds
[2025-12-16T13:56:27.849+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:56:27.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:56:27.852+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:56:27.852+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:56:28.396+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:56:28.435+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:56:28.434+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:56:28.451+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:56:28.450+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:56:28.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.631 seconds
[2025-12-16T13:56:59.229+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:56:59.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:56:59.232+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:56:59.232+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:56:59.766+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:56:59.805+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:56:59.805+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:56:59.823+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:56:59.823+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:56:59.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.626 seconds
[2025-12-16T13:57:30.594+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:57:30.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:57:30.597+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:57:30.597+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:57:31.118+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:57:31.159+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:57:31.158+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:57:31.177+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:57:31.176+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:57:31.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.618 seconds
[2025-12-16T13:58:01.974+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:58:01.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:58:01.978+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:58:01.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:58:02.484+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:58:02.525+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:58:02.524+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:58:02.543+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:58:02.543+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:58:02.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.602 seconds
[2025-12-16T13:58:33.397+0000] {processor.py:161} INFO - Started process (PID=428) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:58:33.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:58:33.401+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:58:33.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:58:33.949+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:58:33.988+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:58:33.988+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:58:34.006+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:58:34.006+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:58:34.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.646 seconds
[2025-12-16T13:59:04.754+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:59:04.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:59:04.759+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:59:04.758+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:59:05.270+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:59:05.309+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:59:05.308+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:59:05.325+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:59:05.324+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:59:05.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.600 seconds
[2025-12-16T13:59:36.108+0000] {processor.py:161} INFO - Started process (PID=450) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:59:36.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T13:59:36.111+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:59:36.111+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:59:36.639+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T13:59:36.676+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:59:36.675+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T13:59:36.692+0000] {logging_mixin.py:188} INFO - [2025-12-16T13:59:36.692+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T13:59:36.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.612 seconds
[2025-12-16T14:00:07.471+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:00:07.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:00:07.475+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:00:07.475+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:00:07.991+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:00:08.026+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:00:08.025+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:00:08.041+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:00:08.040+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:00:08.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.603 seconds
[2025-12-16T14:00:38.827+0000] {processor.py:161} INFO - Started process (PID=472) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:00:38.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:00:38.830+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:00:38.830+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:00:39.513+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:00:39.557+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:00:39.557+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:00:39.580+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:00:39.579+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:00:39.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.067 seconds
[2025-12-16T14:01:10.158+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:01:10.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:01:10.161+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:01:10.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:01:10.735+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:01:10.772+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:01:10.771+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:01:10.792+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:01:10.791+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:01:10.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.665 seconds
[2025-12-16T14:01:41.483+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:01:41.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:01:41.485+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:01:41.485+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:01:42.037+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:01:42.078+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:01:42.077+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:01:42.095+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:01:42.095+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:01:42.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.644 seconds
[2025-12-16T14:02:12.858+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:02:12.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:02:12.861+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:02:12.860+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:02:13.389+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:02:13.429+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:02:13.428+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:02:13.445+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:02:13.445+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:02:13.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.615 seconds
[2025-12-16T14:02:44.223+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:02:44.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:02:44.226+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:02:44.226+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:02:44.807+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:02:44.843+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:02:44.842+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:02:44.859+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:02:44.858+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:02:44.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.665 seconds
[2025-12-16T14:03:15.618+0000] {processor.py:161} INFO - Started process (PID=527) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:03:15.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:03:15.621+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:03:15.621+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:03:16.167+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:03:16.203+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:03:16.202+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:03:16.219+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:03:16.218+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:03:16.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.636 seconds
[2025-12-16T14:03:47.042+0000] {processor.py:161} INFO - Started process (PID=543) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:03:47.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:03:47.045+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:03:47.044+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:03:47.555+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:03:47.591+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:03:47.590+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:03:47.608+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:03:47.608+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:03:47.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.802 seconds
[2025-12-16T14:04:18.461+0000] {processor.py:161} INFO - Started process (PID=554) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:04:18.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:04:18.464+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:04:18.463+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:04:18.971+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:04:19.009+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:04:19.008+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:04:19.028+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:04:19.028+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:04:19.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.598 seconds
[2025-12-16T14:04:49.824+0000] {processor.py:161} INFO - Started process (PID=565) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:04:49.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:04:49.828+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:04:49.827+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:04:50.320+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:04:50.357+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:04:50.357+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:04:50.373+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:04:50.373+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:04:50.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.583 seconds
[2025-12-16T14:05:21.180+0000] {processor.py:161} INFO - Started process (PID=576) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:05:21.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:05:21.183+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:05:21.183+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:05:21.669+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:05:21.705+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:05:21.704+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:05:21.721+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:05:21.721+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:05:21.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.571 seconds
[2025-12-16T14:05:52.526+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:05:52.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:05:52.530+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:05:52.530+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:05:53.003+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:05:53.043+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:05:53.043+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:05:53.066+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:05:53.065+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:05:53.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.579 seconds
[2025-12-16T14:06:23.904+0000] {processor.py:161} INFO - Started process (PID=598) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:06:23.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:06:23.907+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:06:23.907+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:06:24.419+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:06:24.458+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:06:24.457+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:06:24.476+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:06:24.476+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:06:24.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.610 seconds
[2025-12-16T14:06:55.297+0000] {processor.py:161} INFO - Started process (PID=609) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:06:55.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:06:55.301+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:06:55.301+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:06:55.850+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:06:55.891+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:06:55.890+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:06:55.912+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:06:55.912+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:06:56.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.882 seconds
[2025-12-16T14:07:26.632+0000] {processor.py:161} INFO - Started process (PID=620) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:07:26.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:07:26.634+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:07:26.634+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:07:27.217+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:07:27.258+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:07:27.257+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:07:27.278+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:07:27.277+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:07:27.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.678 seconds
[2025-12-16T14:07:57.999+0000] {processor.py:161} INFO - Started process (PID=631) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:07:58.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:07:58.002+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:07:58.002+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:07:58.417+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:07:58.448+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:07:58.448+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:07:58.462+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:07:58.462+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:07:58.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.502 seconds
[2025-12-16T14:08:28.596+0000] {processor.py:161} INFO - Started process (PID=645) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:08:28.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:08:28.598+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:08:28.598+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:08:29.022+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:08:29.053+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:08:29.053+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:08:29.066+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:08:29.066+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:08:29.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.493 seconds
[2025-12-16T14:08:59.800+0000] {processor.py:161} INFO - Started process (PID=656) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:08:59.801+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:08:59.802+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:08:59.801+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:09:00.171+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:09:00.203+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:09:00.203+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:09:00.217+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:09:00.217+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:09:00.239+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.443 seconds
[2025-12-16T14:09:31.146+0000] {processor.py:161} INFO - Started process (PID=667) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:09:31.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:09:31.148+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:09:31.148+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:09:31.503+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:09:31.532+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:09:31.532+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:09:31.545+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:09:31.544+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:09:31.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.688 seconds
[2025-12-16T14:10:02.460+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:10:02.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:10:02.462+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:10:02.462+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:10:02.822+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:10:02.849+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:10:02.848+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:10:03.014+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:10:03.014+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:10:03.050+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.594 seconds
[2025-12-16T14:10:33.787+0000] {processor.py:161} INFO - Started process (PID=689) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:10:33.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:10:33.790+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:10:33.789+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:10:34.169+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:10:34.202+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:10:34.201+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:10:34.215+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:10:34.214+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:10:34.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.452 seconds
[2025-12-16T14:11:05.103+0000] {processor.py:161} INFO - Started process (PID=700) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:11:05.104+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:11:05.105+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:11:05.105+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:11:05.459+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:11:05.488+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:11:05.487+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:11:05.501+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:11:05.501+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:11:05.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.442 seconds
[2025-12-16T14:11:36.440+0000] {processor.py:161} INFO - Started process (PID=711) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:11:36.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:11:36.443+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:11:36.442+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:11:36.847+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:11:36.880+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:11:36.879+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:11:36.895+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:11:36.895+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:11:36.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.501 seconds
[2025-12-16T14:12:07.758+0000] {processor.py:161} INFO - Started process (PID=722) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:12:07.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:12:07.761+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:12:07.761+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:12:08.205+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:12:08.239+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:12:08.239+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:12:08.254+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:12:08.253+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:12:08.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.541 seconds
[2025-12-16T14:12:39.120+0000] {processor.py:161} INFO - Started process (PID=733) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:12:39.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:12:39.122+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:12:39.122+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:12:39.501+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:12:39.528+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:12:39.528+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:12:39.541+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:12:39.540+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:12:39.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.613 seconds
[2025-12-16T14:13:10.476+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:13:10.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:13:10.478+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:13:10.478+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:13:10.858+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:13:10.886+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:13:10.885+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:13:10.899+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:13:10.899+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:13:10.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.463 seconds
[2025-12-16T14:13:41.801+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:13:41.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:13:41.804+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:13:41.804+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:13:42.232+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:13:42.264+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:13:42.264+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:13:42.278+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:13:42.278+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:13:42.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.503 seconds
[2025-12-16T14:14:13.136+0000] {processor.py:161} INFO - Started process (PID=766) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:14:13.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:14:13.139+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:14:13.138+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:14:13.525+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:14:13.557+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:14:13.557+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:14:13.570+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:14:13.570+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:14:13.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.457 seconds
[2025-12-16T14:14:44.491+0000] {processor.py:161} INFO - Started process (PID=777) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:14:44.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:14:44.493+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:14:44.493+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:14:44.856+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:14:44.884+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:14:44.883+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:14:44.895+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:14:44.895+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:14:44.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.424 seconds
[2025-12-16T14:15:15.823+0000] {processor.py:161} INFO - Started process (PID=788) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:15:15.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:15:15.825+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:15:15.825+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:15:16.316+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:15:16.354+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:15:16.354+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:15:16.371+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:15:16.370+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:15:16.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.766 seconds
[2025-12-16T14:15:47.154+0000] {processor.py:161} INFO - Started process (PID=799) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:15:47.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:15:47.157+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:15:47.156+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:15:47.560+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:15:47.590+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:15:47.590+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:15:47.795+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:15:47.794+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:15:47.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.664 seconds
[2025-12-16T14:16:18.510+0000] {processor.py:161} INFO - Started process (PID=810) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:16:18.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:16:18.513+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:16:18.512+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:16:18.883+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:16:18.914+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:16:18.913+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:16:18.926+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:16:18.926+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:16:18.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.438 seconds
[2025-12-16T14:16:49.821+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:16:49.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:16:49.823+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:16:49.823+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:16:50.289+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:16:50.326+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:16:50.325+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:16:50.340+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:16:50.340+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:16:50.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.549 seconds
[2025-12-16T14:17:21.128+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:17:21.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:17:21.130+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:17:21.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:17:21.511+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:17:21.539+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:17:21.539+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:17:21.551+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:17:21.551+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:17:21.568+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.443 seconds
[2025-12-16T14:17:52.476+0000] {processor.py:161} INFO - Started process (PID=843) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:17:52.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:17:52.478+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:17:52.478+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:17:53.180+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:17:53.215+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:17:53.214+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:17:53.229+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:17:53.228+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:17:53.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.777 seconds
[2025-12-16T14:18:23.874+0000] {processor.py:161} INFO - Started process (PID=854) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:18:23.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:18:23.877+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:18:23.876+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:18:24.300+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:18:24.334+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:18:24.333+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:18:24.348+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:18:24.348+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:18:24.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.766 seconds
[2025-12-16T14:19:46.712+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:19:46.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:19:46.715+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:19:46.715+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:19:48.607+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:19:48.660+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:19:48.660+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:19:48.677+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:19:48.677+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:19:48.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.995 seconds
[2025-12-16T14:20:19.214+0000] {processor.py:161} INFO - Started process (PID=211) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:20:19.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:20:19.217+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:20:19.216+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:20:19.596+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:20:19.647+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:20:19.646+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:20:19.660+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:20:19.660+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:20:19.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.656 seconds
[2025-12-16T14:20:50.578+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:20:50.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:20:50.581+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:20:50.581+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:20:51.060+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:20:51.096+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:20:51.095+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:20:51.114+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:20:51.113+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:20:51.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.564 seconds
[2025-12-16T14:21:21.939+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:21:21.940+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:21:21.942+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:21:21.941+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:21:22.426+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:21:22.468+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:21:22.467+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:21:22.492+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:21:22.491+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:21:22.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.596 seconds
[2025-12-16T14:21:53.308+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:21:53.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:21:53.312+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:21:53.311+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:21:53.860+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:21:53.906+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:21:53.906+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:21:53.928+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:21:53.927+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:21:53.956+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.653 seconds
[2025-12-16T14:22:24.689+0000] {processor.py:161} INFO - Started process (PID=261) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:22:24.691+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:22:24.693+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:22:24.692+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:22:25.184+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:22:25.220+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:22:25.219+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:22:25.235+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:22:25.235+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:22:25.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.576 seconds
[2025-12-16T14:22:55.357+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:22:55.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:22:55.361+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:22:55.360+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:22:56.014+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:22:56.068+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:22:56.067+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:22:56.091+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:22:56.090+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:22:56.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.785 seconds
[2025-12-16T14:23:26.420+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:23:26.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:23:26.424+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:23:26.423+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:23:26.884+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:23:26.918+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:23:26.918+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:23:26.934+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:23:26.933+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:23:27.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.721 seconds
[2025-12-16T14:23:57.839+0000] {processor.py:161} INFO - Started process (PID=297) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:23:57.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:23:57.841+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:23:57.841+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:23:58.269+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:23:58.298+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:23:58.298+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:23:58.313+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:23:58.313+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:23:58.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.496 seconds
[2025-12-16T14:24:29.186+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:24:29.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:24:29.188+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:24:29.188+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:24:29.572+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:24:29.601+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:24:29.601+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:24:29.614+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:24:29.613+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:24:29.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.447 seconds
[2025-12-16T14:25:00.515+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:25:00.516+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:25:00.518+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:25:00.517+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:25:00.900+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:25:00.926+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:25:00.926+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:25:00.939+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:25:00.939+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:25:00.956+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.444 seconds
[2025-12-16T14:25:31.013+0000] {processor.py:161} INFO - Started process (PID=330) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:25:31.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:25:31.016+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:25:31.015+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:25:31.407+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:25:31.436+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:25:31.436+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:25:31.448+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:25:31.448+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:25:31.485+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.476 seconds
[2025-12-16T14:26:02.287+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:26:02.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:26:02.290+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:26:02.290+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:26:02.830+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:26:02.860+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:26:02.860+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:26:02.874+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:26:02.873+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:26:02.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.614 seconds
[2025-12-16T14:26:33.638+0000] {processor.py:161} INFO - Started process (PID=355) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:26:33.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:26:33.641+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:26:33.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:26:33.993+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:26:34.023+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:26:34.022+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:26:34.038+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:26:34.038+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:26:34.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.628 seconds
[2025-12-16T14:27:04.974+0000] {processor.py:161} INFO - Started process (PID=366) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:27:04.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:27:04.976+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:27:04.976+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:27:05.338+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:27:05.371+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:27:05.370+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:27:05.385+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:27:05.384+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:27:05.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.432 seconds
[2025-12-16T14:27:36.314+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:27:36.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:27:36.316+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:27:36.316+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:27:36.700+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:27:36.733+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:27:36.733+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:27:36.749+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:27:36.748+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:27:36.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.482 seconds
[2025-12-16T14:28:07.638+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:28:07.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:28:07.640+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:28:07.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:28:08.007+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:28:08.051+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:28:08.051+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:28:08.063+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:28:08.063+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:28:08.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.446 seconds
[2025-12-16T14:28:38.975+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:28:38.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:28:38.977+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:28:38.976+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:28:39.328+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:28:39.358+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:28:39.358+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:28:39.372+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:28:39.372+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:28:39.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.441 seconds
[2025-12-16T14:29:10.282+0000] {processor.py:161} INFO - Started process (PID=410) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:29:10.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:29:10.284+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:29:10.283+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:29:10.700+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:29:10.739+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:29:10.738+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:29:10.755+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:29:10.755+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:29:10.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.504 seconds
[2025-12-16T14:29:41.622+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:29:41.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:29:41.624+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:29:41.624+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:29:41.987+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:29:42.015+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:29:42.015+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:29:42.030+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:29:42.030+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:29:42.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.602 seconds
[2025-12-16T14:30:12.953+0000] {processor.py:161} INFO - Started process (PID=432) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:30:12.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:30:12.955+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:30:12.955+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:30:13.326+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:30:13.356+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:30:13.356+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:30:13.368+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:30:13.368+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:30:13.385+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.436 seconds
[2025-12-16T14:30:44.253+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:30:44.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:30:44.256+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:30:44.256+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:30:44.707+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:30:44.739+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:30:44.738+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:30:44.752+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:30:44.752+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:30:44.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.524 seconds
[2025-12-16T14:31:15.592+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:31:15.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:31:15.596+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:31:15.596+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:31:15.977+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:31:16.006+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:31:16.006+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:31:16.019+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:31:16.019+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:31:16.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.453 seconds
[2025-12-16T14:31:46.952+0000] {processor.py:161} INFO - Started process (PID=465) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:31:46.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:31:46.955+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:31:46.955+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:31:47.344+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:31:47.374+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:31:47.373+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:31:47.386+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:31:47.386+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:31:47.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.478 seconds
[2025-12-16T14:32:18.244+0000] {processor.py:161} INFO - Started process (PID=476) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:32:18.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:32:18.247+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:32:18.247+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:32:18.658+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:32:18.687+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:32:18.686+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:32:18.699+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:32:18.699+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:32:18.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.646 seconds
[2025-12-16T14:32:49.616+0000] {processor.py:161} INFO - Started process (PID=487) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:32:49.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:32:49.620+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:32:49.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:32:50.024+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:32:50.053+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:32:50.052+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:32:50.218+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:32:50.218+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:32:50.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.624 seconds
[2025-12-16T14:33:20.971+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:33:20.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:33:20.974+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:33:20.974+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:33:21.367+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:33:21.396+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:33:21.395+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:33:21.408+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:33:21.408+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:33:21.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.458 seconds
[2025-12-16T14:33:51.492+0000] {processor.py:161} INFO - Started process (PID=509) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:33:51.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:33:51.497+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:33:51.496+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:33:51.961+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:33:51.998+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:33:51.998+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:33:52.012+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:33:52.012+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:33:52.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.566 seconds
[2025-12-16T14:34:22.695+0000] {processor.py:161} INFO - Started process (PID=520) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:34:22.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:34:22.698+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:34:22.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:34:23.104+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:34:23.134+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:34:23.134+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:34:23.147+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:34:23.147+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:34:23.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.506 seconds
[2025-12-16T14:34:54.084+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:34:54.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:34:54.086+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:34:54.086+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:34:54.466+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:34:54.494+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:34:54.493+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:34:54.507+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:34:54.506+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:34:54.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.453 seconds
[2025-12-16T14:35:25.383+0000] {processor.py:161} INFO - Started process (PID=542) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:35:25.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:35:25.385+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:35:25.385+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:35:25.759+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:35:25.788+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:35:25.788+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:35:25.801+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:35:25.801+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:35:25.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.612 seconds
[2025-12-16T14:35:56.749+0000] {processor.py:161} INFO - Started process (PID=553) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:35:56.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:35:56.751+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:35:56.751+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:35:57.113+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:35:57.142+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:35:57.141+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:35:57.307+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:35:57.307+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:35:57.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.578 seconds
[2025-12-16T14:36:28.156+0000] {processor.py:161} INFO - Started process (PID=564) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:36:28.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:36:28.158+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:36:28.158+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:36:28.514+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:36:28.543+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:36:28.542+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:36:28.555+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:36:28.554+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:36:28.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.421 seconds
[2025-12-16T14:36:58.684+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:36:58.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:36:58.686+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:36:58.686+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:36:59.131+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:36:59.163+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:36:59.163+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:36:59.177+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:36:59.176+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:36:59.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.518 seconds
[2025-12-16T14:37:29.891+0000] {processor.py:161} INFO - Started process (PID=591) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:37:29.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:37:29.893+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:37:29.893+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:37:30.307+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:37:30.340+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:37:30.340+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:37:30.353+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:37:30.353+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:37:30.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.485 seconds
[2025-12-16T14:38:01.240+0000] {processor.py:161} INFO - Started process (PID=602) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:38:01.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:38:01.242+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:38:01.242+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:38:01.621+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:38:01.652+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:38:01.651+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:38:01.664+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:38:01.664+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:38:01.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.467 seconds
[2025-12-16T14:38:31.829+0000] {processor.py:161} INFO - Started process (PID=613) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:38:31.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:38:31.831+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:38:31.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:38:32.510+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:38:32.545+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:38:32.545+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:38:32.562+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:38:32.562+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:38:32.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.937 seconds
[2025-12-16T14:39:02.998+0000] {processor.py:161} INFO - Started process (PID=624) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:39:02.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:39:03.000+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:39:03.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:39:03.523+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:39:03.550+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:39:03.549+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:39:03.563+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:39:03.563+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:39:03.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.605 seconds
[2025-12-16T14:40:16.732+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:40:16.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:40:16.735+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:40:16.734+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:40:18.368+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:40:18.407+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:40:18.407+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:40:18.423+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:40:18.422+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:40:18.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.716 seconds
[2025-12-16T14:40:49.289+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:40:49.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:40:49.292+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:40:49.292+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:40:49.911+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:40:49.951+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:40:49.950+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:40:49.967+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:40:49.967+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:40:50.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.899 seconds
[2025-12-16T14:41:20.502+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:41:20.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:41:20.505+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:41:20.505+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:41:20.959+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:41:20.990+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:41:20.989+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:41:21.004+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:41:21.004+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:41:21.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.528 seconds
[2025-12-16T14:41:51.879+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:41:51.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:41:51.882+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:41:51.882+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:41:52.473+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:41:52.511+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:41:52.511+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:41:52.527+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:41:52.527+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:41:52.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.678 seconds
[2025-12-16T14:42:23.289+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:42:23.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:42:23.292+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:42:23.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:42:23.772+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:42:23.813+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:42:23.812+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:42:23.830+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:42:23.830+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:42:23.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.572 seconds
[2025-12-16T14:42:54.670+0000] {processor.py:161} INFO - Started process (PID=260) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:42:54.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:42:54.672+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:42:54.672+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:42:55.159+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:42:55.199+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:42:55.198+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:42:55.218+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:42:55.218+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:42:55.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.579 seconds
[2025-12-16T14:43:25.339+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:43:25.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:43:25.343+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:43:25.343+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:43:25.981+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:43:26.031+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:43:26.030+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:43:26.051+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:43:26.051+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:43:26.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.772 seconds
[2025-12-16T14:43:56.378+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:43:56.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:43:56.381+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:43:56.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:43:56.911+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:43:56.953+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:43:56.952+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:43:56.970+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:43:56.970+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:43:57.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.917 seconds
[2025-12-16T14:44:27.814+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:44:27.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:44:27.816+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:44:27.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:44:28.323+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:44:28.359+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:44:28.359+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:44:28.377+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:44:28.377+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:44:28.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.591 seconds
[2025-12-16T14:44:59.178+0000] {processor.py:161} INFO - Started process (PID=310) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:44:59.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:44:59.182+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:44:59.182+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:44:59.568+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:44:59.600+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:44:59.599+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:44:59.612+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:44:59.611+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:44:59.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.461 seconds
[2025-12-16T14:45:30.461+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:45:30.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:45:30.464+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:45:30.463+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:45:30.844+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:45:30.869+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:45:30.868+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:45:30.880+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:45:30.880+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:45:30.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.440 seconds
[2025-12-16T14:46:01.808+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:46:01.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:46:01.811+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:46:01.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:46:02.188+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:46:02.216+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:46:02.216+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:46:02.229+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:46:02.228+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:46:02.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.442 seconds
[2025-12-16T14:46:32.313+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:46:32.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:46:32.315+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:46:32.315+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:46:32.670+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:46:32.723+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:46:32.722+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:46:32.736+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:46:32.736+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:46:32.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.447 seconds
[2025-12-16T14:47:03.509+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:47:03.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:47:03.511+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:47:03.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:47:03.859+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:47:03.889+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:47:03.888+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:47:03.903+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:47:03.902+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:47:04.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.585 seconds
[2025-12-16T14:47:34.893+0000] {processor.py:161} INFO - Started process (PID=365) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:47:34.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:47:34.896+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:47:34.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:47:35.305+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:47:35.336+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:47:35.336+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:47:35.350+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:47:35.350+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:47:35.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.499 seconds
[2025-12-16T14:48:06.295+0000] {processor.py:161} INFO - Started process (PID=376) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:48:06.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:48:06.297+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:48:06.297+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:48:06.769+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:48:06.802+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:48:06.802+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:48:06.816+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:48:06.815+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:48:06.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.563 seconds
[2025-12-16T14:48:37.672+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:48:37.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:48:37.674+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:48:37.674+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:48:38.144+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:48:38.173+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:48:38.172+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:48:38.186+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:48:38.186+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:48:38.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.556 seconds
[2025-12-16T14:49:09.072+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:49:09.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:49:09.075+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:49:09.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:49:09.470+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:49:09.499+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:49:09.499+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:49:09.512+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:49:09.512+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:49:09.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.461 seconds
[2025-12-16T14:49:40.405+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:49:40.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:49:40.408+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:49:40.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:49:40.912+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:49:40.945+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:49:40.944+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:49:40.959+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:49:40.958+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:49:40.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.595 seconds
[2025-12-16T14:50:11.753+0000] {processor.py:161} INFO - Started process (PID=420) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:50:11.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:50:11.756+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:50:11.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:50:12.148+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:50:12.178+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:50:12.177+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:50:12.192+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:50:12.192+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:50:12.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.729 seconds
[2025-12-16T14:50:43.180+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:50:43.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:50:43.185+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:50:43.185+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:50:43.641+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:50:43.675+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:50:43.674+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:50:43.690+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:50:43.689+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:50:43.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.540 seconds
[2025-12-16T14:51:14.486+0000] {processor.py:161} INFO - Started process (PID=442) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:51:14.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:51:14.489+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:51:14.488+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:51:14.896+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:51:14.929+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:51:14.928+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:51:14.942+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:51:14.942+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:51:14.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.478 seconds
[2025-12-16T14:51:45.857+0000] {processor.py:161} INFO - Started process (PID=453) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:51:45.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:51:45.859+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:51:45.859+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:51:46.254+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:51:46.285+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:51:46.284+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:51:46.298+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:51:46.298+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:51:46.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.467 seconds
[2025-12-16T14:52:16.410+0000] {processor.py:161} INFO - Started process (PID=464) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:52:16.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:52:16.414+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:52:16.414+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:52:17.123+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:52:17.177+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:52:17.177+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:52:17.200+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:52:17.200+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:52:17.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.830 seconds
[2025-12-16T14:52:47.686+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:52:47.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:52:47.691+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:52:47.690+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:52:48.367+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:52:48.420+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:52:48.419+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:52:48.443+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:52:48.442+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:52:48.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.103 seconds
[2025-12-16T14:53:19.201+0000] {processor.py:161} INFO - Started process (PID=486) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:53:19.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:53:19.206+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:53:19.205+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:53:20.000+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:53:20.046+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:53:20.046+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:53:20.285+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:53:20.285+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:53:20.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.119 seconds
[2025-12-16T14:53:50.754+0000] {processor.py:161} INFO - Started process (PID=497) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:53:50.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:53:50.759+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:53:50.759+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:53:51.446+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:53:51.496+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:53:51.495+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:53:51.517+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:53:51.516+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:53:51.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.802 seconds
[2025-12-16T14:54:22.004+0000] {processor.py:161} INFO - Started process (PID=508) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:54:22.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:54:22.008+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:54:22.007+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:54:22.697+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:54:22.755+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:54:22.754+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:54:22.780+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:54:22.779+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:54:22.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.820 seconds
[2025-12-16T14:54:53.604+0000] {processor.py:161} INFO - Started process (PID=519) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:54:53.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T14:54:53.608+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:54:53.608+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:54:54.370+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T14:54:54.418+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:54:54.418+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T14:54:54.440+0000] {logging_mixin.py:188} INFO - [2025-12-16T14:54:54.440+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T14:54:54.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.876 seconds
[2025-12-16T15:15:34.213+0000] {processor.py:161} INFO - Started process (PID=530) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:15:34.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:15:34.220+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:15:34.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:15:34.743+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:15:34.776+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:15:34.776+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:15:34.790+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:15:34.790+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:15:34.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.605 seconds
[2025-12-16T15:16:05.680+0000] {processor.py:161} INFO - Started process (PID=548) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:16:05.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:16:05.682+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:16:05.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:16:06.018+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:16:06.046+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:16:06.046+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:16:06.058+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:16:06.058+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:16:06.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.419 seconds
[2025-12-16T15:16:36.147+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:16:36.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:16:36.149+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:16:36.149+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:16:36.534+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:16:36.563+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:16:36.563+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:16:36.577+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:16:36.577+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:16:36.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.647 seconds
[2025-12-16T15:17:07.347+0000] {processor.py:161} INFO - Started process (PID=570) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:17:07.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:17:07.349+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:17:07.349+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:17:07.702+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:17:07.730+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:17:07.729+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:17:07.743+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:17:07.743+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:17:07.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.440 seconds
[2025-12-16T15:17:38.706+0000] {processor.py:161} INFO - Started process (PID=581) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:17:38.708+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:17:38.708+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:17:38.708+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:17:39.182+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:17:39.218+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:17:39.217+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:17:39.231+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:17:39.231+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:17:39.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.552 seconds
[2025-12-16T15:18:10.038+0000] {processor.py:161} INFO - Started process (PID=592) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:18:10.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:18:10.040+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:18:10.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:18:10.404+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:18:10.433+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:18:10.432+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:18:10.446+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:18:10.445+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:18:10.485+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.450 seconds
[2025-12-16T15:18:41.389+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:18:41.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:18:41.392+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:18:41.391+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:18:41.791+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:18:41.819+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:18:41.819+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:18:41.831+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:18:41.831+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:18:41.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.463 seconds
[2025-12-16T15:19:12.744+0000] {processor.py:161} INFO - Started process (PID=614) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:19:12.746+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:19:12.747+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:19:12.747+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:19:13.102+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:19:13.131+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:19:13.130+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:19:13.142+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:19:13.142+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:19:13.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.440 seconds
[2025-12-16T15:19:43.242+0000] {processor.py:161} INFO - Started process (PID=625) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:19:43.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:19:43.244+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:19:43.244+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:19:43.661+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:19:43.693+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:19:43.692+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:19:43.708+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:19:43.708+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:19:43.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.694 seconds
[2025-12-16T15:20:14.442+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:20:14.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:20:14.444+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:20:14.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:20:14.893+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:20:14.923+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:20:14.923+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:20:14.936+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:20:14.936+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:20:14.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.516 seconds
[2025-12-16T15:20:45.833+0000] {processor.py:161} INFO - Started process (PID=647) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:20:45.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:20:45.836+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:20:45.836+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:20:46.250+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:20:46.296+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:20:46.296+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:20:46.311+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:20:46.310+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:20:46.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.504 seconds
[2025-12-16T15:21:17.169+0000] {processor.py:161} INFO - Started process (PID=658) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:21:17.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:21:17.172+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:21:17.171+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:21:17.541+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:21:17.568+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:21:17.568+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:21:17.581+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:21:17.581+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:21:17.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.455 seconds
[2025-12-16T15:21:48.477+0000] {processor.py:161} INFO - Started process (PID=669) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:21:48.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:21:48.479+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:21:48.478+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:21:48.850+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:21:48.879+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:21:48.878+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:21:48.890+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:21:48.890+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:21:48.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.454 seconds
[2025-12-16T15:22:19.819+0000] {processor.py:161} INFO - Started process (PID=680) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:22:19.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:22:19.823+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:22:19.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:22:20.207+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:22:20.236+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:22:20.236+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:22:20.251+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:22:20.251+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:22:20.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.627 seconds
[2025-12-16T15:22:51.146+0000] {processor.py:161} INFO - Started process (PID=691) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:22:51.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:22:51.148+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:22:51.147+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:22:51.562+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:22:51.592+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:22:51.592+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:22:51.773+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:22:51.772+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:22:51.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.647 seconds
[2025-12-16T15:23:22.522+0000] {processor.py:161} INFO - Started process (PID=702) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:23:22.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:23:22.523+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:23:22.523+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:23:22.872+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:23:22.902+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:23:22.901+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:23:22.914+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:23:22.913+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:23:22.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.411 seconds
[2025-12-16T15:23:53.015+0000] {processor.py:161} INFO - Started process (PID=713) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:23:53.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:23:53.017+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:23:53.017+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:23:53.363+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:23:53.392+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:23:53.391+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:23:53.404+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:23:53.404+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:23:53.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.433 seconds
[2025-12-16T15:24:24.229+0000] {processor.py:161} INFO - Started process (PID=724) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:24:24.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:24:24.232+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:24:24.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:24:24.603+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:24:24.631+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:24:24.630+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:24:24.643+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:24:24.643+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:24:24.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.436 seconds
[2025-12-16T15:24:55.543+0000] {processor.py:161} INFO - Started process (PID=735) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:24:55.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:24:55.546+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:24:55.545+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:24:55.956+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:24:55.987+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:24:55.986+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:24:56.001+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:24:56.000+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:24:56.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.480 seconds
[2025-12-16T15:25:26.876+0000] {processor.py:161} INFO - Started process (PID=746) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:25:26.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:25:26.878+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:25:26.878+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:25:27.290+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:25:27.319+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:25:27.318+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:25:27.330+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:25:27.330+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:25:27.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.647 seconds
[2025-12-16T15:25:58.233+0000] {processor.py:161} INFO - Started process (PID=757) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:25:58.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:25:58.235+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:25:58.235+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:25:58.653+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:25:58.687+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:25:58.687+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:25:58.702+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:25:58.702+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:25:58.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.513 seconds
[2025-12-16T15:26:29.575+0000] {processor.py:161} INFO - Started process (PID=768) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:26:29.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:26:29.578+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:26:29.578+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:26:30.286+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:26:30.320+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:26:30.320+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:26:30.333+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:26:30.333+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:26:30.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.780 seconds
[2025-12-16T15:27:00.927+0000] {processor.py:161} INFO - Started process (PID=779) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:27:00.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:27:00.929+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:27:00.929+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:27:01.291+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:27:01.320+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:27:01.320+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:27:01.334+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:27:01.334+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:27:01.352+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.428 seconds
[2025-12-16T15:27:31.413+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:27:31.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:27:31.417+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:27:31.416+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:27:32.026+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:27:32.060+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:27:32.060+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:27:32.075+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:27:32.075+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:27:32.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.686 seconds
[2025-12-16T15:28:02.615+0000] {processor.py:161} INFO - Started process (PID=801) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:28:02.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:28:02.617+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:28:02.617+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:28:03.051+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:28:03.085+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:28:03.084+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:28:03.102+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:28:03.102+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:28:03.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.722 seconds
[2025-12-16T15:28:33.927+0000] {processor.py:161} INFO - Started process (PID=812) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:28:33.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:28:33.929+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:28:33.929+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:28:34.303+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:28:34.334+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:28:34.333+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:28:34.514+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:28:34.514+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:28:34.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.609 seconds
[2025-12-16T15:29:05.301+0000] {processor.py:161} INFO - Started process (PID=823) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:29:05.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:29:05.304+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:29:05.303+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:29:05.739+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:29:05.772+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:29:05.771+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:29:05.784+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:29:05.783+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:29:05.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.527 seconds
[2025-12-16T15:29:36.623+0000] {processor.py:161} INFO - Started process (PID=834) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:29:36.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:29:36.625+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:29:36.624+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:29:37.014+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:29:37.044+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:29:37.043+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:29:37.059+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:29:37.059+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:29:37.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.463 seconds
[2025-12-16T15:30:07.975+0000] {processor.py:161} INFO - Started process (PID=845) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:30:07.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:30:07.977+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:30:07.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:30:08.633+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:30:08.663+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:30:08.663+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:30:08.675+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:30:08.675+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:30:08.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.722 seconds
[2025-12-16T15:30:39.354+0000] {processor.py:161} INFO - Started process (PID=856) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:30:39.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:30:39.356+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:30:39.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:30:39.748+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:30:39.778+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:30:39.778+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:30:39.791+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:30:39.791+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:30:39.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.460 seconds
[2025-12-16T15:31:10.666+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:31:10.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:31:10.669+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:31:10.669+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:31:11.100+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:31:11.132+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:31:11.131+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:31:11.146+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:31:11.146+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:31:11.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.686 seconds
[2025-12-16T15:31:41.987+0000] {processor.py:161} INFO - Started process (PID=878) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:31:41.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:31:41.989+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:31:41.989+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:31:42.538+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:31:42.575+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:31:42.574+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:31:42.588+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:31:42.588+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:31:42.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.627 seconds
[2025-12-16T15:32:13.279+0000] {processor.py:161} INFO - Started process (PID=889) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:32:13.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:32:13.282+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:32:13.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:32:13.679+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:32:13.708+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:32:13.707+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:32:13.721+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:32:13.721+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:32:13.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.483 seconds
[2025-12-16T15:32:44.621+0000] {processor.py:161} INFO - Started process (PID=900) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:32:44.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:32:44.622+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:32:44.622+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:32:44.977+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:32:45.006+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:32:45.005+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:32:45.018+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:32:45.017+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:32:45.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.420 seconds
[2025-12-16T15:33:15.963+0000] {processor.py:161} INFO - Started process (PID=911) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:33:15.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:33:15.966+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:33:15.965+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:33:16.538+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:33:16.569+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:33:16.568+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:33:16.582+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:33:16.581+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:33:16.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.642 seconds
[2025-12-16T15:33:47.338+0000] {processor.py:161} INFO - Started process (PID=927) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:33:47.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:33:47.340+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:33:47.340+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:33:47.681+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:33:47.708+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:33:47.708+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:33:47.721+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:33:47.721+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:33:47.917+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.582 seconds
[2025-12-16T15:34:18.650+0000] {processor.py:161} INFO - Started process (PID=938) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:34:18.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:34:18.652+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:34:18.652+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:34:19.029+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:34:19.057+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:34:19.056+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:34:19.224+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:34:19.224+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:34:19.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.594 seconds
[2025-12-16T15:34:49.979+0000] {processor.py:161} INFO - Started process (PID=949) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:34:49.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:34:49.981+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:34:49.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:34:50.419+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:34:50.451+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:34:50.451+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:34:50.464+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:34:50.464+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:34:50.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.508 seconds
[2025-12-16T15:35:21.325+0000] {processor.py:161} INFO - Started process (PID=960) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:35:21.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:35:21.327+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:35:21.327+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:35:21.919+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:35:21.965+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:35:21.965+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:35:21.981+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:35:21.981+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:35:22.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.686 seconds
[2025-12-16T15:35:52.709+0000] {processor.py:161} INFO - Started process (PID=971) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:35:52.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:35:52.711+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:35:52.710+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:35:53.065+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:35:53.097+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:35:53.097+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:35:53.111+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:35:53.111+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:35:53.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.427 seconds
[2025-12-16T15:36:23.203+0000] {processor.py:161} INFO - Started process (PID=982) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:36:23.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:36:23.205+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:36:23.204+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:36:23.796+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:36:23.826+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:36:23.825+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:36:23.838+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:36:23.838+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:36:23.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.657 seconds
[2025-12-16T15:36:54.410+0000] {processor.py:161} INFO - Started process (PID=993) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:36:54.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:36:54.412+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:36:54.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:36:54.792+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:36:54.822+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:36:54.822+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:36:54.836+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:36:54.835+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:36:55.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.632 seconds
[2025-12-16T15:37:25.755+0000] {processor.py:161} INFO - Started process (PID=1004) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:37:25.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:37:25.758+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:37:25.758+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:37:26.327+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:37:26.357+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:37:26.356+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:37:26.581+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:37:26.581+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:37:26.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.853 seconds
[2025-12-16T15:37:57.095+0000] {processor.py:161} INFO - Started process (PID=1015) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:37:57.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:37:57.098+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:37:57.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:37:57.460+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:37:57.488+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:37:57.487+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:37:57.500+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:37:57.500+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:37:57.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.431 seconds
[2025-12-16T15:38:27.601+0000] {processor.py:161} INFO - Started process (PID=1026) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:38:27.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:38:27.603+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:38:27.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:38:28.177+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:38:28.208+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:38:28.208+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:38:28.221+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:38:28.221+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:38:28.242+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.644 seconds
[2025-12-16T15:38:58.807+0000] {processor.py:161} INFO - Started process (PID=1037) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:38:58.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:38:58.810+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:38:58.809+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:38:59.171+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:38:59.200+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:38:59.200+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:38:59.212+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:38:59.212+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:38:59.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.448 seconds
[2025-12-16T15:39:30.132+0000] {processor.py:161} INFO - Started process (PID=1048) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:39:30.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:39:30.134+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:39:30.134+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:39:30.764+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:39:30.792+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:39:30.792+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:39:30.804+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:39:30.803+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:39:30.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.861 seconds
[2025-12-16T15:40:01.492+0000] {processor.py:161} INFO - Started process (PID=1059) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:40:01.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:40:01.494+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:40:01.494+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:40:01.875+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:40:01.904+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:40:01.904+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:40:02.071+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:40:02.071+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:40:02.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.628 seconds
[2025-12-16T15:40:32.915+0000] {processor.py:161} INFO - Started process (PID=1070) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:40:32.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:40:32.917+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:40:32.917+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:40:33.329+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:40:33.358+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:40:33.358+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:40:33.521+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:40:33.521+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:40:33.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.648 seconds
[2025-12-16T15:41:04.280+0000] {processor.py:161} INFO - Started process (PID=1081) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:41:04.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:41:04.284+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:41:04.283+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:41:04.833+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:41:04.874+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:41:04.873+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:41:04.890+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:41:04.889+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:41:04.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.638 seconds
[2025-12-16T15:41:35.602+0000] {processor.py:161} INFO - Started process (PID=1092) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:41:35.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:41:35.605+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:41:35.605+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:41:35.999+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:41:36.030+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:41:36.029+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:41:36.044+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:41:36.043+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:41:36.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.471 seconds
[2025-12-16T15:42:06.966+0000] {processor.py:161} INFO - Started process (PID=1103) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:42:06.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:42:06.969+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:42:06.968+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:42:07.354+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:42:07.383+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:42:07.383+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:42:07.396+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:42:07.396+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:42:07.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.474 seconds
[2025-12-16T15:42:38.300+0000] {processor.py:161} INFO - Started process (PID=1114) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:42:38.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:42:38.302+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:42:38.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:42:38.860+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:42:38.889+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:42:38.888+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:42:38.901+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:42:38.901+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:42:39.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.780 seconds
[2025-12-16T15:43:09.674+0000] {processor.py:161} INFO - Started process (PID=1125) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:43:09.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:43:09.675+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:43:09.675+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:43:10.021+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:43:10.048+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:43:10.047+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:43:10.235+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:43:10.235+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:43:10.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.585 seconds
[2025-12-16T15:43:40.995+0000] {processor.py:161} INFO - Started process (PID=1136) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:43:40.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:43:40.997+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:43:40.996+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:43:41.638+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:43:41.668+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:43:41.667+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:43:41.681+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:43:41.680+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:43:41.699+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.707 seconds
[2025-12-16T15:44:12.353+0000] {processor.py:161} INFO - Started process (PID=1147) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:44:12.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:44:12.357+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:44:12.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:44:12.782+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:44:12.811+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:44:12.811+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:44:12.824+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:44:12.824+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:44:12.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.492 seconds
[2025-12-16T15:44:43.661+0000] {processor.py:161} INFO - Started process (PID=1158) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:44:43.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:44:43.663+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:44:43.662+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:44:44.088+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:44:44.121+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:44:44.120+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:44:44.134+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:44:44.134+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:44:44.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.496 seconds
[2025-12-16T15:45:14.970+0000] {processor.py:161} INFO - Started process (PID=1169) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:45:14.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:45:14.972+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:45:14.972+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:45:15.559+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:45:15.594+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:45:15.594+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:45:15.608+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:45:15.607+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:45:15.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.821 seconds
[2025-12-16T15:45:46.349+0000] {processor.py:161} INFO - Started process (PID=1180) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:45:46.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:45:46.352+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:45:46.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:45:46.718+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:45:46.746+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:45:46.745+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:45:46.913+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:45:46.912+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:45:46.956+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.611 seconds
[2025-12-16T15:46:17.628+0000] {processor.py:161} INFO - Started process (PID=1191) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:46:17.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:46:17.630+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:46:17.630+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:46:18.232+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:46:18.266+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:46:18.266+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:46:18.429+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:46:18.429+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:46:18.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.821 seconds
[2025-12-16T15:46:49.019+0000] {processor.py:161} INFO - Started process (PID=1202) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:46:49.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:46:49.021+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:46:49.021+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:46:49.445+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:46:49.479+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:46:49.479+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:46:49.493+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:46:49.493+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:46:49.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.498 seconds
[2025-12-16T15:47:20.287+0000] {processor.py:161} INFO - Started process (PID=1213) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:47:20.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:47:20.289+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:47:20.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:47:20.989+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:47:21.032+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:47:21.031+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:47:21.044+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:47:21.044+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:47:21.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.784 seconds
[2025-12-16T15:47:51.586+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:47:51.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:47:51.588+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:47:51.588+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:47:51.934+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:47:51.961+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:47:51.960+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:47:51.973+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:47:51.973+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:47:52.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.428 seconds
[2025-12-16T15:48:22.888+0000] {processor.py:161} INFO - Started process (PID=1235) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:48:22.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:48:22.891+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:48:22.890+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:48:23.483+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:48:23.520+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:48:23.519+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:48:23.533+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:48:23.533+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:48:23.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.835 seconds
[2025-12-16T15:48:54.220+0000] {processor.py:161} INFO - Started process (PID=1246) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:48:54.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:48:54.225+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:48:54.224+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:48:54.758+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:48:54.800+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:48:54.799+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:48:55.047+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:48:55.046+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:48:55.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.871 seconds
[2025-12-16T15:49:25.504+0000] {processor.py:161} INFO - Started process (PID=1257) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:49:25.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:49:25.505+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:49:25.505+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:49:25.883+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:49:26.096+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:49:26.096+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:49:26.107+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:49:26.107+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:49:26.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.640 seconds
[2025-12-16T15:49:56.799+0000] {processor.py:161} INFO - Started process (PID=1268) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:49:56.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:49:56.801+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:49:56.801+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:49:57.143+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:49:57.171+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:49:57.171+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:49:57.184+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:49:57.183+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:49:57.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.425 seconds
[2025-12-16T15:50:27.336+0000] {processor.py:161} INFO - Started process (PID=1284) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:50:27.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:50:27.338+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:50:27.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:50:27.879+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:50:27.908+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:50:27.907+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:50:27.919+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:50:27.919+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:50:27.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.603 seconds
[2025-12-16T15:50:58.590+0000] {processor.py:161} INFO - Started process (PID=1295) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:50:58.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:50:58.592+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:50:58.592+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:50:58.929+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:50:58.955+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:50:58.955+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:50:58.967+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:50:58.967+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:50:59.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.571 seconds
[2025-12-16T15:51:29.919+0000] {processor.py:161} INFO - Started process (PID=1306) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:51:29.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:51:29.921+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:51:29.921+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:51:30.278+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:51:30.307+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:51:30.307+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:51:30.492+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:51:30.492+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:51:30.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.601 seconds
[2025-12-16T15:52:01.249+0000] {processor.py:161} INFO - Started process (PID=1317) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:52:01.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:52:01.252+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:52:01.251+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:52:01.622+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:52:01.651+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:52:01.650+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:52:01.806+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:52:01.805+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:52:01.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.595 seconds
[2025-12-16T15:52:32.623+0000] {processor.py:161} INFO - Started process (PID=1328) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:52:32.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:52:32.626+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:52:32.626+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:52:33.052+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:52:33.082+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:52:33.082+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:52:33.095+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:52:33.095+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:52:33.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.495 seconds
[2025-12-16T15:53:03.933+0000] {processor.py:161} INFO - Started process (PID=1339) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:53:03.935+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:53:03.936+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:53:03.935+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:53:04.296+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:53:04.324+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:53:04.324+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:53:04.338+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:53:04.337+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:53:04.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.429 seconds
[2025-12-16T15:53:34.415+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:53:34.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:53:34.417+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:53:34.417+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:53:34.991+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:53:35.017+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:53:35.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:53:35.028+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:53:35.028+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:53:35.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.635 seconds
[2025-12-16T15:54:05.618+0000] {processor.py:161} INFO - Started process (PID=1361) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:54:05.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:54:05.620+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:54:05.619+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:54:05.964+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:54:05.991+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:54:05.991+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:54:06.004+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:54:06.004+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:54:06.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.601 seconds
[2025-12-16T15:54:37.038+0000] {processor.py:161} INFO - Started process (PID=1372) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:54:37.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:54:37.042+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:54:37.041+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:54:37.495+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:54:37.529+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:54:37.528+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:54:37.767+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:54:37.766+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:54:37.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.778 seconds
[2025-12-16T15:55:08.404+0000] {processor.py:161} INFO - Started process (PID=1383) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:55:08.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:55:08.406+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:55:08.406+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:55:08.796+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:55:08.999+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:55:08.998+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:55:09.010+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:55:09.010+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:55:09.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.627 seconds
[2025-12-16T15:55:39.789+0000] {processor.py:161} INFO - Started process (PID=1394) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:55:39.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:55:39.791+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:55:39.791+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:55:40.187+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:55:40.217+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:55:40.216+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:55:40.231+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:55:40.231+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:55:40.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.466 seconds
[2025-12-16T15:56:11.095+0000] {processor.py:161} INFO - Started process (PID=1405) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:56:11.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:56:11.097+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:56:11.097+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:56:11.569+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:56:11.597+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:56:11.597+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:56:11.611+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:56:11.611+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:56:11.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.539 seconds
[2025-12-16T15:56:42.460+0000] {processor.py:161} INFO - Started process (PID=1416) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:56:42.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:56:42.464+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:56:42.463+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:56:43.190+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:56:43.218+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:56:43.218+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:56:43.231+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:56:43.230+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:56:43.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.963 seconds
[2025-12-16T15:57:13.775+0000] {processor.py:161} INFO - Started process (PID=1427) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:57:13.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:57:13.778+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:57:13.777+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:57:14.142+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:57:14.173+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:57:14.172+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:57:14.346+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:57:14.346+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:57:14.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.593 seconds
[2025-12-16T15:57:44.982+0000] {processor.py:161} INFO - Started process (PID=1438) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:57:44.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:57:44.985+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:57:44.984+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:57:45.362+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:57:45.391+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:57:45.390+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:57:45.558+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:57:45.558+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:57:45.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.598 seconds
[2025-12-16T15:58:16.312+0000] {processor.py:161} INFO - Started process (PID=1449) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:58:16.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:58:16.315+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:58:16.314+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:58:16.893+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:58:17.084+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:58:17.084+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:58:17.095+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:58:17.094+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:58:17.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.804 seconds
[2025-12-16T15:58:47.638+0000] {processor.py:161} INFO - Started process (PID=1460) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:58:47.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:58:47.640+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:58:47.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:58:48.015+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:58:48.044+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:58:48.044+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:58:48.055+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:58:48.055+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:58:48.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.440 seconds
[2025-12-16T15:59:18.138+0000] {processor.py:161} INFO - Started process (PID=1471) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:59:18.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:59:18.140+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:59:18.140+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:59:18.737+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:59:18.779+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:59:18.779+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:59:18.794+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:59:18.793+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:59:18.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.684 seconds
[2025-12-16T15:59:49.336+0000] {processor.py:161} INFO - Started process (PID=1482) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:59:49.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T15:59:49.338+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:59:49.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:59:49.708+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T15:59:49.736+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:59:49.736+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T15:59:49.750+0000] {logging_mixin.py:188} INFO - [2025-12-16T15:59:49.750+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T15:59:49.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.623 seconds
[2025-12-16T16:00:20.705+0000] {processor.py:161} INFO - Started process (PID=1493) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:00:20.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:00:20.708+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:00:20.707+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:00:21.357+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:00:21.407+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:00:21.407+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:00:21.604+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:00:21.604+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:00:21.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.919 seconds
[2025-12-16T16:00:52.045+0000] {processor.py:161} INFO - Started process (PID=1504) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:00:52.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:00:52.048+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:00:52.048+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:00:52.434+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:00:52.646+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:00:52.646+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:00:52.655+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:00:52.655+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:00:52.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.632 seconds
[2025-12-16T16:01:23.265+0000] {processor.py:161} INFO - Started process (PID=1515) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:01:23.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:01:23.267+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:01:23.267+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:01:23.851+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:01:23.886+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:01:23.886+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:01:23.901+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:01:23.901+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:01:23.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.664 seconds
[2025-12-16T16:01:54.579+0000] {processor.py:161} INFO - Started process (PID=1526) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:01:54.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:01:54.580+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:01:54.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:01:54.993+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:01:55.027+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:01:55.027+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:01:55.042+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:01:55.041+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:01:55.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.486 seconds
[2025-12-16T16:02:25.880+0000] {processor.py:161} INFO - Started process (PID=1537) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:02:25.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:02:25.883+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:02:25.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:02:26.460+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:02:26.492+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:02:26.492+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:02:26.505+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:02:26.505+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:02:26.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.801 seconds
[2025-12-16T16:02:57.204+0000] {processor.py:161} INFO - Started process (PID=1548) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:02:57.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:02:57.206+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:02:57.206+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:02:57.566+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:02:57.594+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:02:57.593+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:02:57.768+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:02:57.767+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:02:57.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.585 seconds
[2025-12-16T16:03:28.511+0000] {processor.py:161} INFO - Started process (PID=1559) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:03:28.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:03:28.514+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:03:28.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:03:29.114+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:03:29.150+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:03:29.149+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:03:29.338+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:03:29.337+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:03:29.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.850 seconds
[2025-12-16T16:03:59.813+0000] {processor.py:161} INFO - Started process (PID=1570) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:03:59.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:03:59.815+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:03:59.814+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:04:00.215+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:04:00.416+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:04:00.416+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:04:00.427+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:04:00.427+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:04:00.446+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.636 seconds
[2025-12-16T16:04:31.134+0000] {processor.py:161} INFO - Started process (PID=1581) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:04:31.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:04:31.136+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:04:31.136+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:04:31.523+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:04:31.554+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:04:31.554+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:04:31.569+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:04:31.568+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:04:31.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.467 seconds
[2025-12-16T16:05:02.473+0000] {processor.py:161} INFO - Started process (PID=1592) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:05:02.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:05:02.475+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:05:02.475+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:05:02.852+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:05:02.882+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:05:02.881+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:05:02.895+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:05:02.895+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:05:02.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.466 seconds
[2025-12-16T16:05:33.093+0000] {processor.py:161} INFO - Started process (PID=1603) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:05:33.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:05:33.097+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:05:33.097+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:05:33.843+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:05:33.898+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:05:33.897+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:05:34.169+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:05:34.168+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:05:34.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.111 seconds
[2025-12-16T16:06:04.694+0000] {processor.py:161} INFO - Started process (PID=1614) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:06:04.696+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:06:04.698+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:06:04.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:06:05.400+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:06:05.452+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:06:05.451+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:06:05.689+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:06:05.689+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:06:05.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.040 seconds
[2025-12-16T16:06:36.114+0000] {processor.py:161} INFO - Started process (PID=1625) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:06:36.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:06:36.119+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:06:36.118+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:06:36.815+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:06:37.108+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:06:37.107+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:06:37.127+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:06:37.127+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:06:37.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.064 seconds
[2025-12-16T16:07:07.566+0000] {processor.py:161} INFO - Started process (PID=1636) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:07:07.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:07:07.571+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:07:07.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:07:08.282+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:07:08.330+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:07:08.330+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:07:08.350+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:07:08.350+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:07:08.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.841 seconds
[2025-12-16T16:07:38.889+0000] {processor.py:161} INFO - Started process (PID=1647) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:07:38.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:07:38.892+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:07:38.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:07:39.542+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:07:39.590+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:07:39.590+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:07:39.610+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:07:39.609+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:07:39.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.761 seconds
[2025-12-16T16:08:09.762+0000] {processor.py:161} INFO - Started process (PID=1663) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:08:09.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:08:09.766+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:08:09.765+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:08:10.465+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:08:10.514+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:08:10.513+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:08:10.536+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:08:10.535+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:08:10.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.046 seconds
[2025-12-16T16:08:41.200+0000] {processor.py:161} INFO - Started process (PID=1674) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:08:41.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:08:41.204+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:08:41.203+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:08:42.015+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:08:42.066+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:08:42.066+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:08:42.343+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:08:42.342+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:08:42.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.198 seconds
[2025-12-16T16:09:12.765+0000] {processor.py:161} INFO - Started process (PID=1685) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:09:12.767+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:09:12.769+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:09:12.768+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:09:13.523+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:09:13.582+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:09:13.581+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:09:13.829+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:09:13.829+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:09:13.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.116 seconds
[2025-12-16T16:09:44.322+0000] {processor.py:161} INFO - Started process (PID=1696) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:09:44.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:09:44.326+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:09:44.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:09:45.072+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:09:45.364+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:09:45.364+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:09:45.382+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:09:45.382+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:09:45.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.115 seconds
[2025-12-16T16:10:15.802+0000] {processor.py:161} INFO - Started process (PID=1707) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:10:15.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:10:15.806+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:10:15.805+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:10:16.486+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:10:16.540+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:10:16.540+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:10:16.565+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:10:16.565+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:10:16.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.803 seconds
[2025-12-16T16:10:47.194+0000] {processor.py:161} INFO - Started process (PID=1718) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:10:47.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:10:47.199+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:10:47.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:10:47.897+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:10:47.955+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:10:47.954+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:10:47.985+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:10:47.985+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:10:48.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.836 seconds
[2025-12-16T16:11:18.628+0000] {processor.py:161} INFO - Started process (PID=1729) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:11:18.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:11:18.633+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:11:18.632+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:11:19.319+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:11:19.367+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:11:19.366+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:11:19.389+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:11:19.388+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:11:19.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.012 seconds
[2025-12-16T16:11:50.008+0000] {processor.py:161} INFO - Started process (PID=1740) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:11:50.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:11:50.017+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:11:50.016+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:11:50.686+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:11:50.736+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:11:50.735+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:11:50.993+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:11:50.992+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:11:51.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.038 seconds
[2025-12-16T16:12:21.500+0000] {processor.py:161} INFO - Started process (PID=1751) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:12:21.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:12:21.504+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:12:21.503+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:12:22.284+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:12:22.582+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:12:22.581+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:12:22.599+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:12:22.599+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:12:22.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.176 seconds
[2025-12-16T16:12:53.073+0000] {processor.py:161} INFO - Started process (PID=1762) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:12:53.075+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:12:53.076+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:12:53.076+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:12:53.739+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:12:53.790+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:12:53.789+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:12:53.811+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:12:53.811+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:12:53.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.808 seconds
[2025-12-16T16:13:24.469+0000] {processor.py:161} INFO - Started process (PID=1773) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:13:24.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:13:24.473+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:13:24.473+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:13:25.184+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:13:25.232+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:13:25.231+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:13:25.252+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:13:25.252+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:13:25.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.841 seconds
[2025-12-16T16:13:55.843+0000] {processor.py:161} INFO - Started process (PID=1784) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:13:55.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:13:55.847+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:13:55.847+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:13:56.514+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:13:56.569+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:13:56.568+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:13:56.593+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:13:56.593+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:13:56.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.026 seconds
[2025-12-16T16:14:27.251+0000] {processor.py:161} INFO - Started process (PID=1795) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:14:27.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:14:27.256+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:14:27.255+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:14:27.968+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:14:28.037+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:14:28.036+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:14:28.286+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:14:28.286+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:14:28.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.095 seconds
[2025-12-16T16:14:58.738+0000] {processor.py:161} INFO - Started process (PID=1806) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:14:58.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:14:58.742+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:14:58.742+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:14:59.465+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:14:59.519+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:14:59.518+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:14:59.785+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:14:59.785+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:14:59.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.092 seconds
[2025-12-16T16:15:30.281+0000] {processor.py:161} INFO - Started process (PID=1817) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:15:30.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:15:30.287+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:15:30.286+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:15:31.069+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:15:31.396+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:15:31.395+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:15:31.416+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:15:31.416+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:15:31.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.192 seconds
[2025-12-16T16:16:01.896+0000] {processor.py:161} INFO - Started process (PID=1828) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:16:01.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:16:01.901+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:16:01.900+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:16:02.705+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:16:02.761+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:16:02.761+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:16:02.795+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:16:02.794+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:16:02.838+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.948 seconds
[2025-12-16T16:16:33.359+0000] {processor.py:161} INFO - Started process (PID=1839) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:16:33.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:16:33.363+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:16:33.363+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:16:34.109+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:16:34.165+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:16:34.164+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:16:34.187+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:16:34.187+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:16:34.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.871 seconds
[2025-12-16T16:17:04.834+0000] {processor.py:161} INFO - Started process (PID=1850) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:17:04.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:17:04.838+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:17:04.838+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:17:05.552+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:17:05.604+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:17:05.603+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:17:05.627+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:17:05.627+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:17:05.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.102 seconds
[2025-12-16T16:17:36.318+0000] {processor.py:161} INFO - Started process (PID=1861) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:17:36.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:17:36.323+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:17:36.322+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:17:37.049+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:17:37.107+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:17:37.106+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:17:37.397+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:17:37.396+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:17:37.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.140 seconds
[2025-12-16T16:18:07.853+0000] {processor.py:161} INFO - Started process (PID=1872) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:18:07.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:18:07.856+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:18:07.856+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:18:08.589+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:18:08.905+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:18:08.905+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:18:08.923+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:18:08.923+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:18:08.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.129 seconds
[2025-12-16T16:18:39.422+0000] {processor.py:161} INFO - Started process (PID=1883) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:18:39.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:18:39.426+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:18:39.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:18:40.425+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:18:40.472+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:18:40.471+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:18:40.489+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:18:40.489+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:18:40.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.109 seconds
[2025-12-16T16:19:10.931+0000] {processor.py:161} INFO - Started process (PID=1894) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:19:10.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:19:10.936+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:19:10.935+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:19:11.651+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:19:11.703+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:19:11.702+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:19:11.738+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:19:11.738+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:19:11.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.875 seconds
[2025-12-16T16:19:42.431+0000] {processor.py:161} INFO - Started process (PID=1905) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:19:42.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:19:42.436+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:19:42.435+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:19:43.158+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:19:43.214+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:19:43.213+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:19:43.242+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:19:43.242+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:19:43.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.096 seconds
[2025-12-16T16:20:13.922+0000] {processor.py:161} INFO - Started process (PID=1916) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:20:13.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:20:13.925+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:20:13.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:20:14.647+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:20:14.697+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:20:14.696+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:20:14.937+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:20:14.937+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:20:14.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.067 seconds
[2025-12-16T16:20:45.461+0000] {processor.py:161} INFO - Started process (PID=1927) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:20:45.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:20:45.465+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:20:45.464+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:20:46.226+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:20:46.277+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:20:46.276+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:20:46.549+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:20:46.549+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:20:46.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.142 seconds
[2025-12-16T16:21:16.992+0000] {processor.py:161} INFO - Started process (PID=1938) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:21:16.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:21:16.996+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:21:16.995+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:21:17.928+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:21:17.973+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:21:17.973+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:21:17.991+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:21:17.991+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:21:18.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.036 seconds
[2025-12-16T16:21:48.410+0000] {processor.py:161} INFO - Started process (PID=1949) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:21:48.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:21:48.413+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:21:48.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:21:49.087+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:21:49.145+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:21:49.144+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:21:49.171+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:21:49.170+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:21:49.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.813 seconds
[2025-12-16T16:22:19.907+0000] {processor.py:161} INFO - Started process (PID=1960) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:22:19.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:22:19.911+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:22:19.911+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:22:20.590+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:22:20.643+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:22:20.642+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:22:20.663+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:22:20.663+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:22:20.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.817 seconds
[2025-12-16T16:22:51.253+0000] {processor.py:161} INFO - Started process (PID=1971) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:22:51.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:22:51.257+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:22:51.257+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:22:51.931+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:22:51.997+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:22:51.996+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:22:52.031+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:22:52.030+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:22:52.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.078 seconds
[2025-12-16T16:23:22.732+0000] {processor.py:161} INFO - Started process (PID=1982) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:23:22.734+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:23:22.736+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:23:22.735+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:23:23.421+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:23:23.468+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:23:23.468+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:23:23.749+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:23:23.748+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:23:23.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.075 seconds
[2025-12-16T16:23:54.273+0000] {processor.py:161} INFO - Started process (PID=1993) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:23:54.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:23:54.277+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:23:54.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:23:54.959+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:23:55.233+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:23:55.233+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:23:55.250+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:23:55.250+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:23:55.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.032 seconds
[2025-12-16T16:24:25.761+0000] {processor.py:161} INFO - Started process (PID=2009) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:24:25.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:24:25.765+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:24:25.764+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:24:26.448+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:24:26.500+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:24:26.499+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:24:26.526+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:24:26.526+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:24:26.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.824 seconds
[2025-12-16T16:24:57.194+0000] {processor.py:161} INFO - Started process (PID=2020) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:24:57.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:24:57.198+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:24:57.197+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:24:57.915+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:24:57.967+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:24:57.966+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:24:57.994+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:24:57.994+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:24:58.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.859 seconds
[2025-12-16T16:25:28.569+0000] {processor.py:161} INFO - Started process (PID=2031) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:25:28.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:25:28.573+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:25:28.573+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:25:29.222+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:25:29.268+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:25:29.268+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:25:29.290+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:25:29.290+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:25:29.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.002 seconds
[2025-12-16T16:26:00.054+0000] {processor.py:161} INFO - Started process (PID=2042) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:26:00.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:26:00.059+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:26:00.058+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:26:00.767+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:26:00.816+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:26:00.816+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:26:01.058+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:26:01.058+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:26:01.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.063 seconds
[2025-12-16T16:26:31.515+0000] {processor.py:161} INFO - Started process (PID=2053) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:26:31.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:26:31.520+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:26:31.519+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:26:32.432+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:26:32.820+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:26:32.819+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:26:32.840+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:26:32.839+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:26:32.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.368 seconds
[2025-12-16T16:27:03.246+0000] {processor.py:161} INFO - Started process (PID=2064) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:27:03.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:27:03.250+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:27:03.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:27:04.206+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:27:04.263+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:27:04.262+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:27:04.299+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:27:04.299+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:27:04.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.102 seconds
[2025-12-16T16:27:34.728+0000] {processor.py:161} INFO - Started process (PID=2075) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:27:34.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:27:34.732+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:27:34.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:27:35.410+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:27:35.462+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:27:35.461+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:27:35.484+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:27:35.484+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:27:35.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.798 seconds
[2025-12-16T16:28:06.123+0000] {processor.py:161} INFO - Started process (PID=2086) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:28:06.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:28:06.126+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:28:06.126+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:28:06.816+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:28:06.868+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:28:06.868+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:28:06.889+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:28:06.889+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:28:06.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.827 seconds
[2025-12-16T16:28:37.493+0000] {processor.py:161} INFO - Started process (PID=2097) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:28:37.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:28:37.497+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:28:37.496+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:28:38.292+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:28:38.356+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:28:38.355+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:28:38.382+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:28:38.382+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:28:38.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.236 seconds
[2025-12-16T16:29:09.170+0000] {processor.py:161} INFO - Started process (PID=2108) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:29:09.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:29:09.176+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:29:09.175+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:29:10.006+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:29:10.072+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:29:10.071+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:29:10.398+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:29:10.398+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:29:10.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.293 seconds
[2025-12-16T16:29:40.896+0000] {processor.py:161} INFO - Started process (PID=2119) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:29:40.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:29:40.903+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:29:40.902+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:29:41.737+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:29:42.068+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:29:42.067+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:29:42.088+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:29:42.088+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:29:42.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.250 seconds
[2025-12-16T16:30:12.587+0000] {processor.py:161} INFO - Started process (PID=2130) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:30:12.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:30:12.591+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:30:12.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:30:13.684+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:30:13.734+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:30:13.733+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:30:13.757+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:30:13.756+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:30:13.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.221 seconds
[2025-12-16T16:30:44.334+0000] {processor.py:161} INFO - Started process (PID=2141) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:30:44.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:30:44.339+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:30:44.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:30:45.264+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:30:45.323+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:30:45.323+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:30:45.347+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:30:45.346+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:30:45.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.080 seconds
[2025-12-16T16:31:15.865+0000] {processor.py:161} INFO - Started process (PID=2152) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:31:15.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:31:15.873+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:31:15.872+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:31:16.844+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:31:16.921+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:31:16.919+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:31:16.952+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:31:16.951+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:31:17.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.481 seconds
[2025-12-16T16:31:47.824+0000] {processor.py:161} INFO - Started process (PID=2163) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:31:47.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:31:47.830+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:31:47.829+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:31:48.734+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:31:48.802+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:31:48.801+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:31:49.161+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:31:49.161+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:31:49.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.389 seconds
[2025-12-16T16:32:19.628+0000] {processor.py:161} INFO - Started process (PID=2174) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:32:19.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:32:19.634+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:32:19.633+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:32:20.461+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:32:20.817+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:32:20.816+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:32:20.838+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:32:20.838+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:32:20.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.279 seconds
[2025-12-16T16:32:51.280+0000] {processor.py:161} INFO - Started process (PID=2185) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:32:51.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:32:51.284+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:32:51.283+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:32:52.429+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:32:52.487+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:32:52.487+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:32:52.515+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:32:52.515+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:32:52.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.298 seconds
[2025-12-16T16:33:22.760+0000] {processor.py:161} INFO - Started process (PID=2196) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:33:22.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:33:22.768+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:33:22.768+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:33:23.614+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:33:23.670+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:33:23.670+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:33:23.694+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:33:23.693+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:33:23.735+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.987 seconds
[2025-12-16T16:33:54.161+0000] {processor.py:161} INFO - Started process (PID=2207) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:33:54.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:33:54.165+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:33:54.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:33:55.011+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:33:55.071+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:33:55.070+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:33:55.094+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:33:55.094+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:33:55.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.004 seconds
[2025-12-16T16:34:25.597+0000] {processor.py:161} INFO - Started process (PID=2218) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:34:25.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:34:25.601+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:34:25.601+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:34:26.420+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:34:26.481+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:34:26.480+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:34:26.509+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:34:26.508+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:34:26.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.252 seconds
[2025-12-16T16:34:57.274+0000] {processor.py:161} INFO - Started process (PID=2229) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:34:57.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:34:57.279+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:34:57.278+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:34:58.098+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:34:58.158+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:34:58.157+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:34:58.489+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:34:58.488+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:34:58.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.272 seconds
[2025-12-16T16:35:28.987+0000] {processor.py:161} INFO - Started process (PID=2240) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:35:28.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:35:28.992+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:35:28.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:35:29.837+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:35:30.220+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:35:30.219+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:35:30.242+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:35:30.242+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:35:30.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.318 seconds
[2025-12-16T16:36:00.594+0000] {processor.py:161} INFO - Started process (PID=2251) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:36:00.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:36:00.598+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:36:00.598+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:36:01.720+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:36:01.765+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:36:01.765+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:36:01.785+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:36:01.785+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:36:01.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.254 seconds
[2025-12-16T16:36:32.283+0000] {processor.py:161} INFO - Started process (PID=2262) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:36:32.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:36:32.288+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:36:32.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:36:33.158+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:36:33.217+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:36:33.216+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:36:33.242+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:36:33.242+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:36:33.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.023 seconds
[2025-12-16T16:37:03.735+0000] {processor.py:161} INFO - Started process (PID=2273) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:37:03.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:37:03.744+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:37:03.743+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:37:04.610+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:37:04.670+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:37:04.669+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:37:04.695+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:37:04.694+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:37:05.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.356 seconds
[2025-12-16T16:37:35.549+0000] {processor.py:161} INFO - Started process (PID=2284) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:37:35.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:37:35.554+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:37:35.553+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:37:36.411+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:37:36.469+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:37:36.467+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:37:36.767+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:37:36.767+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:37:36.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.288 seconds
[2025-12-16T16:38:06.985+0000] {processor.py:161} INFO - Started process (PID=2295) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:38:06.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:38:06.991+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:38:06.990+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:38:07.710+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:38:08.030+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:38:08.029+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:38:08.046+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:38:08.045+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:38:08.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.100 seconds
[2025-12-16T16:38:38.501+0000] {processor.py:161} INFO - Started process (PID=2306) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:38:38.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:38:38.507+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:38:38.506+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:38:39.753+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:38:39.816+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:38:39.815+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:38:39.836+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:38:39.836+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:38:39.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.384 seconds
[2025-12-16T16:39:10.214+0000] {processor.py:161} INFO - Started process (PID=2317) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:39:10.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:39:10.222+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:39:10.219+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:39:11.314+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:39:11.362+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:39:11.361+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:39:11.385+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:39:11.384+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:39:11.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.234 seconds
[2025-12-16T16:39:41.638+0000] {processor.py:161} INFO - Started process (PID=2328) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:39:41.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:39:41.641+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:39:41.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:39:42.445+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:39:42.497+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:39:42.496+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:39:42.522+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:39:42.521+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:39:42.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.931 seconds
[2025-12-16T16:40:13.053+0000] {processor.py:161} INFO - Started process (PID=2344) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:40:13.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:40:13.060+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:40:13.059+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:40:13.801+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:40:13.851+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:40:13.850+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:40:13.875+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:40:13.875+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:40:14.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.115 seconds
[2025-12-16T16:40:44.545+0000] {processor.py:161} INFO - Started process (PID=2355) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:40:44.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:40:44.550+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:40:44.549+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:40:45.349+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:40:45.397+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:40:45.397+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:40:45.652+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:40:45.651+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:40:45.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.156 seconds
[2025-12-16T16:41:16.128+0000] {processor.py:161} INFO - Started process (PID=2366) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:41:16.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:41:16.133+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:41:16.132+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:41:16.946+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:41:17.390+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:41:17.389+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:41:17.413+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:41:17.412+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:41:17.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.350 seconds
[2025-12-16T16:41:47.917+0000] {processor.py:161} INFO - Started process (PID=2377) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:41:47.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:41:47.921+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:41:47.921+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:41:49.076+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:41:49.122+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:41:49.122+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:41:49.144+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:41:49.143+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:41:49.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.297 seconds
[2025-12-16T16:42:19.637+0000] {processor.py:161} INFO - Started process (PID=2388) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:42:19.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:42:19.641+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:42:19.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:42:20.413+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:42:20.472+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:42:20.471+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:42:20.494+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:42:20.494+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:42:20.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.916 seconds
[2025-12-16T16:42:51.175+0000] {processor.py:161} INFO - Started process (PID=2399) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:42:51.177+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:42:51.180+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:42:51.179+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:42:52.060+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:42:52.126+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:42:52.125+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:42:52.155+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:42:52.154+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:42:52.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.328 seconds
[2025-12-16T16:43:22.939+0000] {processor.py:161} INFO - Started process (PID=2410) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:43:22.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:43:22.944+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:43:22.944+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:43:23.834+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:43:23.897+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:43:23.895+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:43:24.206+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:43:24.205+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:43:24.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.318 seconds
[2025-12-16T16:43:54.694+0000] {processor.py:161} INFO - Started process (PID=2421) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:43:54.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:43:54.700+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:43:54.699+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:43:55.548+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:43:55.903+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:43:55.902+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:43:55.925+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:43:55.925+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:43:55.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.278 seconds
[2025-12-16T16:44:26.402+0000] {processor.py:161} INFO - Started process (PID=2432) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:44:26.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:44:26.406+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:44:26.406+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:44:27.566+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:44:27.615+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:44:27.614+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:44:27.637+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:44:27.637+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:44:27.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.295 seconds
[2025-12-16T16:44:58.107+0000] {processor.py:161} INFO - Started process (PID=2443) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:44:58.118+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:44:58.120+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:44:58.119+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:44:59.248+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:44:59.306+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:44:59.305+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:44:59.329+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:44:59.328+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:44:59.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.288 seconds
[2025-12-16T16:45:29.667+0000] {processor.py:161} INFO - Started process (PID=2454) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:45:29.669+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:45:29.670+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:45:29.670+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:45:30.352+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:45:30.405+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:45:30.404+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:45:30.423+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:45:30.423+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:45:30.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.814 seconds
[2025-12-16T16:46:00.888+0000] {processor.py:161} INFO - Started process (PID=2465) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:46:00.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:46:00.895+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:46:00.893+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:46:01.756+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:46:01.815+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:46:01.814+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:46:01.840+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:46:01.839+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:46:02.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.297 seconds
[2025-12-16T16:46:32.631+0000] {processor.py:161} INFO - Started process (PID=2476) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:46:32.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:46:32.635+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:46:32.635+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:46:33.554+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:46:33.616+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:46:33.615+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:46:33.939+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:46:33.939+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:46:33.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.361 seconds
[2025-12-16T16:47:04.405+0000] {processor.py:161} INFO - Started process (PID=2487) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:47:04.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:47:04.410+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:47:04.410+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:47:05.267+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:47:05.646+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:47:05.645+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:47:05.667+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:47:05.667+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:47:05.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.330 seconds
[2025-12-16T16:47:36.035+0000] {processor.py:161} INFO - Started process (PID=2498) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:47:36.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:47:36.039+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:47:36.038+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:47:36.999+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:47:37.044+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:47:37.044+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:47:37.062+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:47:37.062+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:47:37.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.083 seconds
[2025-12-16T16:48:07.533+0000] {processor.py:161} INFO - Started process (PID=2509) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:48:07.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:48:07.537+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:48:07.536+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:48:08.477+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:48:08.524+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:48:08.523+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:48:08.544+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:48:08.543+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:48:08.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.072 seconds
[2025-12-16T16:48:38.996+0000] {processor.py:161} INFO - Started process (PID=2520) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:48:38.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:48:39.000+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:48:39.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:48:39.716+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:48:39.765+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:48:39.764+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:48:39.790+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:48:39.790+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:48:40.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.113 seconds
[2025-12-16T16:49:10.495+0000] {processor.py:161} INFO - Started process (PID=2531) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:49:10.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:49:10.499+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:49:10.499+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:49:11.232+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:49:11.285+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:49:11.284+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:49:11.535+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:49:11.534+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:49:11.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.081 seconds
[2025-12-16T16:49:41.961+0000] {processor.py:161} INFO - Started process (PID=2542) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:49:41.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:49:41.966+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:49:41.965+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:49:42.683+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:49:42.959+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:49:42.958+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:49:42.975+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:49:42.975+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:49:43.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.069 seconds
[2025-12-16T16:50:13.502+0000] {processor.py:161} INFO - Started process (PID=2553) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:50:13.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2025-12-16T16:50:13.508+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:50:13.508+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:50:14.537+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2025-12-16T16:50:14.576+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:50:14.575+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-12-16T16:50:14.592+0000] {logging_mixin.py:188} INFO - [2025-12-16T16:50:14.592+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2025-12-16T16:50:14.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.150 seconds
