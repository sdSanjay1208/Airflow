[2026-01-12T11:50:15.960+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:50:15.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:50:15.964+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:50:15.963+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:50:17.917+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:50:18.862+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:50:18.861+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:50:18.895+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:50:18.895+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:50:18.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 3.010 seconds
[2026-01-12T11:50:49.190+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:50:49.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:50:49.193+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:50:49.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:50:49.644+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:50:49.674+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:50:49.673+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:50:49.686+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:50:49.686+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:50:49.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.710 seconds
[2026-01-12T11:51:20.103+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:51:20.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:51:20.106+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:51:20.106+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:51:20.738+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:51:20.775+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:51:20.774+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:51:20.791+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:51:20.791+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:51:20.815+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.716 seconds
[2026-01-12T11:51:51.660+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:51:51.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:51:51.663+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:51:51.662+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:51:52.144+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:51:52.181+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:51:52.181+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:51:52.197+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:51:52.197+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:51:52.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.565 seconds
[2026-01-12T11:52:22.627+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:52:22.628+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:52:22.629+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:52:22.629+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:52:23.212+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:52:23.251+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:52:23.251+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:52:23.270+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:52:23.270+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:52:23.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.676 seconds
[2026-01-12T11:52:53.758+0000] {processor.py:161} INFO - Started process (PID=326) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:52:53.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:52:53.761+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:52:53.761+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:52:54.239+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:52:54.275+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:52:54.274+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:52:54.292+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:52:54.291+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:52:54.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.562 seconds
[2026-01-12T11:53:24.462+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:53:24.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:53:24.467+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:53:24.467+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:53:25.585+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:53:25.638+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:53:25.637+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:53:25.660+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:53:25.659+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:53:25.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.434 seconds
[2026-01-12T11:53:56.605+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:53:56.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:53:56.607+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:53:56.607+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:53:57.085+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:53:57.124+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:53:57.123+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:53:57.141+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:53:57.140+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:53:57.164+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.564 seconds
[2026-01-12T11:54:27.419+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:54:27.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:54:27.422+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:54:27.422+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:54:27.873+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:54:27.909+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:54:27.908+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:54:27.922+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:54:27.922+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:54:27.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.531 seconds
[2026-01-12T11:54:58.435+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:54:58.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:54:58.437+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:54:58.437+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:54:58.868+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:54:58.900+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:54:58.900+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:54:58.917+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:54:58.917+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:54:58.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.507 seconds
[2026-01-12T11:55:13.612+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:55:13.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:55:13.615+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:55:13.614+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:55:13.984+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:55:14.030+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:55:14.029+0000] {dag.py:1509} INFO - Executing dag callback function: <function dag_success_callback at 0x76d3c6ce7a60>
[2026-01-12T11:55:14.132+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:55:14.132+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:55:14.143+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:55:14.143+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:55:14.329+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.722 seconds
[2026-01-12T11:55:44.785+0000] {processor.py:161} INFO - Started process (PID=451) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:55:44.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:55:44.787+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:55:44.786+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:55:45.185+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:55:45.215+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:55:45.215+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:55:45.227+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:55:45.227+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:55:45.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.464 seconds
[2026-01-12T11:56:15.568+0000] {processor.py:161} INFO - Started process (PID=473) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:56:15.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:56:15.570+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:56:15.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:56:15.944+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:56:15.976+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:56:15.976+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:56:15.990+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:56:15.990+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:56:16.012+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.447 seconds
[2026-01-12T11:56:46.415+0000] {processor.py:161} INFO - Started process (PID=495) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:56:46.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:56:46.416+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:56:46.416+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:56:46.774+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:56:46.805+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:56:46.805+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:56:46.820+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:56:46.820+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:56:47.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.713 seconds
[2026-01-12T11:57:17.478+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:57:17.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:57:17.481+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:57:17.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:57:17.853+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:57:17.883+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:57:17.883+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:57:17.897+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:57:17.897+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:57:17.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.443 seconds
[2026-01-12T11:57:48.407+0000] {processor.py:161} INFO - Started process (PID=539) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:57:48.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:57:48.409+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:57:48.409+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:57:48.814+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:57:48.852+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:57:48.851+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:57:48.865+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:57:48.865+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:57:48.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.478 seconds
[2026-01-12T11:58:19.345+0000] {processor.py:161} INFO - Started process (PID=561) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:58:19.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:58:19.347+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:58:19.347+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:58:19.753+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:58:19.784+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:58:19.784+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:58:19.799+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:58:19.798+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:58:19.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.480 seconds
[2026-01-12T11:58:50.197+0000] {processor.py:161} INFO - Started process (PID=583) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:58:50.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:58:50.199+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:58:50.199+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:58:50.567+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:58:50.594+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:58:50.594+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:58:50.606+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:58:50.606+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:58:50.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.429 seconds
[2026-01-12T11:59:21.165+0000] {processor.py:161} INFO - Started process (PID=605) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:59:21.166+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:59:21.168+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:59:21.167+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:59:21.622+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:59:21.651+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:59:21.650+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:59:21.664+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:59:21.664+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:59:21.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.686 seconds
[2026-01-12T11:59:51.986+0000] {processor.py:161} INFO - Started process (PID=627) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:59:51.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T11:59:51.989+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:59:51.988+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:59:52.388+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T11:59:52.422+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:59:52.422+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T11:59:52.437+0000] {logging_mixin.py:188} INFO - [2026-01-12T11:59:52.437+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T11:59:52.460+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.477 seconds
[2026-01-12T12:00:22.946+0000] {processor.py:161} INFO - Started process (PID=649) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:00:22.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:00:22.948+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:00:22.948+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:00:23.420+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:00:23.452+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:00:23.451+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:00:23.465+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:00:23.465+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:00:23.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.542 seconds
[2026-01-12T12:00:53.880+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:00:53.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:00:53.882+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:00:53.882+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:00:54.284+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:00:54.313+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:00:54.313+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:00:54.325+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:00:54.325+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:00:54.345+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.468 seconds
[2026-01-12T12:01:24.816+0000] {processor.py:161} INFO - Started process (PID=693) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:01:24.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:01:24.818+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:01:24.818+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:01:25.174+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:01:25.205+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:01:25.205+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:01:25.217+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:01:25.217+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:01:25.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.442 seconds
[2026-01-12T12:01:55.682+0000] {processor.py:161} INFO - Started process (PID=715) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:01:55.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:01:55.684+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:01:55.684+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:01:56.109+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:01:56.142+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:01:56.142+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:01:56.158+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:01:56.157+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:01:56.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.504 seconds
[2026-01-12T12:02:26.696+0000] {processor.py:161} INFO - Started process (PID=737) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:02:26.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:02:26.699+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:02:26.699+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:02:27.128+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:02:27.160+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:02:27.159+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:02:27.174+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:02:27.174+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:02:27.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.683 seconds
[2026-01-12T12:02:57.493+0000] {processor.py:161} INFO - Started process (PID=759) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:02:57.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:02:57.495+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:02:57.494+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:02:57.858+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:02:57.889+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:02:57.889+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:02:57.904+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:02:57.904+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:02:57.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.432 seconds
[2026-01-12T12:03:28.437+0000] {processor.py:161} INFO - Started process (PID=781) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:03:28.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:03:28.439+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:03:28.439+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:03:28.818+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:03:28.847+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:03:28.846+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:03:28.858+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:03:28.858+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:03:28.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.442 seconds
[2026-01-12T12:03:59.298+0000] {processor.py:161} INFO - Started process (PID=803) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:03:59.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:03:59.300+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:03:59.300+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:03:59.728+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:03:59.762+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:03:59.762+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:03:59.775+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:03:59.774+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:03:59.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.502 seconds
[2026-01-12T12:04:30.236+0000] {processor.py:161} INFO - Started process (PID=825) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:04:30.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:04:30.238+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:04:30.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:04:30.606+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:04:30.636+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:04:30.635+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:04:30.648+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:04:30.648+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:04:30.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.435 seconds
[2026-01-12T12:05:01.087+0000] {processor.py:161} INFO - Started process (PID=847) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:05:01.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:05:01.090+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:05:01.090+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:05:01.499+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:05:01.526+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:05:01.526+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:05:01.539+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:05:01.539+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:05:01.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.644 seconds
[2026-01-12T12:05:31.987+0000] {processor.py:161} INFO - Started process (PID=869) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:05:31.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:05:31.990+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:05:31.990+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:05:32.457+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:05:32.490+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:05:32.489+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:05:32.508+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:05:32.507+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:05:32.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.546 seconds
[2026-01-12T12:06:02.827+0000] {processor.py:161} INFO - Started process (PID=891) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:06:02.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:06:02.829+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:06:02.829+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:06:03.195+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:06:03.230+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:06:03.229+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:06:03.247+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:06:03.246+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:06:03.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.475 seconds
[2026-01-12T12:06:33.742+0000] {processor.py:161} INFO - Started process (PID=913) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:06:33.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:06:33.744+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:06:33.743+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:06:34.111+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:06:34.139+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:06:34.138+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:06:34.150+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:06:34.150+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:06:34.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.428 seconds
[2026-01-12T12:07:04.563+0000] {processor.py:161} INFO - Started process (PID=935) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:07:04.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:07:04.565+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:07:04.565+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:07:04.976+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:07:05.006+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:07:05.005+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:07:05.019+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:07:05.019+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:07:05.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.478 seconds
[2026-01-12T12:07:35.394+0000] {processor.py:161} INFO - Started process (PID=957) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:07:35.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:07:35.396+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:07:35.396+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:07:35.754+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:07:35.782+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:07:35.782+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:07:35.795+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:07:35.795+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:07:35.815+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.424 seconds
[2026-01-12T12:08:06.250+0000] {processor.py:161} INFO - Started process (PID=979) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:08:06.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:08:06.252+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:08:06.252+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:08:06.626+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:08:06.655+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:08:06.654+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:08:06.836+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:08:06.836+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:08:06.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.605 seconds
[2026-01-12T12:08:37.062+0000] {processor.py:161} INFO - Started process (PID=1001) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:08:37.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:08:37.064+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:08:37.064+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:08:37.428+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:08:37.460+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:08:37.460+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:08:37.473+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:08:37.473+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:08:37.502+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.443 seconds
[2026-01-12T12:09:07.561+0000] {processor.py:161} INFO - Started process (PID=1023) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:09:07.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:09:07.564+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:09:07.563+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:09:08.006+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:09:08.041+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:09:08.041+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:09:08.056+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:09:08.055+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:09:08.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.517 seconds
[2026-01-12T12:09:38.383+0000] {processor.py:161} INFO - Started process (PID=1045) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:09:38.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:09:38.386+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:09:38.386+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:09:38.759+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:09:38.788+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:09:38.788+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:09:38.801+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:09:38.801+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:09:38.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.443 seconds
[2026-01-12T12:10:09.313+0000] {processor.py:161} INFO - Started process (PID=1067) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:10:09.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:10:09.315+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:10:09.315+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:10:09.721+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:10:09.759+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:10:09.759+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:10:09.780+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:10:09.779+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:10:09.805+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.495 seconds
[2026-01-12T12:10:40.353+0000] {processor.py:161} INFO - Started process (PID=1089) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:10:40.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:10:40.355+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:10:40.355+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:10:40.725+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:10:40.763+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:10:40.763+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:10:40.937+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:10:40.936+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:10:40.955+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.604 seconds
[2026-01-12T12:11:11.270+0000] {processor.py:161} INFO - Started process (PID=1111) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:11:11.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:11:11.272+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:11:11.272+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:11:11.700+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:11:11.729+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:11:11.729+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:11:11.741+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:11:11.741+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:11:11.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.491 seconds
[2026-01-12T12:11:42.297+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:11:42.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:11:42.299+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:11:42.299+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:11:42.735+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:11:42.772+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:11:42.772+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:11:42.788+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:11:42.788+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:11:42.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.518 seconds
[2026-01-12T12:12:13.231+0000] {processor.py:161} INFO - Started process (PID=1155) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:12:13.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:12:13.233+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:12:13.233+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:12:13.702+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:12:13.737+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:12:13.736+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:12:13.752+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:12:13.752+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:12:13.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.546 seconds
[2026-01-12T12:12:44.192+0000] {processor.py:161} INFO - Started process (PID=1177) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:12:44.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:12:44.194+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:12:44.194+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:12:44.607+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:12:44.632+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:12:44.631+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:12:44.643+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:12:44.643+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:12:44.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.478 seconds
[2026-01-12T12:13:15.041+0000] {processor.py:161} INFO - Started process (PID=1199) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:13:15.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:13:15.042+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:13:15.042+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:13:15.411+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:13:15.444+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:13:15.443+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:13:15.460+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:13:15.460+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:13:15.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.622 seconds
[2026-01-12T12:13:45.941+0000] {processor.py:161} INFO - Started process (PID=1221) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:13:45.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:13:45.943+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:13:45.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:13:46.311+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:13:46.342+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:13:46.342+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:13:46.355+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:13:46.355+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:13:46.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.436 seconds
[2026-01-12T12:14:16.553+0000] {processor.py:161} INFO - Started process (PID=1243) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:14:16.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:14:16.555+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:14:16.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:14:17.003+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:14:17.039+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:14:17.038+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:14:17.055+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:14:17.054+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:14:17.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.530 seconds
[2026-01-12T12:14:47.271+0000] {processor.py:161} INFO - Started process (PID=1265) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:14:47.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:14:47.273+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:14:47.273+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:14:47.640+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:14:47.668+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:14:47.668+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:14:47.681+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:14:47.681+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:14:47.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.431 seconds
[2026-01-12T12:15:18.163+0000] {processor.py:161} INFO - Started process (PID=1287) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:15:18.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:15:18.165+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:15:18.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:15:18.529+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:15:18.560+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:15:18.560+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:15:18.573+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:15:18.573+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:15:18.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.435 seconds
[2026-01-12T12:15:48.965+0000] {processor.py:161} INFO - Started process (PID=1309) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:15:48.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:15:48.968+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:15:48.967+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:15:49.329+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:15:49.361+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:15:49.361+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:15:49.374+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:15:49.374+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:15:49.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.596 seconds
[2026-01-12T12:16:19.839+0000] {processor.py:161} INFO - Started process (PID=1331) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:16:19.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:16:19.842+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:16:19.841+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:16:20.206+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:16:20.236+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:16:20.236+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:16:20.413+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:16:20.413+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:16:20.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.592 seconds
[2026-01-12T12:16:50.728+0000] {processor.py:161} INFO - Started process (PID=1353) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:16:50.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:16:50.731+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:16:50.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:16:51.174+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:16:51.212+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:16:51.211+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:16:51.227+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:16:51.227+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:16:51.267+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.543 seconds
[2026-01-12T12:17:21.641+0000] {processor.py:161} INFO - Started process (PID=1375) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:17:21.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:17:21.645+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:17:21.644+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:17:22.038+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:17:22.072+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:17:22.071+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:17:22.086+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:17:22.085+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:17:22.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.470 seconds
[2026-01-12T12:17:52.610+0000] {processor.py:161} INFO - Started process (PID=1397) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:17:52.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:17:52.612+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:17:52.612+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:17:52.993+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:17:53.020+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:17:53.020+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:17:53.033+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:17:53.032+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:17:53.050+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.444 seconds
[2026-01-12T12:18:23.455+0000] {processor.py:161} INFO - Started process (PID=1419) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:18:23.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:18:23.457+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:18:23.457+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:18:23.891+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:18:23.925+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:18:23.924+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:18:23.939+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:18:23.938+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:18:24.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.682 seconds
[2026-01-12T12:18:54.387+0000] {processor.py:161} INFO - Started process (PID=1441) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:18:54.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:18:54.389+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:18:54.389+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:18:54.767+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:18:54.795+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:18:54.794+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:18:54.958+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:18:54.957+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:18:54.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.610 seconds
[2026-01-12T12:19:25.254+0000] {processor.py:161} INFO - Started process (PID=1463) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:19:25.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:19:25.257+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:19:25.256+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:19:25.631+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:19:25.661+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:19:25.661+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:19:25.834+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:19:25.833+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:19:25.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.617 seconds
[2026-01-12T12:19:56.261+0000] {processor.py:161} INFO - Started process (PID=1485) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:19:56.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:19:56.263+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:19:56.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:19:56.648+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:19:56.682+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:19:56.682+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:19:56.696+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:19:56.696+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:19:56.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.461 seconds
[2026-01-12T12:20:27.133+0000] {processor.py:161} INFO - Started process (PID=1507) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:20:27.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:20:27.136+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:20:27.135+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:20:27.510+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:20:27.542+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:20:27.542+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:20:27.556+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:20:27.556+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:20:27.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.449 seconds
[2026-01-12T12:20:58.133+0000] {processor.py:161} INFO - Started process (PID=1529) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:20:58.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:20:58.135+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:20:58.135+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:20:58.556+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:20:58.587+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:20:58.587+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:20:58.601+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:20:58.601+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:20:58.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.653 seconds
[2026-01-12T12:21:29.019+0000] {processor.py:161} INFO - Started process (PID=1551) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:21:29.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:21:29.021+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:21:29.020+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:21:29.399+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:21:29.425+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:21:29.425+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:21:29.591+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:21:29.591+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:21:29.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.592 seconds
[2026-01-12T12:21:59.808+0000] {processor.py:161} INFO - Started process (PID=1573) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:21:59.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:21:59.810+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:21:59.810+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:22:00.310+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:22:00.347+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:22:00.346+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:22:00.536+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:22:00.535+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:22:00.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.751 seconds
[2026-01-12T12:22:30.804+0000] {processor.py:161} INFO - Started process (PID=1595) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:22:30.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:22:30.806+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:22:30.806+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:22:31.244+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:22:31.276+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:22:31.276+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:22:31.291+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:22:31.290+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:22:31.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.511 seconds
[2026-01-12T12:23:01.603+0000] {processor.py:161} INFO - Started process (PID=1617) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:23:01.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:23:01.605+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:23:01.605+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:23:02.038+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:23:02.068+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:23:02.068+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:23:02.080+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:23:02.080+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:23:02.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.497 seconds
[2026-01-12T12:23:32.558+0000] {processor.py:161} INFO - Started process (PID=1639) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:23:32.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:23:32.561+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:23:32.560+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:23:32.947+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:23:32.976+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:23:32.976+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:23:32.990+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:23:32.990+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:23:33.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.455 seconds
[2026-01-12T12:24:03.495+0000] {processor.py:161} INFO - Started process (PID=1661) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:24:03.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:24:03.498+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:24:03.497+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:24:03.869+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:24:03.897+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:24:03.896+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:24:03.910+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:24:03.910+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:24:04.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.604 seconds
[2026-01-12T12:24:34.310+0000] {processor.py:161} INFO - Started process (PID=1683) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:24:34.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:24:34.312+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:24:34.312+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:24:34.752+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:24:34.783+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:24:34.782+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:24:34.961+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:24:34.961+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:24:34.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.675 seconds
[2026-01-12T12:25:05.208+0000] {processor.py:161} INFO - Started process (PID=1705) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:25:05.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:25:05.210+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:25:05.210+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:25:05.625+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:25:05.656+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:25:05.656+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:25:05.669+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:25:05.669+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:25:05.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.484 seconds
[2026-01-12T12:25:36.174+0000] {processor.py:161} INFO - Started process (PID=1727) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:25:36.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:25:36.177+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:25:36.176+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:25:36.655+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:25:36.689+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:25:36.688+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:25:36.703+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:25:36.703+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:25:36.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.558 seconds
[2026-01-12T12:26:07.242+0000] {processor.py:161} INFO - Started process (PID=1749) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:26:07.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:26:07.244+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:26:07.244+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:26:07.610+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:26:07.638+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:26:07.638+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:26:07.651+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:26:07.651+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:26:07.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.454 seconds
[2026-01-12T12:26:38.154+0000] {processor.py:161} INFO - Started process (PID=1771) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:26:38.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:26:38.156+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:26:38.156+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:26:38.528+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:26:38.562+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:26:38.561+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:26:38.751+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:26:38.751+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:26:38.767+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.617 seconds
[2026-01-12T12:27:09.037+0000] {processor.py:161} INFO - Started process (PID=1793) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:27:09.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:27:09.039+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:27:09.039+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:27:09.422+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:27:09.453+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:27:09.453+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:27:09.619+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:27:09.619+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:27:09.655+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.621 seconds
[2026-01-12T12:27:39.899+0000] {processor.py:161} INFO - Started process (PID=1815) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:27:39.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:27:39.902+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:27:39.901+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:27:40.355+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:27:40.558+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:27:40.558+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:27:40.571+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:27:40.571+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:27:40.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.699 seconds
[2026-01-12T12:28:11.229+0000] {processor.py:161} INFO - Started process (PID=1837) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:28:11.231+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:28:11.232+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:28:11.232+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:28:11.697+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:28:11.728+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:28:11.728+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:28:11.743+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:28:11.743+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:28:11.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.553 seconds
[2026-01-12T12:28:42.301+0000] {processor.py:161} INFO - Started process (PID=1859) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:28:42.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:28:42.303+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:28:42.303+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:28:42.682+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:28:42.713+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:28:42.712+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:28:42.725+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:28:42.725+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:28:42.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.449 seconds
[2026-01-12T12:29:12.924+0000] {processor.py:161} INFO - Started process (PID=1881) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:29:12.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:29:12.926+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:29:12.926+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:29:13.307+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:29:13.336+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:29:13.336+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:29:13.350+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:29:13.350+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:29:13.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.618 seconds
[2026-01-12T12:29:43.712+0000] {processor.py:161} INFO - Started process (PID=1908) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:29:43.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:29:43.714+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:29:43.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:29:44.103+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:29:44.139+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:29:44.138+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:29:44.340+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:29:44.339+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:29:44.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.648 seconds
[2026-01-12T12:30:14.887+0000] {processor.py:161} INFO - Started process (PID=1930) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:30:14.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:30:14.888+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:30:14.888+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:30:15.341+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:30:15.367+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:30:15.366+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:30:15.530+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:30:15.530+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:30:15.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.662 seconds
[2026-01-12T12:30:46.494+0000] {processor.py:161} INFO - Started process (PID=1957) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:30:46.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:30:46.497+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:30:46.496+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:30:46.909+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:30:46.942+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:30:46.941+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:30:46.955+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:30:46.955+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:30:46.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.484 seconds
[2026-01-12T12:31:17.960+0000] {processor.py:161} INFO - Started process (PID=1979) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:31:17.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:31:17.962+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:31:17.962+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:31:18.331+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:31:18.360+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:31:18.360+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:31:18.373+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:31:18.373+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:31:18.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.436 seconds
[2026-01-12T12:31:49.285+0000] {processor.py:161} INFO - Started process (PID=2001) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:31:49.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:31:49.287+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:31:49.287+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:31:49.647+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:31:49.677+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:31:49.676+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:31:49.690+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:31:49.689+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:31:49.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.581 seconds
[2026-01-12T12:32:20.774+0000] {processor.py:161} INFO - Started process (PID=2023) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:32:20.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:32:20.776+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:32:20.776+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:32:21.144+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:32:21.171+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:32:21.171+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:32:21.341+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:32:21.341+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:32:21.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.586 seconds
[2026-01-12T12:32:52.192+0000] {processor.py:161} INFO - Started process (PID=2045) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:32:52.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:32:52.194+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:32:52.194+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:32:52.617+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:32:52.647+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:32:52.647+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:32:52.829+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:32:52.829+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:32:52.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.658 seconds
[2026-01-12T12:33:23.624+0000] {processor.py:161} INFO - Started process (PID=2067) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:33:23.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:33:23.627+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:33:23.626+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:33:24.013+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:33:24.041+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:33:24.040+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:33:24.052+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:33:24.052+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:33:24.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.448 seconds
[2026-01-12T12:33:54.969+0000] {processor.py:161} INFO - Started process (PID=2089) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:33:54.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:33:54.971+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:33:54.970+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:33:55.353+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:33:55.381+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:33:55.380+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:33:55.393+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:33:55.392+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:33:55.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.444 seconds
[2026-01-12T12:34:25.843+0000] {processor.py:161} INFO - Started process (PID=2111) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:34:25.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:34:25.845+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:34:25.845+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:34:26.208+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:34:26.236+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:34:26.235+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:34:26.248+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:34:26.248+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:34:26.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.428 seconds
[2026-01-12T12:34:56.683+0000] {processor.py:161} INFO - Started process (PID=2133) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:34:56.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:34:56.685+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:34:56.684+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:34:57.042+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:34:57.069+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:34:57.069+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:34:57.254+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:34:57.254+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:34:57.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.594 seconds
[2026-01-12T12:35:27.925+0000] {processor.py:161} INFO - Started process (PID=2155) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:35:27.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:35:27.928+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:35:27.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:35:28.295+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:35:28.326+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:35:28.325+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:35:28.508+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:35:28.507+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:35:28.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.603 seconds
[2026-01-12T12:35:58.599+0000] {processor.py:161} INFO - Started process (PID=2177) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:35:58.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:35:58.601+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:35:58.601+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:35:58.970+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:35:59.000+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:35:59.000+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:35:59.012+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:35:59.012+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:35:59.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.457 seconds
[2026-01-12T12:36:29.172+0000] {processor.py:161} INFO - Started process (PID=2199) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:36:29.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:36:29.174+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:36:29.174+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:36:29.527+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:36:29.560+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:36:29.559+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:36:29.573+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:36:29.573+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:36:29.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.424 seconds
[2026-01-12T12:37:00.582+0000] {processor.py:161} INFO - Started process (PID=2221) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:37:00.583+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:37:00.584+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:37:00.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:37:00.941+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:37:00.970+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:37:00.970+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:37:00.982+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:37:00.982+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:37:01.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.441 seconds
[2026-01-12T12:37:31.923+0000] {processor.py:161} INFO - Started process (PID=2243) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:37:31.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:37:31.924+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:37:31.924+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:37:32.283+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:37:32.311+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:37:32.310+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:37:32.324+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:37:32.324+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:37:32.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.592 seconds
[2026-01-12T12:38:03.342+0000] {processor.py:161} INFO - Started process (PID=2265) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:38:03.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:38:03.344+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:38:03.344+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:38:03.728+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:38:03.757+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:38:03.757+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:38:03.923+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:38:03.923+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:38:03.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.600 seconds
[2026-01-12T12:38:34.368+0000] {processor.py:161} INFO - Started process (PID=2287) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:38:34.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:38:34.371+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:38:34.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:38:34.915+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:38:35.219+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:38:35.218+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:38:35.231+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:38:35.230+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:38:35.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.888 seconds
[2026-01-12T12:39:05.997+0000] {processor.py:161} INFO - Started process (PID=2309) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:39:05.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:39:06.000+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:39:05.999+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:39:06.449+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:39:06.482+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:39:06.482+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:39:06.497+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:39:06.496+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:39:06.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.522 seconds
[2026-01-12T12:39:36.948+0000] {processor.py:161} INFO - Started process (PID=2331) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:39:36.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:39:36.950+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:39:36.950+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:39:37.340+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:39:37.370+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:39:37.369+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:39:37.383+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:39:37.382+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:39:37.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.455 seconds
[2026-01-12T12:40:07.848+0000] {processor.py:161} INFO - Started process (PID=2353) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:40:07.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:40:07.850+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:40:07.850+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:40:08.210+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:40:08.239+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:40:08.238+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:40:08.252+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:40:08.252+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:40:08.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.594 seconds
[2026-01-12T12:40:39.050+0000] {processor.py:161} INFO - Started process (PID=2375) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:40:39.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:40:39.052+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:40:39.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:40:39.411+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:40:39.445+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:40:39.444+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:40:39.613+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:40:39.612+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:40:39.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.581 seconds
[2026-01-12T12:41:09.815+0000] {processor.py:161} INFO - Started process (PID=2397) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:41:09.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:41:09.817+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:41:09.817+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:41:10.226+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:41:10.434+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:41:10.434+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:41:10.445+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:41:10.445+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:41:10.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.670 seconds
[2026-01-12T12:41:41.191+0000] {processor.py:161} INFO - Started process (PID=2419) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:41:41.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:41:41.193+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:41:41.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:41:41.570+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:41:41.598+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:41:41.598+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:41:41.611+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:41:41.611+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:41:41.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.439 seconds
[2026-01-12T12:42:12.531+0000] {processor.py:161} INFO - Started process (PID=2441) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:42:12.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:42:12.533+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:42:12.533+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:42:12.960+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:42:12.987+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:42:12.987+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:42:13.000+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:42:12.999+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:42:13.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.509 seconds
[2026-01-12T12:42:43.464+0000] {processor.py:161} INFO - Started process (PID=2463) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:42:43.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:42:43.466+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:42:43.466+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:42:43.876+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:42:43.904+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:42:43.904+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:42:43.916+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:42:43.916+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:42:44.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.636 seconds
[2026-01-12T12:43:14.975+0000] {processor.py:161} INFO - Started process (PID=2485) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:43:14.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:43:14.977+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:43:14.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:43:15.438+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:43:15.467+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:43:15.467+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:43:15.654+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:43:15.654+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:43:15.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.702 seconds
[2026-01-12T12:43:46.448+0000] {processor.py:161} INFO - Started process (PID=2507) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:43:46.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:43:46.450+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:43:46.450+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:43:46.819+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:43:47.017+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:43:47.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:43:47.027+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:43:47.026+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:43:47.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.598 seconds
[2026-01-12T12:44:17.462+0000] {processor.py:161} INFO - Started process (PID=2529) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:44:17.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:44:17.465+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:44:17.465+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:44:17.894+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:44:17.929+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:44:17.928+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:44:17.945+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:44:17.945+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:44:17.970+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.511 seconds
[2026-01-12T12:44:48.380+0000] {processor.py:161} INFO - Started process (PID=2551) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:44:48.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:44:48.382+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:44:48.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:44:48.789+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:44:48.818+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:44:48.817+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:44:48.831+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:44:48.831+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:44:48.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.471 seconds
[2026-01-12T12:45:19.325+0000] {processor.py:161} INFO - Started process (PID=2573) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:45:19.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:45:19.327+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:45:19.327+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:45:19.712+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:45:19.745+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:45:19.744+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:45:19.761+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:45:19.761+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:45:19.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.634 seconds
[2026-01-12T12:46:44.500+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:46:44.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:46:44.504+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:46:44.504+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:46:46.272+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:46:46.323+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:46:46.323+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:46:46.342+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:46:46.342+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:46:46.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 1.874 seconds
[2026-01-12T12:47:16.874+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:47:16.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:47:16.879+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:47:16.878+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:47:17.468+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:47:17.506+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:47:17.505+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:47:17.522+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:47:17.522+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:47:17.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.878 seconds
[2026-01-12T12:47:48.075+0000] {processor.py:161} INFO - Started process (PID=238) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:47:48.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:47:48.077+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:47:48.077+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:47:48.499+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:47:48.529+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:47:48.529+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:47:48.543+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:47:48.542+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:47:48.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.490 seconds
[2026-01-12T12:48:19.030+0000] {processor.py:161} INFO - Started process (PID=260) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:48:19.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:48:19.032+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:48:19.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:48:19.515+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:48:19.545+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:48:19.545+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:48:19.559+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:48:19.559+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:48:19.579+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.553 seconds
[2026-01-12T12:48:50.052+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:48:50.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:48:50.055+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:48:50.055+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:48:50.483+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:48:50.517+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:48:50.517+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:48:50.530+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:48:50.530+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:48:50.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.501 seconds
[2026-01-12T12:49:20.968+0000] {processor.py:161} INFO - Started process (PID=304) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:49:20.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:49:20.971+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:49:20.971+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:49:21.445+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:49:21.476+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:49:21.476+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:49:21.489+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:49:21.489+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:49:21.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.546 seconds
[2026-01-12T12:49:51.962+0000] {processor.py:161} INFO - Started process (PID=326) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:49:51.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:49:51.965+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:49:51.965+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:49:52.444+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:49:52.479+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:49:52.478+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:49:52.493+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:49:52.493+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:49:52.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.560 seconds
[2026-01-12T12:50:22.984+0000] {processor.py:161} INFO - Started process (PID=348) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:50:22.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:50:22.987+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:50:22.987+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:50:23.428+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:50:23.464+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:50:23.464+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:50:23.480+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:50:23.480+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:50:23.504+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.524 seconds
[2026-01-12T12:50:53.933+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:50:53.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:50:53.935+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:50:53.934+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:50:54.341+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:50:54.374+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:50:54.374+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:50:54.389+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:50:54.389+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:50:54.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.480 seconds
[2026-01-12T12:51:24.838+0000] {processor.py:161} INFO - Started process (PID=392) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:51:24.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:51:24.840+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:51:24.840+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:51:25.261+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:51:25.293+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:51:25.293+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:51:25.306+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:51:25.306+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:51:25.326+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.493 seconds
[2026-01-12T12:51:55.814+0000] {processor.py:161} INFO - Started process (PID=414) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:51:55.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:51:55.816+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:51:55.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:51:56.227+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:51:56.256+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:51:56.256+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:51:56.269+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:51:56.269+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:51:56.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.478 seconds
[2026-01-12T12:52:26.734+0000] {processor.py:161} INFO - Started process (PID=436) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:52:26.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:52:26.737+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:52:26.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:52:27.202+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:52:27.239+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:52:27.238+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:52:27.254+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:52:27.253+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:52:27.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.547 seconds
[2026-01-12T12:52:57.730+0000] {processor.py:161} INFO - Started process (PID=458) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:52:57.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:52:57.732+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:52:57.732+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:52:58.275+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:52:58.305+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:52:58.305+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:52:58.317+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:52:58.317+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:52:58.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.770 seconds
[2026-01-12T12:53:28.852+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:53:28.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:53:28.855+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:53:28.854+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:53:29.309+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:53:29.342+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:53:29.342+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:53:29.357+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:53:29.357+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:53:29.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.527 seconds
[2026-01-12T12:53:59.832+0000] {processor.py:161} INFO - Started process (PID=502) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:53:59.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:53:59.835+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:53:59.834+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:54:00.284+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:54:00.321+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:54:00.320+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:54:00.335+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:54:00.335+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:54:00.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.528 seconds
[2026-01-12T12:54:30.841+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:54:30.842+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:54:30.843+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:54:30.843+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:54:31.240+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:54:31.271+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:54:31.271+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:54:31.285+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:54:31.285+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:54:31.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.468 seconds
[2026-01-12T12:55:01.788+0000] {processor.py:161} INFO - Started process (PID=546) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:55:01.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:55:01.790+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:55:01.790+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:55:02.220+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:55:02.248+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:55:02.248+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:55:02.261+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:55:02.261+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:55:02.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.497 seconds
[2026-01-12T12:55:32.698+0000] {processor.py:161} INFO - Started process (PID=568) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:55:32.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:55:32.700+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:55:32.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:55:33.109+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:55:33.140+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:55:33.139+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:55:33.154+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:55:33.153+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:55:33.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.484 seconds
[2026-01-12T12:56:03.608+0000] {processor.py:161} INFO - Started process (PID=590) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:56:03.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:56:03.611+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:56:03.610+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:56:04.183+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:56:04.236+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:56:04.236+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:56:04.271+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:56:04.270+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:56:04.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.874 seconds
[2026-01-12T12:56:34.795+0000] {processor.py:161} INFO - Started process (PID=612) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:56:34.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:56:34.798+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:56:34.798+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:56:35.307+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:56:35.342+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:56:35.342+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:56:35.359+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:56:35.358+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:56:35.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.590 seconds
[2026-01-12T12:57:05.993+0000] {processor.py:161} INFO - Started process (PID=634) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:57:05.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:57:05.995+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:57:05.995+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:57:06.446+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:57:06.478+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:57:06.477+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:57:06.492+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:57:06.492+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:57:06.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.525 seconds
[2026-01-12T12:57:36.965+0000] {processor.py:161} INFO - Started process (PID=656) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:57:36.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:57:36.967+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:57:36.967+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:57:37.383+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:57:37.416+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:57:37.416+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:57:37.431+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:57:37.430+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:57:37.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.489 seconds
[2026-01-12T12:58:07.985+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:58:07.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:58:07.987+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:58:07.986+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:58:08.443+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:58:08.479+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:58:08.478+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:58:08.493+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:58:08.493+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:58:08.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.534 seconds
[2026-01-12T12:58:38.954+0000] {processor.py:161} INFO - Started process (PID=700) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:58:38.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:58:38.957+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:58:38.957+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:58:39.380+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:58:39.409+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:58:39.409+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:58:39.421+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:58:39.421+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:58:39.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.639 seconds
[2026-01-12T12:59:09.935+0000] {processor.py:161} INFO - Started process (PID=722) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:59:09.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:59:09.938+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:59:09.938+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:59:10.349+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:59:10.379+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:59:10.378+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:59:10.391+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:59:10.391+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:59:10.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.483 seconds
[2026-01-12T12:59:40.828+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:59:40.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T12:59:40.830+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:59:40.830+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:59:41.266+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T12:59:41.299+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:59:41.299+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T12:59:41.313+0000] {logging_mixin.py:188} INFO - [2026-01-12T12:59:41.313+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T12:59:41.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.512 seconds
[2026-01-12T13:00:11.801+0000] {processor.py:161} INFO - Started process (PID=766) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:00:11.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:00:11.804+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:00:11.804+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:00:12.282+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:00:12.312+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:00:12.311+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:00:12.324+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:00:12.324+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:00:12.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.544 seconds
[2026-01-12T13:00:42.792+0000] {processor.py:161} INFO - Started process (PID=788) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:00:42.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:00:42.795+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:00:42.794+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:00:43.210+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:00:43.242+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:00:43.242+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:00:43.260+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:00:43.260+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:00:43.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.503 seconds
[2026-01-12T13:01:13.775+0000] {processor.py:161} INFO - Started process (PID=810) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:01:13.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:01:13.778+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:01:13.777+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:01:14.211+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:01:14.254+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:01:14.253+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:01:14.273+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:01:14.273+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:01:14.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.536 seconds
[2026-01-12T13:01:44.848+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:01:44.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:01:44.851+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:01:44.851+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:01:45.287+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:01:45.322+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:01:45.322+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:01:45.516+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:01:45.516+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:01:45.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.690 seconds
[2026-01-12T13:02:15.854+0000] {processor.py:161} INFO - Started process (PID=854) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:02:15.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:02:15.856+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:02:15.856+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:02:16.271+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:02:16.303+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:02:16.302+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:02:16.317+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:02:16.316+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:02:16.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.484 seconds
[2026-01-12T13:02:46.757+0000] {processor.py:161} INFO - Started process (PID=876) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:02:46.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:02:46.760+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:02:46.759+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:02:47.173+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:02:47.204+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:02:47.204+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:02:47.217+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:02:47.216+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:02:47.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.482 seconds
[2026-01-12T13:03:17.666+0000] {processor.py:161} INFO - Started process (PID=898) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:03:17.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:03:17.668+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:03:17.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:03:18.101+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:03:18.135+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:03:18.134+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:03:18.148+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:03:18.148+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:03:18.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.505 seconds
[2026-01-12T13:03:48.595+0000] {processor.py:161} INFO - Started process (PID=920) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:03:48.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:03:48.597+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:03:48.597+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:03:49.022+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:03:49.050+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:03:49.050+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:03:49.063+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:03:49.062+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:03:49.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.491 seconds
[2026-01-12T13:04:19.548+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:04:19.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:04:19.552+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:04:19.551+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:04:20.060+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:04:20.117+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:04:20.116+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:04:20.142+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:04:20.141+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:04:20.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.837 seconds
[2026-01-12T13:04:50.740+0000] {processor.py:161} INFO - Started process (PID=964) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:04:50.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:04:50.742+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:04:50.742+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:04:51.190+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:04:51.231+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:04:51.230+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:04:51.418+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:04:51.417+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:04:51.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.700 seconds
[2026-01-12T13:05:21.764+0000] {processor.py:161} INFO - Started process (PID=986) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:05:21.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:05:21.766+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:05:21.766+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:05:22.195+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:05:22.247+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:05:22.246+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:05:22.262+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:05:22.262+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:05:22.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.527 seconds
[2026-01-12T13:05:52.746+0000] {processor.py:161} INFO - Started process (PID=1008) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:05:52.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:05:52.749+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:05:52.749+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:05:53.169+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:05:53.200+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:05:53.199+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:05:53.212+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:05:53.212+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:05:53.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.490 seconds
[2026-01-12T13:06:23.677+0000] {processor.py:161} INFO - Started process (PID=1030) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:06:23.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:06:23.680+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:06:23.679+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:06:24.096+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:06:24.126+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:06:24.126+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:06:24.138+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:06:24.138+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:06:24.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.483 seconds
[2026-01-12T13:06:54.659+0000] {processor.py:161} INFO - Started process (PID=1052) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:06:54.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:06:54.662+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:06:54.661+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:06:55.091+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:06:55.122+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:06:55.121+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:06:55.135+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:06:55.135+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:06:55.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.502 seconds
[2026-01-12T13:07:25.587+0000] {processor.py:161} INFO - Started process (PID=1074) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:07:25.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:07:25.589+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:07:25.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:07:26.002+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:07:26.032+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:07:26.032+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:07:26.244+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:07:26.244+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:07:26.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.683 seconds
[2026-01-12T13:07:56.570+0000] {processor.py:161} INFO - Started process (PID=1096) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:07:56.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:07:56.572+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:07:56.572+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:07:56.986+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:07:57.016+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:07:57.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:07:57.031+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:07:57.031+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:07:57.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.486 seconds
[2026-01-12T13:08:27.551+0000] {processor.py:161} INFO - Started process (PID=1118) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:08:27.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:08:27.554+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:08:27.553+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:08:27.979+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:08:28.010+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:08:28.009+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:08:28.022+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:08:28.022+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:08:28.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.497 seconds
[2026-01-12T13:08:58.473+0000] {processor.py:161} INFO - Started process (PID=1140) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:08:58.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:08:58.475+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:08:58.475+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:08:58.878+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:08:58.911+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:08:58.911+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:08:58.929+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:08:58.928+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:08:58.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.484 seconds
[2026-01-12T13:09:29.475+0000] {processor.py:161} INFO - Started process (PID=1162) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:09:29.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:09:29.483+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:09:29.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:09:30.080+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:09:30.123+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:09:30.122+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:09:30.140+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:09:30.140+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:09:30.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.709 seconds
[2026-01-12T13:10:00.743+0000] {processor.py:161} INFO - Started process (PID=1184) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:10:00.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:10:00.746+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:10:00.745+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:10:01.278+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:10:01.316+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:10:01.315+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:10:01.331+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:10:01.331+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:10:01.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.858 seconds
[2026-01-12T13:10:31.923+0000] {processor.py:161} INFO - Started process (PID=1206) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:10:31.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:10:31.926+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:10:31.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:10:32.364+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:10:32.399+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:10:32.399+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:10:32.598+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:10:32.597+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:10:32.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.703 seconds
[2026-01-12T13:11:02.984+0000] {processor.py:161} INFO - Started process (PID=1228) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:11:02.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:11:02.986+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:11:02.986+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:11:03.438+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:11:03.470+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:11:03.469+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:11:03.481+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:11:03.481+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:11:03.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.521 seconds
[2026-01-12T13:11:33.947+0000] {processor.py:161} INFO - Started process (PID=1250) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:11:33.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:11:33.950+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:11:33.949+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:11:34.377+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:11:34.412+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:11:34.411+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:11:34.426+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:11:34.426+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:11:34.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.504 seconds
[2026-01-12T13:12:04.964+0000] {processor.py:161} INFO - Started process (PID=1272) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:12:04.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:12:04.967+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:12:04.967+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:12:05.413+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:12:05.447+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:12:05.447+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:12:05.462+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:12:05.462+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:12:05.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.525 seconds
[2026-01-12T13:12:35.944+0000] {processor.py:161} INFO - Started process (PID=1294) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:12:35.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:12:35.946+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:12:35.946+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:12:36.344+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:12:36.373+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:12:36.373+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:12:36.385+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:12:36.385+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:12:36.407+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.467 seconds
[2026-01-12T13:22:41.405+0000] {processor.py:161} INFO - Started process (PID=1316) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:22:41.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:22:41.408+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:22:41.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:22:41.993+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:22:42.028+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:22:42.027+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:22:42.045+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:22:42.045+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:22:42.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.881 seconds
[2026-01-12T13:23:12.678+0000] {processor.py:161} INFO - Started process (PID=1340) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:23:12.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:23:12.681+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:23:12.681+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:23:13.287+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:23:13.323+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:23:13.323+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:23:13.339+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:23:13.339+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:23:13.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.692 seconds
[2026-01-12T13:23:43.921+0000] {processor.py:161} INFO - Started process (PID=1362) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:23:43.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:23:43.924+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:23:43.924+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:23:44.455+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:23:44.497+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:23:44.497+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:23:44.515+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:23:44.515+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:23:44.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.627 seconds
[2026-01-12T13:24:15.052+0000] {processor.py:161} INFO - Started process (PID=1384) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:24:15.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:24:15.054+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:24:15.054+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:24:15.451+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:24:15.484+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:24:15.484+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:24:15.497+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:24:15.497+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:24:15.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.471 seconds
[2026-01-12T13:24:46.050+0000] {processor.py:161} INFO - Started process (PID=1406) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:24:46.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:24:46.055+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:24:46.054+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:24:46.858+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:24:46.901+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:24:46.900+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:24:46.915+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:24:46.915+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:24:46.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.899 seconds
[2026-01-12T13:25:17.488+0000] {processor.py:161} INFO - Started process (PID=1428) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:25:17.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:25:17.491+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:25:17.491+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:25:18.036+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:25:18.076+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:25:18.075+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:25:18.094+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:25:18.093+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:25:18.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.831 seconds
[2026-01-12T13:25:48.665+0000] {processor.py:161} INFO - Started process (PID=1450) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:25:48.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:25:48.669+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:25:48.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:25:49.158+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:25:49.191+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:25:49.190+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:25:49.417+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:25:49.416+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:25:49.440+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.780 seconds
[2026-01-12T13:26:19.783+0000] {processor.py:161} INFO - Started process (PID=1472) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:26:19.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:26:19.786+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:26:19.785+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:26:20.274+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:26:20.312+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:26:20.311+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:26:20.329+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:26:20.329+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:26:20.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.575 seconds
[2026-01-12T13:26:50.932+0000] {processor.py:161} INFO - Started process (PID=1494) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:26:50.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:26:50.935+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:26:50.934+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:26:51.385+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:26:51.421+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:26:51.420+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:26:51.435+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:26:51.435+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:26:51.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.530 seconds
[2026-01-12T13:27:21.925+0000] {processor.py:161} INFO - Started process (PID=1516) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:27:21.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:27:21.928+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:27:21.928+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:27:22.424+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:27:22.462+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:27:22.461+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:27:22.479+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:27:22.479+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:27:22.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.584 seconds
[2026-01-12T13:27:53.019+0000] {processor.py:161} INFO - Started process (PID=1538) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:27:53.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:27:53.021+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:27:53.021+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:27:53.498+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:27:53.540+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:27:53.540+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:27:53.555+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:27:53.554+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:27:53.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.566 seconds
[2026-01-12T13:28:24.027+0000] {processor.py:161} INFO - Started process (PID=1560) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:28:24.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:28:24.030+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:28:24.029+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:28:24.431+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:28:24.459+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:28:24.459+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:28:24.634+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:28:24.634+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:28:24.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.629 seconds
[2026-01-12T13:28:55.018+0000] {processor.py:161} INFO - Started process (PID=1582) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:28:55.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:28:55.020+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:28:55.020+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:28:55.442+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:28:55.476+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:28:55.475+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:28:55.666+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:28:55.666+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:28:55.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.672 seconds
[2026-01-12T13:29:26.239+0000] {processor.py:161} INFO - Started process (PID=1604) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:29:26.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:29:26.241+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:29:26.241+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:29:26.697+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:29:26.739+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:29:26.738+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:29:26.755+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:29:26.755+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:29:26.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.548 seconds
[2026-01-12T13:29:57.277+0000] {processor.py:161} INFO - Started process (PID=1626) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:29:57.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:29:57.281+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:29:57.280+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:29:57.746+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:29:57.782+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:29:57.781+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:29:57.799+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:29:57.799+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:29:57.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.552 seconds
[2026-01-12T13:30:28.283+0000] {processor.py:161} INFO - Started process (PID=1648) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:30:28.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:30:28.285+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:30:28.285+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:30:28.784+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:30:28.834+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:30:28.834+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:30:28.853+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:30:28.853+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:30:28.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.607 seconds
[2026-01-12T13:30:59.357+0000] {processor.py:161} INFO - Started process (PID=1670) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:30:59.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:30:59.359+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:30:59.359+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:30:59.777+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:30:59.814+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:30:59.814+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:30:59.830+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:30:59.830+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:31:00.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.726 seconds
[2026-01-12T13:31:30.368+0000] {processor.py:161} INFO - Started process (PID=1692) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:31:30.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:31:30.370+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:31:30.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:31:30.765+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:31:30.797+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:31:30.796+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:31:30.996+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:31:30.996+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:31:31.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.652 seconds
[2026-01-12T13:32:01.459+0000] {processor.py:161} INFO - Started process (PID=1714) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:32:01.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:32:01.462+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:32:01.462+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:32:01.869+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:32:01.903+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:32:01.903+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:32:01.918+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:32:01.918+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:32:01.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.485 seconds
[2026-01-12T13:32:32.493+0000] {processor.py:161} INFO - Started process (PID=1736) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:32:32.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:32:32.496+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:32:32.495+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:32:32.919+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:32:32.951+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:32:32.951+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:32:32.965+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:32:32.965+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:32:32.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.496 seconds
[2026-01-12T13:33:03.496+0000] {processor.py:161} INFO - Started process (PID=1758) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:33:03.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:33:03.498+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:33:03.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:33:03.974+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:33:04.013+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:33:04.012+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:33:04.028+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:33:04.028+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:33:04.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.558 seconds
[2026-01-12T13:33:34.570+0000] {processor.py:161} INFO - Started process (PID=1780) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:33:34.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:33:34.573+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:33:34.572+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:33:34.982+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:33:35.014+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:33:35.014+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:33:35.028+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:33:35.027+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:33:35.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.485 seconds
[2026-01-12T13:34:05.498+0000] {processor.py:161} INFO - Started process (PID=1802) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:34:05.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:34:05.500+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:34:05.500+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:34:05.961+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:34:05.993+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:34:05.993+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:34:06.168+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:34:06.167+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:34:06.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.703 seconds
[2026-01-12T13:34:36.548+0000] {processor.py:161} INFO - Started process (PID=1824) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:34:36.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:34:36.551+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:34:36.550+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:34:37.134+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:34:37.169+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:34:37.168+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:34:37.380+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:34:37.380+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:34:37.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.855 seconds
[2026-01-12T13:35:07.864+0000] {processor.py:161} INFO - Started process (PID=1846) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:35:07.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:35:07.867+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:35:07.866+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:35:08.295+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:35:08.324+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:35:08.324+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:35:08.337+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:35:08.337+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:35:08.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.495 seconds
[2026-01-12T13:35:38.791+0000] {processor.py:161} INFO - Started process (PID=1868) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:35:38.792+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:35:38.794+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:35:38.793+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:35:39.231+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:35:39.267+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:35:39.267+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:35:39.279+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:35:39.279+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:35:39.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.510 seconds
[2026-01-12T13:36:09.736+0000] {processor.py:161} INFO - Started process (PID=1890) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:36:09.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:36:09.739+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:36:09.738+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:36:10.260+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:36:10.302+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:36:10.301+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:36:10.317+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:36:10.317+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:36:10.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.608 seconds
[2026-01-12T13:36:40.792+0000] {processor.py:161} INFO - Started process (PID=1912) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:36:40.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:36:40.795+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:36:40.795+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:36:41.252+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:36:41.285+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:36:41.284+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:36:41.300+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:36:41.300+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:36:41.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.704 seconds
[2026-01-12T13:37:11.837+0000] {processor.py:161} INFO - Started process (PID=1934) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:37:11.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:37:11.840+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:37:11.839+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:37:12.256+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:37:12.289+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:37:12.289+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:37:12.511+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:37:12.511+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:37:12.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.699 seconds
[2026-01-12T13:37:43.046+0000] {processor.py:161} INFO - Started process (PID=1956) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:37:43.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:37:43.049+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:37:43.048+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:37:43.479+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:37:43.511+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:37:43.511+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:37:43.524+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:37:43.524+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:37:43.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.502 seconds
[2026-01-12T13:38:13.968+0000] {processor.py:161} INFO - Started process (PID=1978) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:38:13.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:38:13.970+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:38:13.970+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:38:14.383+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:38:14.413+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:38:14.412+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:38:14.425+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:38:14.425+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:38:14.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.481 seconds
[2026-01-12T13:38:44.873+0000] {processor.py:161} INFO - Started process (PID=2000) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:38:44.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:38:44.876+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:38:44.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:38:45.283+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:38:45.313+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:38:45.312+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:38:45.325+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:38:45.325+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:38:45.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.477 seconds
[2026-01-12T13:39:15.782+0000] {processor.py:161} INFO - Started process (PID=2022) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:39:15.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:39:15.784+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:39:15.784+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:39:16.210+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:39:16.253+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:39:16.252+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:39:16.519+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:39:16.519+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:39:16.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.762 seconds
[2026-01-12T13:39:46.903+0000] {processor.py:161} INFO - Started process (PID=2044) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:39:46.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:39:46.905+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:39:46.905+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:39:47.450+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:39:47.482+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:39:47.482+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:39:47.672+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:39:47.672+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:39:47.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.790 seconds
[2026-01-12T13:40:18.126+0000] {processor.py:161} INFO - Started process (PID=2066) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:40:18.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:40:18.128+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:40:18.128+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:40:18.578+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:40:18.803+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:40:18.802+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:40:18.814+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:40:18.813+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:40:18.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.716 seconds
[2026-01-12T13:40:49.275+0000] {processor.py:161} INFO - Started process (PID=2088) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:40:49.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:40:49.278+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:40:49.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:40:49.718+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:40:49.751+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:40:49.751+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:40:49.766+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:40:49.765+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:40:49.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.515 seconds
[2026-01-12T13:41:20.231+0000] {processor.py:161} INFO - Started process (PID=2110) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:41:20.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:41:20.233+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:41:20.233+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:41:20.639+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:41:20.669+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:41:20.668+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:41:20.682+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:41:20.682+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:41:20.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.473 seconds
[2026-01-12T13:41:51.161+0000] {processor.py:161} INFO - Started process (PID=2132) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:41:51.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:41:51.165+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:41:51.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:41:51.612+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:41:51.650+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:41:51.650+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:41:51.668+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:41:51.668+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:41:51.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.721 seconds
[2026-01-12T13:42:22.185+0000] {processor.py:161} INFO - Started process (PID=2154) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:42:22.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:42:22.187+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:42:22.187+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:42:22.594+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:42:22.626+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:42:22.626+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:42:22.811+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:42:22.811+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:42:22.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.650 seconds
[2026-01-12T13:42:53.214+0000] {processor.py:161} INFO - Started process (PID=2176) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:42:53.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:42:53.216+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:42:53.216+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:42:53.625+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:42:53.660+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:42:53.659+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:42:53.902+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:42:53.901+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:42:53.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.713 seconds
[2026-01-12T13:43:24.376+0000] {processor.py:161} INFO - Started process (PID=2198) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:43:24.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:43:24.378+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:43:24.378+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:43:24.810+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:43:24.842+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:43:24.841+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:43:24.855+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:43:24.855+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:43:24.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.502 seconds
[2026-01-12T13:43:55.299+0000] {processor.py:161} INFO - Started process (PID=2220) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:43:55.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:43:55.302+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:43:55.301+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:43:55.722+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:43:55.752+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:43:55.752+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:43:55.765+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:43:55.765+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:43:55.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.487 seconds
[2026-01-12T13:44:26.206+0000] {processor.py:161} INFO - Started process (PID=2242) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:44:26.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:44:26.208+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:44:26.208+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:44:26.620+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:44:26.651+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:44:26.650+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:44:26.663+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:44:26.663+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:44:26.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.484 seconds
[2026-01-12T13:44:57.183+0000] {processor.py:161} INFO - Started process (PID=2264) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:44:57.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:44:57.185+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:44:57.185+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:44:57.678+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:44:57.710+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:44:57.709+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:44:57.890+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:44:57.890+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:44:57.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.730 seconds
[2026-01-12T13:45:28.230+0000] {processor.py:161} INFO - Started process (PID=2286) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:45:28.231+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:45:28.232+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:45:28.232+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:45:28.675+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:45:28.707+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:45:28.706+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:45:28.895+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:45:28.894+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:45:28.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.685 seconds
[2026-01-12T13:45:59.354+0000] {processor.py:161} INFO - Started process (PID=2308) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:45:59.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:45:59.357+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:45:59.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:45:59.806+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:45:59.838+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:45:59.838+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:45:59.852+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:45:59.852+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:45:59.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.539 seconds
[2026-01-12T13:46:30.438+0000] {processor.py:161} INFO - Started process (PID=2330) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:46:30.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:46:30.440+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:46:30.440+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:46:30.871+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:46:30.904+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:46:30.904+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:46:30.919+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:46:30.918+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:46:30.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.508 seconds
[2026-01-12T13:47:01.385+0000] {processor.py:161} INFO - Started process (PID=2352) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:47:01.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:47:01.387+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:47:01.387+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:47:01.801+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:47:01.833+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:47:01.833+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:47:01.846+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:47:01.846+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:47:01.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.485 seconds
[2026-01-12T13:47:32.295+0000] {processor.py:161} INFO - Started process (PID=2374) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:47:32.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:47:32.298+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:47:32.297+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:47:32.700+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:47:32.730+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:47:32.729+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:47:32.906+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:47:32.906+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:47:32.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.632 seconds
[2026-01-12T13:48:03.314+0000] {processor.py:161} INFO - Started process (PID=2396) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:48:03.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:48:03.316+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:48:03.316+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:48:03.740+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:48:03.775+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:48:03.774+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:48:03.967+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:48:03.967+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:48:03.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.672 seconds
[2026-01-12T13:48:34.416+0000] {processor.py:161} INFO - Started process (PID=2418) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:48:34.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:48:34.418+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:48:34.418+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:48:34.855+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:48:35.094+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:48:35.093+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:48:35.106+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:48:35.106+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:48:35.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.715 seconds
[2026-01-12T13:49:05.685+0000] {processor.py:161} INFO - Started process (PID=2440) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:49:05.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:49:05.687+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:49:05.687+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:49:06.084+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:49:06.115+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:49:06.114+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:49:06.128+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:49:06.128+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:49:06.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.467 seconds
[2026-01-12T13:49:36.617+0000] {processor.py:161} INFO - Started process (PID=2462) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:49:36.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:49:36.620+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:49:36.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:49:37.154+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:49:37.188+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:49:37.187+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:49:37.203+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:49:37.203+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:49:37.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.611 seconds
[2026-01-12T13:50:07.661+0000] {processor.py:161} INFO - Started process (PID=2484) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:50:07.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:50:07.663+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:50:07.663+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:50:08.292+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:50:08.338+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:50:08.338+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:50:08.356+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:50:08.355+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:50:08.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.920 seconds
[2026-01-12T13:50:38.950+0000] {processor.py:161} INFO - Started process (PID=2506) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:50:38.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:50:38.952+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:50:38.951+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:50:39.396+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:50:39.433+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:50:39.432+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:50:39.647+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:50:39.646+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:50:39.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.728 seconds
[2026-01-12T13:51:10.025+0000] {processor.py:161} INFO - Started process (PID=2528) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:51:10.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:51:10.027+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:51:10.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:51:10.467+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:51:10.501+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:51:10.501+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:51:10.698+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:51:10.698+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:51:10.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.698 seconds
[2026-01-12T13:51:41.165+0000] {processor.py:161} INFO - Started process (PID=2550) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:51:41.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:51:41.168+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:51:41.167+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:51:41.592+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:51:41.625+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:51:41.624+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:51:41.639+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:51:41.639+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:51:41.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.499 seconds
[2026-01-12T13:52:12.010+0000] {processor.py:161} INFO - Started process (PID=2572) to work on /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:52:12.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/amazon_etl_pipeline.py for tasks to queue
[2026-01-12T13:52:12.016+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:52:12.016+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:52:12.836+0000] {processor.py:840} INFO - DAG(s) 'amazon_etl_pipeline' retrieved from /opt/airflow/dags/amazon_etl_pipeline.py
[2026-01-12T13:52:12.885+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:52:12.885+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2026-01-12T13:52:12.906+0000] {logging_mixin.py:188} INFO - [2026-01-12T13:52:12.906+0000] {dag.py:3834} INFO - Setting next_dagrun for amazon_etl_pipeline to None, run_after=None
[2026-01-12T13:52:12.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/amazon_etl_pipeline.py took 0.945 seconds
